%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 

\documentclass[a4paper,12pt]{report}
%TC:group tabular 1 1


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Xiu Hong\ Kooi\xspace}
\def\authorcollege{Wolfson College\xspace}
\def\authoremail{xhk20@cam.ac.uk}
\def\dissertationtitle{Exploring Dependent Types and Behaviour in Imperative Language}
\def\wordcount{0}


%\usepackage[dvips]{epsfig,graphics} 
\usepackage{epsfig,graphicx,verbatim,parskip,tabularx,setspace,xspace}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{semantic}
\usepackage{float}

\usepackage{tabto}

\newenvironment{tabs}[1]
 {\flushleft\TabPositions{#1}}
 {\endflushleft}

\usepackage[british]{babel}
\usepackage[%
  backend=bibtex      % biber or bibtex
%,style=authoryear    % Alphabeticalsch
 ,style=numeric-comp  % numerical-compressed
 ,sorting=none        % no sorting
 ,sortcites=true      % some other example options ...
 ,maxbibnames=99
 ,block=none
 ,indexing=false
 ,citereset=none
 ,isbn=true
 ,url=true
 ,doi=true            % prints doi
 ,natbib=true         % if you need natbib functions
]{biblatex}
\usepackage{biblatex}
\addbibresource{./dissertation.bib}


%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 
\textit{Type systems} \cite{typesystem} have been one of the most extensively researched field in 
Programming Languages. They act as a way from improving the reliability of a 
language by enforcing rules, preventing operations being applied on 
incompatible data. Type systems can be broken down into multiple categories but 
two of the most well known are \textit{Static} \cite{staticTyping} and 
\textit{Dynamic} \cite{dynamicTyping} typing. Mainstream programming 
languages such as \textit{Java} \cite{java}, \textit{C} \cite{c} and \textit{C++} \cite{cpp} 
uses the former while languages like \textit{Python} \cite{python} and 
\textit{JavaScript} \cite{js} uses the latter. 
Over the years, programming languages have included more powerful and flexible 
type systems, languages like \textit{C\#} \cite{cSharp} and \textit{Go} \cite{goInferenceType} allow 
\textit{type inference} \cite{inferenceType}, using a feature called \textit{Reflection} 
Java and Python can even achieve \textit{Duck Typing} \cite{javaDuckType}.
\par
However, as much as we have studied about type systems, \textit{Dependent Types} 
\cite{depenTypeAtWork} remains uncommon in the industry. While the theory of dependent types has been 
established several decades ago, only a small number of languages has 
integrate full dependent type support, most of them being functional languages. 
Dependent types allows the programmer to create types whose definition depends 
on a value. A type system that provides such refined control over the values it 
can take unlocks possibility that are previously unavailable such as 
domain-specific type checking at compile time. Furthermore, it acts as a built 
in ``error-handling'' code and could potentially 
reduces the lines of code a programmer needs to write. An in depth 
definition of dependent types is provided in the next section.

\par
The expressive nature of dependent types allow one to define complex 
mathematical assertations and hence lends itself to theorem proving systems. 
Mutliple functional languages such as \textit{Epigram} 
\cite{epigram} and \textit{Agda} \cite{agda} has 
built in support for dependent typing. However they remain niche and more 
mainstream languages like Java and C++ does not get the luxury. In chapter 2 of 
this dissertation we will be providing an in depth analysis of the current state 
of dependent types in programming languages and answer why dependent types are 
not more prominant in languages, in particular imperative languages.

\par
Multiple past research has studied and show the feasibility of an dependently typed 
imperative language. These studies has expressed the semantics of 
how an imperative languages would interact with dependent types and in some 
cases created a new language from the ground up. While we find these work novel 
and provided highly technical explanation to the field, they fail to caputure 
how this could relate to mainsteam programming languages. Furhtermore, the 
semantics provided in these studies are very complex with advanced language 
features, we propose that a more simple and barebone definiton will allow easier 
access to the literature and motivate more studies into dependenty types. 

\par
In chapter 3 we will be defining the syntax, typing rules and semantics 
of a basic language with dependent types support which will be studied 
and extended throughout the disseratation. Our language, named Simple-$\Pi$ is a 
First-Order Programming Language which highly resembles the C programming 
language. Our aim with the language is to capture the core behaviour of 
dependent types and thus for the pursuit of simplicity is kept at a minimal with 
only the fundamental features. 

\par
In chapter 4 we will be presenting the semantics of Simple-$\Pi$, in addition 
to the basic operational semantics, we will discuss
multiple scenarios that dependent types cause uncertainties when used with 
imperative languages. We proposed different solutions to resolve the 
uncertainties and observes how these different features interact. 

\par
In chapter 5 we will discuss our work with regards to the 
existing work done in the area and how it completments the literature. 
Finally we will conclude by discussing advanced features that can be integrated 
into our languages and how it can further complicate the language. We will also 
discuss some of the other considerations that need to be taken account when 
thinking about incorporating dependent types into a real language. 

\section{What Are Dependent Types}
In this section we will be providing the definitions of dependent types.

\subsection{Basic Definition}
At a very high level dependent types are types that depends on the value of 
another type. For example, we can define a type that captures only the even 
integers using the definition 
\verb+type EvenInt := { i : Int | i % 2 = 0}+. In this case we 
can say that the type EvenInt \textit{EvenInt} depends on the type \textit{int}.
Another commonly used example to describe dependent types would be a type like 
\verb+type FixVec<T, N> := { v : Vec<T> | len(v) = N}+, this type definition defines 
a vector or array of elements with type $T$ that always contains $N$ elements.

\subsection{Dependent $\Pi$ Types}
We can capture the definition mathematically using the notion of \textit{dependent 
product types}, i.e. $\Pi$ type. This is also sometimes referred to as 
\textit{dependent function type} as in this definition we construct a function 
$F: A \rightarrow B$. The function $F$ takes an element of type $A$ and 
gives us an element of type $B$ which depends on $A$. We express it 
mathematically using the $\Pi$ notation as
\begin{center}
 \begin{tabular}{l}
   $\prod x: A.  F(x)$
 \end{tabular} 
\end{center}

In this definition, $F(x)$ is the type family for the type $B$ that depends on $A$.
However $F$ could be a constant function, so we can also express the definition 
as $\Pi x:A.B$, in this case $B$ does not depend 
on the value $x$. Using the \textit{EvenInt} example from earlier, 
it can be defined as 
$\Pi x:Int.\text{ }\{ i:Int\text{ }|\text{ }i\text{ }\%\text{ }2\text{ }= 0\}$.

\par
Interestingly, the dependent product type correspond to the 
\textit{forall quantifier} as per 
the \textit{Curry–Howard correspondence}. The idea is that the dependent 
function $F(x)$ correspond to predicate $P(x)$ and thus the dependent product 
type has a one-to-one correspondence to $\forall x: A. P(x)$.

\subsection{Dependent $\Sigma$ Types}
In addition to the dependent product type, we have the notion of \textit{dependent sum 
types}, written as $\Sigma$ type. This is often referred to as the 
\textit{dependent pair type} as the resulting type here is an ordered pair. 
Specifically the resulting pair $\langle a,b \rangle$ is ordered such that the 
second element depends on the first element. The 
mathematical definition is similar to that of the product type
\begin{center}
 \begin{tabular}{l}
   $\langle a,b \rangle :\sum x: A.  F(x)$
 \end{tabular} 
\end{center}
In the case $a:A, b: F(x)$, similarly, $F$ could be a constant function and thus 
the expression is $\Sigma x:A.B$. Consider the following example, 

$\Sigma x: Int.\{y:Int\text{ }|\text{ } y = x * 2\}$, then the type would 
contain values like $\langle 1,2 \rangle$ and $\langle 4,8 \rangle$ where the 
second pair is doubled the first.

\par
Like the dependent product type, the dependent sum type correspond to a 
universal quantifier, in this case, the \textit{existential quantifier}. As 
per the Curry–Howard correspondence, $F(x)$ corresponds to predicate $P(x)$ 
thus $\Sigma x:A.F(x)$ correponds to $\exists x: A. P(x)$.

\par
While both dependent product types and dependent sum types are important to the 
literature, the project itself will mainly focus on the former. we believe that 
the the notion of pair in dependent sum types prove to be redundant in 
the construction a programming language and does not provide any additional 
value. The dependent product type is largely adequate for our goal.

\section{Overview of a Dependently Typed Language}
In this section we will discuss at a very high level the behaviour one would 
expect from a dependently typed language, its benefits and use cases.

\subsection{Language Behaviour}
The key behaviour we are interested in is regarding compile time type checking. 
For instance, using the example above, if a type is defined as an \textit{EvenInt} 
then if at any point in the code it becomes odd then it should be caught at 
compile time. 

\par
Consider the psedocode below: 
\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  function f(int x) {
    if (x \% 2 == 0) {
      ...
    }
    throw error ``x has to be even''
  }
  
  function dependent_f(EvenInt i) {
    ...
  }
  \end{lstlisting}
  \caption{Dependenty Typed Language Behaviour}
\end{figure}

\par
The function \textit{f} above checks whether the argument $x$ is even, if it 
isn't then it throws a runtime error. If dependent type is available, then if an 
invalid argument is passed in it should signal an error at compile time, saving the 
error handling code as shown in \textit{dependent\_f}. 

\subsection{Benefits of Dependent Types}
As we seen in the previous subsection, dependent types allows programmer to 
define much richer and expressive types that can be checked at compile time. The 
addition of dependent types allow for safer code as it is able to guarentee certain 
properties. 

\par
Furthermore, using dependent types eliminates the need for many trivial error 
handling code. Around 4\% of code in every program is dedicated to error 
handling \cite{errorHandlingCode}, dependent types will be able to reduce the 
numbers and allow the programmer more time to write the logical part of the 
code, indirectly leading to more robust codebases.

\par
Consider a banking system where users are able to transfer and withdraw 
money using a function, 
in order to prevent overdraft one might be able to define a function that takes 
a type \textit{Amount$<$T$>$}, a double type that is always 
greater than 0 and less than \textit{T}, where \textit{T} is the current balance in the account. 
This approach guarantees the amount is always valid without the need of writing 
error handling code. This example demonstrated using an object-oriented style 
language by Vasconcelos \cite{objOritentedDependentType}.


\chapter{Background: State of Dependently Typed in Language} 
In this chapter we will be reviewing the current knowledge of dependent types 
in different programming languages. It will cover languages with full dependent 
types support as well as some languages with similar concepts and point out how 
it differs from dependent types. Lastly we will summarise all these languages 
and point out some limitations and unknowns. 

\section{Functional Languages}

In this section we will be examining three functional languages with 
dependent typing. Functional languages 
uses the \textit{functional programming} \cite{overviewFP} paradigm which is a programming 
paradigm that constructs program using a series of function applications. In 
this paradigm, functions return values as oppose to altering the state of the 
program. In this programming paradigm, the language focuses on describing 
\textit{what} the program will accomplish.

\par

Many functional languages has the notion of purity, i) A function will always 
return the same value when given the same arguments. ii) The evaluation of a 
function has no side effects (changes to the state of the program).

\subsection{Agda}

\textit{Agda} \cite{agda} is a purely functional language originally developed by Ulf Norell in 
1999 however the first appearance the current version known as Agda 2 is in 
2007. Agda has all the necessary constructs one would expect in a functional 
language such as first-class functions, inductive definitions, pattern matching, 
etc. In addition to being a functional language, Agda also serves an automated theorem prover. 
Agda is one of the few programming language with native dependent type support. 

\par
The code listing below is an example of defining a fixed length vector in 
dependent type. 

\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  data Nat : Set where 
  zero : Nat
  suc  : Nat -> Nat  
  
  data EvenNat : Nat -> Set where
  even-zero  : EvenNat zero
  even-plus2 : {n : Nat} -> EvenNat n -> EvenNat (suc (suc n))
  
  data Vec (A : Set) : Nat -> Set where
  [] : Vec A zero
  _::_ : {n : Nat} -> A -> Vec A n -> Vec A (suc n)
  \end{lstlisting}
  \caption{Dependent Types in Agda}
\end{figure}

\par
While Agda provides dependent type support, it remains a niche language. One of 
the reason being its paradigm, Agda is \textit{purely functional} \cite{purelyFP}, meaning that 
all functions are pure (i.e. not relying on the program state or other mutable 
data). Functional languages are generally considered harder to learn and grasp 
compared to other paradigms \cite{fpHarder}. Furthermore, the general lack of 
awareness and competent users who can program dependent types contribute to Agda 
being a niche language in the programming world and is 
predominantly used for theorem proving.

\subsection{Haskell}
\textit{Haskell} \cite{haskell} is a purely functional programming language first appeared in 1990. In 
contrast to Agda, Haskell is often considered a more general purpose programming 
language. Haskell is among the most popular programming languages and argubly 
the most popular ``pure'' language in the world \cite{pypl}. 
Haskell has even been adopted by software companies such as Facebook \cite{haskellFB}.

\par
Haskell is not a language that supports dependent types natively however many 
extensions has been developed to simulate the experience. 
Generalised Algebraic Data Types (GADTs) are a generalization of the 
algebraic data types, it allows the programmer to 
explicitly write down the types of the constructors \cite{haskellGADT}. 
\begin{figure}[H]
  \begin{lstlisting}
    data Expr = I Int        
          | Add Expr Expr 
          | Mul Expr Expr 
  \end{lstlisting}
  \caption{A GADT defintion for arithmetic operations in Haskell}
\end{figure}

Using the power of GADT one could define dependent types as so

\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat (n :: Nat) where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vec a (n :: Nat) where
      Nil  :: Vec a 0
      (:>) :: a -> Vec a n -> Vec a (n + 1)
  \end{lstlisting}
  \caption{Dependent Types in Haskell}
\end{figure}

\par
Although GADTs provide a way of simulating dependent types in Haskell and 
argubly enough for simple dependent typing enough for many cases. 
Haskell does not qualify as a fully dependent 
language due to the lack of certain features such as dependent functions. There 
have been proposals to add full dependent type support to Haskell however a lot 
of work remains to be done \cite{dependentHaskell, aRoleForDependentHaskell}. 
Furthermore, while Haskell is significantly more well known compared to Agda, it 
still lack the popularity of languages like Java and Python.

\subsection{Idris}
\textit{Idris} \cite{idris} is a dependently typed functional language first 
appeared in 2007. Idris bears similarity with Agda, both in terms of paradigm 
and type system. However the differ in one crucial way, Idris is designed to 
emphasise general purpose programming rather than theorem proving. Earlier one 
we stated that one of the less desirable property of Agda was its niche because 
of its emphasis in theorem proving. Idris provides 
interoperability with systems libraries and C programs, 
as well as language constructs for domain specific language 
implementation \cite{gpIdris}. 

\par
Syntactically Idris is very similar to Agda, dependent types are defined as so: 
\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat :  Nat -> Type where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vect : Nat -> Type -> Type where
      Nil  : Vect 0 a
      (::) : (x : a) -> (xs : Vect n a) -> Vect (n + 1) a
  \end{lstlisting}
  \caption{Dependent Types in Idris}
\end{figure}

\par
While Idris offers interoperability with multiple mainstream programming 
languages such as C and JavaScript, Idris remain predominantly a research tool. 
Idris is not production ready \cite{gpIdris} as it is missing certain libraries 
and more importantly nobody is working on Idris full time. Furthermore Idris is 
still a functional language, hence suffering from the limitation stated earlier. 

\section{Imperative Languages}

In this section we will be discussing dependent typing with regards to imperative 
languages. Imprative languages uses the \textit{imperative programming} 
\cite{imperativeOverview} paradigm, in constrat to the functional 
programming, this pradigm emphasises \textit{how} a program will operate 
by using a series of statements to change the program state.

\par

Imperative languages can be further broken down into different categories, 
mainly Procedural and Object-Orinted. Many of the world's most popular languages 
fall into this two categories, C, FORTRAN, COBOL are examples of procedural 
languages while Java, C#, Kotlin are Object-Oriented Languages. Some languages such 
as C++, Python are multi-paradigm and allows the programmer to write code both 
in a procedural manner or object-oriented manner. 

\par

Currently there is no production ready imperative programming language with 
proper dependent type support. Previous research has look at creating an 
impertaive language with dependent types but these are not available to the 
general programmers. Certain mainstream languages also have aspect that 
resembles dependent types but do not provide the complete feature.

\subsection{Xanadu}
\textit{Xanadu} \cite{xanadu} is a dependently typed imperative language created by a team at 
the University of Cincinnati. The language was implemented in OCaml and was 
said to be available online in the original paper, however the original cited 
location looks to have been taken offline. It is safe to conclude that 
the language itself is also no longer in active development 

\par
There are no examples of the actual language available online except some code 
snippets shown by the author in the original paper. As such we are unable to 
provide any analysis on the language itself.

\par
However, the language is worth a mention here as it shows the feasibility of 
imperative languages having full dependent typing. The research by the authors 
are impressive and it serves as inspiration for our project. 

\par
Our project complements the work by Xi by providing analysis on the problem at 
hand. The original paper merely demonstrated the development and semantics of 
Xanadu, our project aims to discuss more on the topic. 

\subsection{C++ Templates}
\textit{C++ Templates} \cite{cppTemplate} are a way of passing the type of a 
data as a parameter so certain code can be reused. For instance, the same 
sorting algorithm can be used on multiple data types such as \textit{int} and 
\textit{double}, using templates the programmer will not need to write the same 
sorting function multiple times for different data types. 

\par
Templates are often compared to Java's \textit{Generics} \cite{javaGenerics} 
as the C++ equivalent. While this statement is mostly true, C++ templates 
differ in a big way. 
Generics only allow the template parameter to be a class, templates on the other 
hand allow the parameter to be a class, values or pointers. The ability to 
pass values into a template to create types certainly resembles dependent types.

\par
The code listing below is an example of templates with values. It defines the 
struct that represents an integer less than N. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N>
    struct LessThanN {
      int value;
      LessThanN(int x) {
        if (x < N)
            value = x;
        else
           throw ``invalid type'';
      }
    };
  \end{lstlisting}
  \caption{Struct dependent on values using C++ Templates}
\end{figure}

\par
Using the above definition it is possible to define types such as \\
\verb+LessThanN<5> ltf = LessThanN<5>(3)+, this will define a type that will has 
to be less than 5. However, certain questions arise from this definition, 

i) What will happen if the constructor is given an invalid argument? 

ii) What if the template parameter is a variable and its 
value change? 

iii) What if the value of \textit{value} change during execution?

In the subsequent text, the term ``Dependent Value'' will be used to refer to the 
value $N$ and ``Value'' will refer to the actual value held by a LessThanN type, 
i.e. the \textit{value} state in the struct. 

\subsubsection{The Intended Behaviour}
First, we observe the intended behaviour of LessThanN using the following test 
code:
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(3);
      cout << ltf.value; // Prints out 3
      return 0;
    }
  \end{lstlisting}
  \caption{Intended Behaviour of LessThanN in C++}
\end{figure}

\par
As expected, the code compiles perfectly and outputs 3 when executed.

\subsubsection{Invalid Definition of LessThanN}
In order to observe the behaviour of i), we simply have to pass in an 
invalid value into the constructor, i.e. a value greater than N, 
the test is conducted using the code below. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(10); // Error here
      cout << ltf.value; 
      return 0;
    }
  \end{lstlisting}
  \caption{Invalid Definition of LessThanN in C++}
\end{figure}

\par
Interestingly, the code compiles perfectely despite the invalid definition. 
However it fails to execute as the exeception thrown in the \textbf{else} clause 
is left uncaught. This behaviour makes it no better than an simple if statement 
in the constructor. An addition in C++ 11 was the introduction of 
\textit{constexpr} and \textit{static\_assertation}. These allow for certain 
compile time checking, however the values checked must fulfil 
the \textit{constant expression} requiremets \cite{cppConstExpr}. 

\par
Modifying the \textbf{struct} to use the code below we get compile time type 
checking. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N, int M>
    struct LessThanN {
      int value;
      LessThanN() {
        static_assert(M < N, ``type is invalid'');
        value = M;
      }
    };
  \end{lstlisting}
  \caption{LessThanN with Compile Time Type Checking in C++}
  \label{code:compileLTN}
\end{figure}

\par
Now, providing an invalid definition yields a compile time error, with the 
following: 
\verb+LessThanN<10, 12> ltf = LessThanN<10, 12>;+ 

\textbf{static\_assert failed due to requirement `12 $<$ 10' ``type is invalid''}

\subsubsection{Mutation of Template Variable}
In our previous example we have been passing integer literal as the template 
parameter for the dependent value. Often programmers are required to 
work with varied values through variables, how will this effect the behaviour? 

\par
Consider the following hypothetical situation using the struct defined in 
figure \ref{code:compileLTN}: 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>();
    n = 2; // Is ltf still well typed??
  \end{lstlisting}
  \caption{Mutating the Dependent Variable for LessThanN in C++}
\end{figure}

\par
Compiling the above code leads to a compile time error, C++ requires template 
arguments to be constant expressions. In order to use variables as template 
arguments, they have to be defined \textbf{const}. In which case the above 
situation is impossible as the variable $n$ now cannot be changed. 

\subsubsection{Changing The Value of Struct During Execution}
We've showed that it is not possible to change the dependent value in 
the program, however what if the value changes? Will a 
variable be well-typed on one line and ill-typed on the next line? 

\par
Consider the following code: 
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    const int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>(); // Well typed
    ltf.value = 10; // Now ill-typed but not caught
  \end{lstlisting}
  \caption{Mutating the value of LessThanN in C++}
\end{figure}

\par
In order to achieve our intended behaviour there has to be some form of check 
that runs throughout the lifetime of the program, currently there is no native 
support for this form of invariant. However one potential workaround as a 
programmer would be to make the LessThanN type immutable, by setting \textit{value} 
to be a \textbf{const} however that significantly limits the usability of the 
language. 

\par
We see glimpses of dependent typing in certain imperative languages, the 
examples using C++ presented above is one of them. One could argue arrays in 
Java and C++ resembles the fixed size vector however they are quite similar. In 
the subsequent chapters of this dissertation we will define a language to 
address these uncertainties. 


\section{Summary of Dependently Typed Langauge}
\begin{table} [H]
  \begin{tabular}{|p{2cm}|p{2cm}|p{10cm}|}
    \hline
    \textbf{Name} & \textbf{Paradigm} & \textbf{Notes} \\ 
    \hline
    Agda & Purely Functional & Actively developed but 
      Predominantly used for theorem proving rather than general programming. \\ 
    \hline
    Haskell & Functional & Widely used as a general purpose programming language, however not natively dependently typed. \\ 
    \hline
    Idris & Purely Functional & More general purpose compared to Agda however 
      still lacks mainstream recognition. \\
    \hline
    \textit{ATS} \cite{ATS} & Functional & Developed by Xi who created Xanadu, 
      support dependent typing however only for static terms. \\
    \hline
    \textit{F*} \cite{FStar} & Functional & Jointly developed by Microsoft 
    Research and Inria aimed at program verification. Lacks mainstream 
    programming recognition.\\
    \hline
  \end{tabular}
  \caption{Summary of Dependently Typed Language}
\end{table}

\par
The table above shows a number of languages that supports dependent typing, we 
observed that majority of the languages in this category are using the 
functional paradigm. As functional languages pale in comparison to imperative 
languages in terms of populatiry, the general awareness for dependent types 
remains low. 

\par
Our aim for this project is to i) Explore how dependent types should behave in 
an imperative language and how a language can use different mechanism to enable 
this behaviour. ii) Encourage the research into dependent types by extending the 
WHILE language \cite{whileLanguage} to support dependent typing. We chose this 
language because of its simple and familair syntax which at its core resembles 
popular languages such as C. 

\chapter{The Simple-$\Pi$ Language}
To address the uncertainties introduced in the previous chapter and provide a 
base for research in dependent types among imperative languages, we look to 
define a basic language called Simple-$\Pi$. This chapter will introduce 
the language's syntax and typing rules. The language follows 
the imperative paradigm, specifically a procedural language.

\section{Language Syntax}
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{l l l}
      \textit{Types} & $T$ & $:\text{ }int\text{ }|\text{ }bool\text{ }|\text{ }\Pi x: A.P(x)
      \text{ }|\text{ }void$\\
      \textit{Functions} & $f$ & $:\text{ }T_1, T_2,T_3...T_n\longrightarrow T_0$\\
      \textit{Operators} & $ops$ & $:$ $+$ $|$ $-$ $|$ $\wedge$ $|$ $\vee$ \\
      \textit{Expressions} & $e$ & $:$ $vals$ $|$ $x$ $|$ $x\text{ }:= e_1$ $|$ 
        $e_1$ $ops$ $e_2$ $|$ $e_1;e_2$ $|$ $f(e_1...e_n)$ \\ 
        & & \; $|$ \textbf{skip} $|$ \textbf{return} $e_1$ $|$ 
        \textbf{while} $e_1$ \textbf{do} $e_2$ \\ & & \;
        $|$ \textbf{if} $e_1$ \textbf{then} $e_2$ \textbf{else} $e_3$ $|$ 
        \textbf{let} $x = e_1$ \textbf{in} $e_2$ \textbf{end}\\
      \textit{Variables} & $vars$& $:$ $x \in {a,b,c...z}$\\
      \textit{Values} & $vals$& $:$ $\forall v \in \mathbb{Z}$ $|$ $\forall v \in \mathbb{B}$ 
        $|$ $nil$\\
      \textit{Variable Types Context} & $\Gamma$& $:$ $vars \mapsto T$\\
      \textit{Variable Values Context} & $\sigma$& $:$ $vars \mapsto vals$
    \end{tabular}
  \end{center}
  \caption{Language Syntax for Simple-$\Pi$}
\end{figure}

\par
Figure 3.1 shown above is the syntax of Simple-$\Pi$, the paragraphs below 
explains the language in details. In constrast to other literatures in this area, 
Simple-$\Pi$ is a \textit{First Order Programming Language} \cite{FOL} modelled 
after the C programming language rather than a Higher Order Language. As is the 
nature of first order programming, functions cannot be passed as arguments or 
returned as result. 

\par
In order to achieve simplicity and observe the core behaviour of dependent 
types, the language is kept at a minimum with only the necessary construct. 

\paragraph{Types} The Simple-$\Pi$ language has support the following four data types. 
\begin{itemize}
  \item The basic integer type \textit{int}
  \item The basic boolean type \textit{bool}
  \item The dependent product type, written as $\Pi x: A.P(x)$, is used to 
  define a type $B$ that depends on the variable $x$ of type A.
  \item The \textit{void} type to represent empty or null.
\end{itemize}

\paragraph{Functions}
Functions are defined in Simple-$\Pi$ as $(T_1, T_2,T_3...T_n \longrightarrow T_0)$, 
taking a up to $n$ types and returning a type. Note that functions are 
not first-class in this language, unlike a higher order 
language, functions are not types in this case, functions cannot be passed to 
other functions, nor can it return a function as a result. One can compare 
functions in Simple-$\Pi$ as functions in C or Java. 

\paragraph{Operators}
The language supports the following built in operators.
\begin{itemize}
  \item Integer addition using the $+$ operator writte in an infix notation.
  \item Integer subtraction using the $-$ operator written in an infix notation.
  \item Logical conjunction using the $\wedge$ operator written in an infix 
  notation.
  \item Logical disjunction using the $\wedge$ operator written in an infix 
  notation.
\end{itemize}

\paragraph{Expressions} The following expressions make up the language.
\begin{itemize}
  \item Variable and values represents the most basic form of an expression.
  \item The four operators are expressions operator on two other expressions $e_1$ 
  and $e_2$
  \item The assignment statement $(:=)$ assigns an expression $e_1$ to variable 
  $x$, note $x$ must have already been declared. 
  \item The \textbf{if then} and \textbf{while do} statements are the standard 
  control flow operations one would expect.
  \item The function call $f(e_1..e_n)$ invokes function $f$ with arguments 
  $e_1..e_n$ and return the result.
  \item The \textbf{skip} statement is use to indicate an empty expression and 
  does not perform any meaningful action. 
  \item The \textbf{let} statement is used to bind new variables in an 
  expression. It is modelled after the same statement in Haskell, where \textbf{let} 
  $x = e_1$ \textbf{in} $e_2$ \textbf{end} declare a variable $x$ with the value after 
  evaluating $e_1$, the variable is then available in the scope $e_2$ until 
  \textbf{end}.
  \item The \textbf{return} represents the termination of a function call and 
  end of scope. It returns an expression to the previous scope. 
\end{itemize}

\paragraph{Variables and Values} In Simple-$\Pi$, all variable are reference 
variables, as one would expect in imperative programming. We use $x$ to denote a 
variable. Variables can take values as suggested by the types, all the integer 
literals $\mathbb{Z}$, booleans $\mathbb{B}$ and $nil$ which is $void$ type. 
While values have a 1-on-1 correspondance with a type, it is obvious that a 
dependent type in the language will be a subset of either 
$\mathbb{Z}$ or $\mathbb{B}$ and as such will have already been a member of 
values.

\paragraph{Variable Values Context} Variables are mapped to values in the program 
context $\sigma$. Each reference variable is allowed to only appear once in 
the context. We use \textbf{dom}($\sigma$) to retrive the domain which represent 
the set of declared variables. We will use the notation $\sigma(x)$ 
to retrieve the value bound to variable $x$.

\paragraph{Variable Types Context} Variables are also mapped to their types 
in the type context $\Gamma$. Each variable is allowed to only appear once in 
the context. This context will be used to type check the program using the 
typing judgement in the next section.

\section{Typing Rules}
This section defines the typing rules for the Simple-$\Pi$ language.

\par
We begin by defining the typing judgement. The typing judgement used in 
Simple-$\Pi$ takes the form of the standard notation. 
\begin{center}
  $\Gamma \vdash e : T$
\end{center}
This judgement represents that expression $e$ under the context $\Gamma$ has the 
type $T$.

\par
Using the judgement rule we can easily define the fist two typing rules for base 
values \textit{int} and \textit{bool}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\forall n \in \mathbb{Z}$, $\Gamma \vdash n : int$ & 
      $\forall b \in \mathbb{B}$, $\Gamma \vdash b : bool$ & 
      $\Gamma \vdash nil : void$      
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}

\par
The remaining typing rules for the operators, statements and function 
calls are presented in figure 3.3 below. Most of the typing rule are straightforward and what one would expect from the 
type checker. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int}
        {\Gamma \vdash e_1 + e_2 : int}[(\textbf{op} $+$)] \text{ }
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int} 
        {\Gamma \vdash e_1 - e_2 : int}[(\textbf{op} $-$)] & \\
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool}
        {\Gamma \vdash e_1 \wedge e_2 : bool}[(\textbf{op} $\wedge$)] \text{ }
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool} 
        {\Gamma \vdash e_1 \vee e_2 : bool}[(\textbf{op} $\vee$)] & \\
      \inference {\Gamma \vdash e_1: bool \\ \Gamma \vdash e_2: T & \Gamma \vdash e_3: T}
        {\Gamma \vdash \text{\textbf{if }} e_1 \text{\textbf{ then }} 
        e_2 \text{\textbf{ else }} e_3: T}[(\textbf{if else})]
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: T}
        {\Gamma \vdash \text{\textbf{while }} e_1 \text{\textbf{ do }} e_2 : void} [(\textbf{while do})] & \\
      \inference {\Gamma \vdash x: T & \Gamma \vdash e_1: T} 
        {\Gamma \vdash x := e_1 : T} [($:=$)] \text{ }
      \inference {\Gamma \vdash e_1: T_1 & \Gamma, x : T_1 \vdash e_2: T_2} 
        {\Gamma \vdash \textbf{let } x = e_1 \textbf{ in } e_2 \textbf{ end }: T_2} [(\textbf{let in})] \text{ }
    \end{tabular}
  \end{center}
\caption{Basic Typing Rules for Simple-$\Pi$}
\end{figure}

\par
For a function call, we use the type judgement above. We use  
first order logic to write $f(e_1...e_n)$ as an n-nary function of 
type $T_1$ to $T_n$, then the arguments $e_1$ to $e_n$ must be of same type. 
Evaluation of the function will then satisfy the return type $T_0$.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e: T} 
        {\Gamma \vdash \textbf{return } e: T} [(\textbf{return})] \text{ }
      & \\
      \inference {f : T_1,T_2...T_n \longrightarrow T_0 \\ 
      \Gamma \vdash e_1 : T_1 & \Gamma \vdash e_2 : T_2 &...& \Gamma \vdash e_n : T_n}
        {\Gamma \vdash f(e_1...e_n): T_2}[(\textit{functions})]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Functions in Simple-$\Pi$}
\end{figure}

\chapter{Semantics for Simple-$\Pi$}
In this chapter we will be covering the semantics of Simple-$\Pi$, we will 
then build up the semantics gradually, starting from the basic 
operational semantics and eventaully formalise the behavour of certain 
non-trivial behaviour involving dependent types such as reassignments and 
arrays. Throughout the chapter we will be extending the syntax defined in the 
previous chapter in order to accomodate more features.

\section{Operational Semantics}
In this section we will define the \textit{Operational Semantics} 
\cite{operationalSemantics} for the Simple-$\Pi$ language 
using the \textit{Structural Operational Semantics} \cite{plotkinSOS} (SOS) rules. 

\par
Throughout the text we will use the following metavariables and notations. 
\begin{itemize}
  \item The metavarible $ops$ to range over all operators.
  \item $\sigma[x \mapsto v]$ updates $\sigma$ such that now $\sigma(x) = e$ and 
  $\sigma + \{x \mapsto v\}$ adds $\{x \mapsto v\}$ to $\sigma$ provided 
  initially $x \notin\textbf{dom}(\sigma)$.
  \item The metavariable $v$ to range over all values.
  \item Uppercase letters $A,B,C$ to range over all types.
  \item Greek letters ($\alpha$, $\pi$, $\upsilon$) to define local variables in 
  the formuli. 
\end{itemize}

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle v, \sigma \rangle \longrightarrow \langle \textbf{skip}, \sigma \rangle$ ($vals$ evaluation) 
      \text{ }
      \inference {x \in \textbf{dom}(\sigma)}{\langle x, \sigma \rangle \longrightarrow \langle \sigma(x), \sigma\rangle}[($vars$) evaluation] 
      & \\
      \inference {v = v_1 + v_2}{\langle v_1 + v_2, \sigma \rangle \longrightarrow \langle v, \sigma\rangle}[(op $+$)] \text{ }
      \inference {v = v_1 - v_2}{\langle v_1 - v_2, \sigma \rangle \longrightarrow \langle v, \sigma\rangle}[(op $-$)]
      & \\
      \inference {v = v_1 \wedge v_2}{\langle v_1 \wedge v_2, \sigma \rangle \longrightarrow \langle v, \sigma \rangle}[(op $\wedge$)] \text{ }
      \inference {v = v_1 \vee v_2}{\langle v_1 \vee v_2, \sigma \rangle \longrightarrow \langle v, \sigma \rangle}[(op $\vee$)]
      & \\
      \inference {\langle e_1, \sigma\rangle \longrightarrow \langle e_1', \sigma\rangle}
        {\langle e_1\text{ }ops\text{ }e_2, \sigma  
        \rangle \longrightarrow \langle e_1'\text{ }ops\text{ }e_2, \sigma' \rangle}[($ops$ $expr$)]
      & \\
      \inference {\langle e_2, \sigma\rangle \longrightarrow \langle e_2', \sigma\rangle}
        {\langle v\text{ }ops\text{ }e_2, \sigma  
        \rangle \longrightarrow \langle v\text{ }ops\text{ }e_2', \sigma' \rangle}[($ops$ $expr$ 2)]
      & \\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle}
        {\langle e_1;e_2, \sigma \rangle \longrightarrow \langle e'_1;e_2, \sigma' \rangle}[($e_1;e_2$)]
      & \\
      $\langle \text{\textbf{skip}};e2, \sigma \rangle \longrightarrow \langle e2, \sigma \rangle$ (\textbf{skip})
      & \\
      $\langle \text{\textbf{if }\textit{true}} \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle e_1, s\rangle$ (\textbf{if} true)
      & \\
      $\langle \text{\textbf{if }\textit{false}} \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle e_2, \sigma\rangle$ (\textbf{if} false)
      & \\
      \inference {\langle e, \sigma\rangle \longrightarrow \langle e', \sigma \rangle}
        {\langle \text{\textbf{if }} e \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle \textbf{if } e \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle}[(\textbf{if} $expr$)] 
      & \\
      $\langle \text{\textbf{while }} c \text{\textbf{ do }} e, \sigma \rangle \longrightarrow \langle 
        \text{\textbf{if }} c \text{\textbf{ then }} e;
        (\text{\textbf{while }} c \text{\textbf{ do }} e) \text{\textbf{ else }} \textbf{skip}, \sigma \rangle$ (\textbf{while do})
      & \\
      \inference {x \in \textbf{dom}(\sigma)} 
      {\langle x := v, \sigma \rangle \longrightarrow \langle \text{\textbf{skip}}, \sigma[x \mapsto v] \rangle} [(assignment $vals$)] \text{ }
      & \\
      \inference {\langle e, \sigma \rangle \longrightarrow \langle e', \sigma' \rangle} 
      {\langle x := e, \sigma \rangle \longrightarrow \langle x := e', \sigma'\rangle} [(assignment $expr$)] \text{ }
     \end{tabular}
  \end{center}
  \caption{Operational Semantics for Simple-$\Pi$}
\end{figure}

\subsection{Scoping}
Scoping has an important role in imperative languages, variables can be defined 
in scopes and are unavailable once outside. While there are many different 
variables that does not follow this rule, such as static variables, global 
variables and reference variables. For simplicity, we will focus initially on local 
variables. 
\par
In order to help us formalise the notion of scopes we define a new notation, 
$\longrightarrow^{*}$ as a multi-step evaluation. The evaluation rule 
$\langle e, \sigma \rangle \longrightarrow^{*}  \langle v, \sigma' \rangle$ simply 
evaluate the expression $e$ one or more times until it evaluates to $v$. 

\par
Using a multi step evaluation, We can easily define the scoping rules as shown 
below.
  
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\sigma' = \sigma + \{x \mapsto v\} & x \notin \sigma \\ \langle e_1, \sigma' \rangle \longrightarrow^{*} \langle v, \sigma'' \rangle} 
      {\langle \text{\textbf{let }}x = v \text{\textbf{ in }} e_1 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle v, \sigma\rangle} [(\textbf{let in} values)] 
      & \\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma'\rangle} 
      {\langle \text{\textbf{let }}x = e_1 \text{\textbf{ in }} e_2 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle \text{\textbf{let }}x = e_1' \text{\textbf{ in }} e_2\text{\textbf{ end}}, \sigma' \rangle} 
      [(\textbf{let in} $expr$)]
    \end{tabular}
  \end{center}
  \caption{Scoping Rules for Simple-$\Pi$}
\end{figure}

\par
Figure 4.2 above defines the scoping rules for Simple-$\Pi$.

\par
The \textbf{let in} statement opens a new scope $\sigma'$ which 
assigns $x$ the value $v$, the in expression, $e_1$ is then evaluated with the 
new context using the multi-step evaluation until it no longer can be evaluted, 
the resulting expression is passed back to the original context.

\par
The multi-step evaluation provides us to much more easily express scoping rules, 
the alternative would be to model an explicit call stack, which complicates the 
formulas.

\subsection{Functions}
Functions in almost all imperative language operates in their own scope. In many 
cases they do not have the access to the local variables out of their scope however 
one can pass data using arguments. Functions in Simple-$\Pi$ are call by values, 
changing the value of an argument in the function does not change the value in 
the outside scope. Our multi-step evaluation rule defined previously helps us 
evaluate functions in their own scope. 

\par
In order to define the operational semantics of a function we will need to 
specify the function body. We define a mapping \textit{fns} $: f \mapsto ((x_1, x_2...x_n), e)$, 
using this mapping allows us to retrieve the body of a function. Since functions 
definition cannot be changed at runtime, this does not need to be part of the 
configuration and can be consider as a static context.

\par
We begin defining the evaluation rules for functions, first we define the 
operational semantics for the \textbf{return } statement which simply evaluates 
to the value returned. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle \textbf{return } v, \sigma \rangle \longrightarrow \langle v, \sigma \rangle$ (\textbf{return} value)
      &\\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle} {\langle \textbf{return } e_1, 
      \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle} [(\textbf{return} nil)]
    \end{tabular}
  \end{center}
  \caption{Evaluation Rules for Return Statement}
\end{figure}

\par
We can then evalute the function body which using the multi-step evaluation.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {((x_1..x_n), e_{body}) = \textit{fns}(f) 
        \\ \sigma' = \{x_1 \mapsto v_1 ... x_n \mapsto v_n\} & \langle e_{body}, \sigma' \rangle \longrightarrow^{*} \langle v, \sigma'' \rangle}
      {\langle f(v_1...v_n), \sigma, \rho' \rangle \longrightarrow \langle v, \sigma \rangle} [(function call vals)]
      & \\
      \inference {\langle e_k, \sigma \rangle \longrightarrow \langle e_k', \sigma' \rangle}
      {\langle f(v_0...v_{k - 1},e_k...e_n), \sigma \rangle \longrightarrow \langle f(v_0...v_{k - 1}, e_{k}'...e_n), \sigma' \rangle} [(function call expr)]
    \end{tabular}
  \end{center}
  \caption{Functions Semantics for Simple-$\Pi$}
\end{figure}

\par
The first rule (function call vals) resembles the evaluation rule for 
\textbf{let in} but it differs in a crucial way, in the new context for a 
function call, none of the variabels from the previous scope transfer over, only 
those of the argument are copied. We then evaluates the function body until it 
evaluates to a value which is then returned to the caller's context. 

\par
The second rule (function call $expr$) evaluates the expression passed into the 
function as arguments. Our language defines a strict behaviour that all 
arguments are evaluated in the order they are passed in, i.e. from left to right. 

\section{Dependent Types Semantics}
Programming languages often have a wide range of features, often the team behind 
the language have to put extensive thought into the design decisions. As there 
are often multiple way to handle a certain feature, rarely are there a definite 
answer to which is the most optimal.

\par
This seemingly undecideable problem is known as \textit{feature interaction} 
\cite{featInteract}, it describes the problem in some situations multiple 
features would modify the behaviours of each others. The same applies to 
dependent types, which is a feature itself. For instance, the inclusion of dependent types 
would modify the behaviour of assignments and vice versa. This section 
will cover the different ways of handling dependent types and they interact with 
other features.

\subsection{Hoare Logic}
In order to formalise the specification of our language we opted to use 
\textit{Hoare Logic} \cite{hoare}. The \textit{Hoare Triple} is defined as follows: 

\begin{figure}[H]
  \begin{center}
    $\{P\}C\{Q\}$
  \end{center}
  \caption{Hoare Triple}
\end{figure}
The Hoare triple simply expresses that given precondition $P$ holds then after executing $C$ 
and $C$ terminates, the postcondition $Q$ will hold.

\par
We chose Hoare Logic as our preferred system because of its simple to understand 
notation. While Hoare Logic is a powerful tool that can become complex when 
reasoning about the correctness of a program we are mainly interested in using 
the Hoare notation as a tool for specifications. We will be using the 
precondition to specify in which state the programmer is allowed to perform 
certain commands and what must be the resulting state after execution. While the 
same formalisation can be achieved using Structures Operational Semantics, the 
Hoare Triple provides a much more concise notation. 


\subsection{Defining Dependent Types with Variable}
Consider the uncertainty of using variables to define dependent types. For 
instance: 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let }$y\text{ }:\text{ } int = 10$ \textbf{ in } \\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y : int. \{i : Int\text{ }|\text{ }i < y\}$; \\ 
    \tab\textbf{let }$x\text{ }:\text{ }BoundedIntY = 4$ \textbf{ in }$y := 5$\textbf { end} \\
    \textbf {end}
  \end{tabs}  
  \caption{Mutation to Variable Depended On}
\end{figure}

\par
How would this behaviour work in practice? Recall from chapter 2 we proposed the 
question of what should happen when the value bound to the variable change. In 
this subsection we will define different methods to handle this behaviour and 
formalise their specification.

\par
First we need to introduce a new expression for type definition, in the example 
above we used the expression (\textbf{typedef} $x = T$) to denote a new type. 
In our example, we mean 
that a new type named $BoundedIntY$ is created. We need to add this construct 
into our syntax. In our current syntax, we have a context for variables and 
values, We would also need a similar mapping for types, We use $\tau$ to 
represent the type name map. 

\par
The syntax is extended by adding the following: 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expression} & $e$ & $:$ ... $|$ \textbf{typedef }$x = T$ \\
      \textit{Type Name Context} & $\tau$& $:$ $vars \mapsto T$ \\
    \end{tabular}
  \end{center}
  \caption{Type Name Context Extension for Simple-$\Pi$}
\end{figure}

\par
We then define the operational semantics: 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {x \notin \text{\textbf{dom}}(\sigma)}{\langle \textbf{typedef }x = A, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \text{\textbf{skip}}, \sigma, \tau + \{x \mapsto A\}\rangle}[(\textbf{typedef})] \text{ }    
    \end{tabular}
  \end{center}
\end{figure}

\par
The operational semantic above simply adds a new type definition with name $x$ 
into the Type Name context $\tau$. Importantly, the variable $x$ cannot have 
already been defined as a value variable n $\sigma$. 


\subsubsection{Complete Immutability}
The main issue one encounters when associating dependent types with imperative 
languages is the presence of mutability and assignments. The obvious way to 
work around this problem is to remove the ability to make changes to the state 
of the program. In other words, all defined variables are constant. 

\par
While this approach does allow for a type system that depends on values, it is 
only partial dependent typing as the values depended on has to be available at 
compile time whereas a fully dependently typed language is able to depend on 
value at runtime.

\par
The approach proposed in this subsection does not encompass the intended behaviour we 
sought after however we decided to formalise it for completeness and serves as 
a building block for our language. 

\par
To achieve complete immutability immutability we can simply ``disable'' the 
reassignment feature. We could remove the assignment operator $(:=)$ from our 
syntax and will achieve immutability. This will avoid any complications 
regarding dependent types as 
if they are well typed during definition it will stay well typed. 

\par
Using this approach does definitely resolves the uncertainty the usability of 
the language is poor. Imperative programming relies on state changes, forbidding 
that go against the paradigm. 

\subsubsection{Immutability For Dependent Variables}
We observe that only variables associated with dependent typing needs to be 
immutable to prevent any uncertain behaviours. To improve the flexibility of our 
language, we could loosen the restrictions by having only the depenent variables 
be immutable. We introduced a new construct in our syntax to handle immutable 
variable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ }
        \textbf{consts }x := e_1 \textbf{ in }e_2\textbf{ end}$ \\
      \textit{Immutable Variables} & $\Sigma$ & $:$ $vars$ \\
    \end{tabular}
  \end{center}
  \caption{Immutable Variable Context for Simple-$\Pi$}
\end{figure}

The set $const$ is simply a set of variables that are deemed to be immutable. 
One construct an immutable variable as though they are defining a mutable 
variable, using the \textbf{const in} statement. We define the semantics as 
below, we will use the following notation $x \in \Sigma$ to state that $x$ is 
immutable.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\langle e_1, \sigma', \Sigma' \rangle \longrightarrow^{*} \langle v, \sigma'', \Sigma'' \rangle \\ \sigma' = \sigma + \{x \mapsto v\} & x \notin \sigma & \Sigma' = \Sigma \cup \{x\}} 
      {\langle \text{\textbf{const }}x = v \text{\textbf{ in }} e_1 \text{\textbf{ end}}, \sigma, \Sigma \rangle 
      \longrightarrow \langle v, \sigma, \Sigma \rangle} [(\textbf{let in} values)] 
      & \\
      \inference {\langle e_1, \sigma, \Sigma \rangle \longrightarrow \langle e_1', \sigma', \Sigma \rangle} 
      {\langle \text{\textbf{const }}x = e_1 \text{\textbf{ in }} e_2 \text{\textbf{ end}}, \sigma, \Sigma \rangle 
      \longrightarrow \langle \text{\textbf{const }}x = e_1' \text{\textbf{ in }} e_2\text{\textbf{ end}}, \sigma', \Sigma \rangle} 
      [(\textbf{const in} $expr$)]
      & \\
      \inference {x \in \textbf{dom}(\sigma) & x \notin \Sigma} 
      {\langle x := v, \sigma \rangle \longrightarrow \langle \text{\textbf{skip}}, \sigma[x \mapsto v] \rangle} [(assignment $vals$)] \text{ }
    \end{tabular}
  \end{center}
  \caption{Immutable Variables Rules for Simple-$\Pi$}
\end{figure}

\par
Once we defined the ability to define immutable variables, we can utilise it in 
our type definition. First we refine our specification for \textbf{typedef} 
with regards to dependent types using the evaluation rules and Hoare Logic 
defined below. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {a \notin \text{\textbf{dom}}(\sigma) & x \in \Sigma & a \notin \textbf{dom}(\tau)}{\langle \textbf{typedef }a = \Pi x : A.P(x), 
      \sigma, \Sigma, \tau \rangle \longrightarrow 
        \langle \text{\textbf{skip}}, \sigma, \Sigma, \tau + \{a \mapsto \Pi x : A.P(x)\}\rangle}[(\textbf{typedef}) $\Pi$] \text{ }    
      & \\
      $\{a \notin \textbf{dom}(\tau) \wedge a \notin \textbf{dom}(\sigma) \wedge x \in \Sigma\}\textbf{typedef }a = \Pi x. P(x)
        \{\tau(a) = \Pi x. P(x)\}$
    \end{tabular}
  \end{center}
  \caption{Dependent Type Definition Rules}
\end{figure}

\subsubsection{Passing by Value}

If we further analyse our design, we notice that if our dependent type is 
constructed using a value then we would not have the problem of variable change. 
In languages such as C/C++, \textit{pass by value} \cite{pbv} is a way of 
passing a parameter into a function in a way that any modification to the 
parameter in the function does not reflect changes outside and vice versa. The 
same cocept is used for functions in Simple-$\Pi$.

\par
The similar approach can be taken in our definitions for dependent types. For 
instance, taking the example in figure 4.2, if the variable $y$ in the dependent 
type function is different from the variable $y$ in the program state, then any 
changes to the variable $y$ will not effect the type definition and the program 
will stay well typed.
 
\par
In subsection 4.1.2 we defined the functions' evaluation rules using scopes. 
We will be adapating a similar approach for our dependent type functions. If 
$\Pi x : A. P(x)$ is a dependent type that depends on $x$ of type $A$ then we have  
$\Pi x : A.P(x) \in $ \textit{dfns}, \textit{dfns} behaves like \textit{fns}, 
holding the definitions of all dependent type functions. The only difference 
here is that a dependent type only takes a singular parameter. 

\par
We first require modification to our \textbf{return} statement, which at the 
moment only returns expressions, as dependent type functions return types, we 
need to accomodate that. We define a special return statement, \textbf{return } 
$T$, this statement is only to be used with dependent type function. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expressions} & $e$& $:$ $\textbf{return }T$ \\
    \end{tabular}
  \end{center}
  \caption{Return statement for Types in Simple-$\Pi$}
\end{figure}

We define the typing rule for this return statement using the idea of 
\textit{universes} \cite{martinLof} 
in type theory, using the notation $\Gamma \vdash A : Type$ we say that $A$ is a 
type. 

We define the formation rule for a dependent type as so: 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash A : Type \\ \Gamma, x : A \vdash P(x) : Type} 
        {\Gamma \vdash \Pi x. P(x) : Type}[($\Pi$ F)] \text{ }
    \end{tabular}
  \end{center}
  \caption{Typing Rules for the Dependent Product Type}
\end{figure}

\par
The dependent product type formation rule ($\Pi$ F) defines the rules in order 
for a dependent product type to be formed. Similarly, we define the 
type judgement for a \textbf{return }$T$ statement, it 
returns a type. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference{\Gamma \vdash A : Type}{\Gamma \vdash \textbf{return } A : Type} [(\textbf{return }T)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}


\par
Using the return statement above, when one define a dependent type, our 
semantics will evaluate the function until a type is returned. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {((x_1), e_{body}) = \textit{dfns}(\Pi v : A.P(v)) 
      \\ \sigma' = \{x_1 \mapsto v\} &  \langle e_{body} , \sigma, \tau \rangle \longrightarrow^{*} \langle \textbf{return }T, \sigma, \tau \rangle}
      {\langle\textbf{typedef } x = \Pi v : A.P(v), 
      \sigma, \rho, \tau \rangle \longrightarrow 
        \langle \textbf{typedef } x = T, \sigma, \tau \rangle}[(\textbf{typedef}) $\Pi$]  
    \end{tabular}
  \end{center}
  \caption{Evaluation of Dependent Type Functions}
\end{figure}

\par 
The rule above formalise the semantics for dependent type definitions in 
Simple-$\Pi$. The dependent type function is evaluated in its own scope. Note 
that in our evalutation the \textbf{typedef} statement is being written 
repeatedly such that we are able to pass back \textbf{return} $T$ to 
\textbf{typedef}. If we were to use the same evaluation as our previous return 
statement then $T$ would have to be an expression and could potentitally results 
in further complications. 

\par
This semantic allow the language to allow us to define types using variable 
whose value are available at runtime, i.e. a non constant variable. It provides 
more flexibility in comparison to C++ templates but it is still has limitations. The 
programmer might sometimes be looking for dependent types whose definitions 
changes with the value of the variable. 

\subsubsection{Dynamic Dependent Types}
In this subsection we will be presenting an approach to handling dependent types 
in imperative languages called \textit{Dynamic Dependent Types}. It is a type 
that will allow the definition of dependent types to change during runtime and 
still guarantees a well-typed program. 

\par
Notice that in figure 4.5, the variable $x$ is 
of type $BoundedIntY$ and has the value 4 which is well typed. In the next line, 
the value of $y$ is reassigned the value 5. In this approach, rather than having 
no effect on the type definition, the type of $BoundedIntY$ changes with the 
value $y$, being now bounded to $5$. In our example, $x$ is still well typed so 
everything is valid. 


\par
However, consider the following examples with certain values replaced. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let }$y\text{ }:\text{ } int = 10$ \textbf{ in } \\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y. \{i : Int\text{ }|\text{ }i < y\}$; \\ 
    \tab\textbf{let }$x\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in }$y := 5$\textbf { end }\textit{// Error}\\
    \textbf {end}
  \end{tabs}  
  \caption{Ill-Typed Dynamically Changing Dependent Types}
\end{figure}

\par
If the reassignment of $y$ causes $x$ to be ill-type as demonstrated in the 
example above, then the type checker should flag it at compile time. 

\par
In order to do this we need will need to type check all variables against its 
type after an assignment. We can use the typing judgement to perform the 
type checking by only allowing assignment if the all variables of a dependent 
type that depnds on $x$ holds after reassignment of $x$.

\par
We modify the typing judgement for assignment by adding a new condition:

\begin{figure}[H]
  \begin{center}
   \begin {tabular} {c} 
     \inference {\Gamma \vdash x: T & \Gamma \vdash v: T 
     \\ \Gamma \vdash \forall \alpha : \Pi x. P(x)\text{ }s.t.\text{ }\alpha : \Pi v. P(v)} 
          {\Gamma \vdash x := v : T} [($:=$ dynamic dependent types)] \text{ }
    \end{tabular}
  \end{center}
  \caption{Dynamic Dependedent Type Reassignment Rule}
\end{figure}

The rule above states that for all $\alpha$ of a type $\Pi x.P(x)$ it will be 
well typed for $\Pi v.P(v)$, the new value of $x$. Our logic here works simply 
by using the concept of type membership, which similar to the the 
concept of set membership in set theory \cite{RussellMathematicalLA}. 
The above statement can simply be rewritten in logic as 
$\forall \alpha \in A\text{ }s.t.\text{ }\alpha \in B$.

\par
Notice that our current value variable context does not 
provide the type that a variable possess, we only have the value. 
In order to formalise the behaviour in Hoare Logic, we will need to typing 
information of a variable. We are able to retrive this information from the 
Variable Type Context $\Gamma$, however we for a better and more concise 
notation we decided to use the syntax defined below.

\par
First we modified the value variable context as shown below:
 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Variables Values Context} & $\sigma$& $:$ $vars \mapsto vals : T$ 
    \end{tabular}
  \end{center}
  \caption{Extended Value Variable Context with Type}
\end{figure}

This means that a varible now maps to a value with type $T$. The notation of 
$\sigma(x)$ to retrieve a value used in previous semantics still hold, now we 
can write $\alpha : \beta = \sigma(x)$ which gets $\alpha$ the value of $x$ 
and $\beta$ the type of $x$. This notation allows us to apply the universal 
quantifier.

\begin{figure}[H]
  \begin{center}
    $\forall \gamma \in \mathcal{P}(\sigma).$\\
    \footnotesize$\{\gamma = \{\alpha : \beta \in \sigma\text{ }|\text{ }\beta = 
    \Pi x : A. P(x)\}\}x:= e\{\sigma(x) = e \wedge 
    \forall \alpha : \beta \in \gamma\text{ }s.t.\text{ }\beta = \Pi x : A. P(x)\}$ 
    \normalsize
  \end{center}
  \caption{Dynamic Dependedent Type Reassignment Rule}
\end{figure}


\par
The Hoare Logic above reiterates this behaviour by stating that all values $\alpha$ with 
type $\Pi x : A.P(x)$ in the state will have their typing updated with the new value 
of $x$.

This section presented multiple solution to achieving reassignment in a 
dependently typed language. While all of the proposed solutions have their 
merits, we decided to use the final approach of Dynamic Dependent Types in our 
language going forward. We believe that approach provides the most usable 
implementation of dependent types and serves best as a research topic as 
introducing new features could present interesting problems. 

\section{Pointers and Vectors}
In this next section we will be presenting dependently typing with regards to 
arrays. The introduction of arrays ties in closely with pointers and aliasing, 
the behaviours of these additional features will be discussed and specified in this 
section.

\subsection{Heap Memory Location}
In programming languages, there are three different types of memory allocation, 
static, stack and heaps \cite{heapVsStack}. While we have not explicitly 
discussed our memory management model, it is rather obvious that Simple-$\Pi$ 
operates on a stack based model. It is apparent in the behaviour of locals 
variable which are inaccesible once out of scope as discussed in subsection 
4.1.1. While arrays can be allocated on the stack, since we are dealing 
with dependent types and arrays are likely to be dynamic, we have decided to use heap 
memory to handle arrays. 

\subsubsection{Syntax Extension}
First we will have to extend our syntax to accomodate these new features, the 
new syntax is shown in figure 4.14 below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Types} & $T$& $:$ $...\text{ }|\text{ }T\text{ \textit{ref }}|\text{ } T \text{ }array$ \\
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ }e_1[e_2]\text{ }
        |\text{ }e_1[e_2] := e_3\text{ }|\text{ }\textbf{size}(e_1)$ \\
        & & \; $|\text{ }\textbf{newarray}(e_1, T)\text{ }|\text{ }!e_1\text{ }|\text{ \textbf{new}}(T)$ \\
     \textit{Values} & $vals$& $:$ $...\text{ }|\text{ }h\text{ }|\text{ }(h_0,h_1...h_n)$ \\
     \textit{Heap} & $\Delta$& $:$ $h \in \{h_1,h_2, h_3...\} \mapsto vals$\\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$\Pi$}
\end{figure}


\par
We introduced two new types, $T$ \textit{ref} is a reference type, it behaves 
like a pointer in C/C++, like pointers, references are typed and its value is a heap address. 
$T$ $array$ is an array type. Like most languages, arrays are typed 
and all elements in the array must be of type $T$.

\par
We introduced the following expressions into the language:
\begin{itemize}
  \item $e_1[e_1]$ to index an element in an array, like C/C++, arrays are 
  0-indexed. $e_1[e_2] := e_3$ to assign values into arrays.
  \item \textbf{size}$(e_1)$ to retrive the size of an array.
  \item \textbf{newarray}$(e_1, T)$ to allocate a new array of $T$ that is of 
  \textbf{size}$(e_1)$.
  \item $!e_1$ to dereference the $T$ \textit{ref} represented by $e_1$.
  \item \textbf{new}($T$) to allocate and return a $T$ \textit{ref}.
\end{itemize}
\par
For simplicity, we have ommited the need for manual memory management and memory 
deallocation.

\par
Values are extended such that it now includes heap address $h$ or in the case of 
an array, a tuple of head addresses $(h_0...h_n)$. 

\par
Finally, Heap $\Delta$ is a set of heap addresses $\{h_0, h_1, h_2...\}$ currently in use, 
realisticly $\Delta$ will be a finite mapping however, in our case we are assuming 
$\Delta$ be an infinite set of heap addresses as we consider cases of 
insufficient memory out of scope for our project. We use the notation, $\Delta(h)$ 
to get the value held at a particular heap address. 

\subsubsection{Typing Rules}

We first define the base types for heap address and array values. As it is with 
many languages, the $nil$ type is a reference type.
\begin{center}
   $\Gamma \vdash nil : T\text{ }ref$ ($nil$ reference type)
\end{center}

\par
We define the type of a heap address simply by checking its type of reference. 
For an array, all heap addresses has to be of the same type. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma(h) = T\textit{ ref}} 
        {\Gamma \vdash h : T\text{ }ref}[(heap address type)]
      & \\
      \inference {\Gamma(h_0) = T\textit{ ref} & \Gamma(h_1) = T\textit{ ref} &...& \Gamma(h_n) = T\textit{ ref}} 
        {\Gamma \vdash (h_0,h_1...h_n) : T\text{ }array}[($array$ type)] 
    \end{tabular}
  \end{center}
  \caption{Typing Rules for the Array and Ref Type}
\end{figure}

\par
We then define the rules for the expressions regarding array indexing and 
pointer dereferencing. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1 : T\text{ }array & \Gamma \vdash e_2 : int} 
        {\Gamma \vdash e_1[e_2] : T}[($array$ indexing)]
      & \\
      \inference {\Gamma \vdash e_1 : T\text{ }array & \Gamma \vdash e_2 : int \\ \Gamma \vdash e_3 : T} 
        {\Gamma \vdash e_1[e_2] := e_3 : T}[($array$ mutation)] 
      & \\
      \inference {\Gamma \vdash e_1 : T\text{ }array} 
        {\Gamma \vdash \textbf{size}(e_1) : int}[(\textbf{size} of $array$)]
      & \\
      \inference {\Gamma \vdash e_1 : int} 
        {\Gamma \vdash \textbf{newarray}(e_1, T) : T\text{ }array}[(\textbf{newarray} formation)]
      & \\
      \inference {\Gamma \vdash e_1 : T\text{ }ref} 
        {\Gamma \vdash !e_1 : T}[(dereferencing)]
      & \\
      $\Gamma \vdash \textbf{new}(T) : T\textit{ ref}$ (\textbf{new} reference)
    \end{tabular}
  \end{center}
  \caption{More Typing Rules for the Array and Ref Type}
\end{figure}

\subsubsection{Operational Semantics}
Lastly, we need to define the operational semantics for the new addition. We 
begin by defining the SOS rules for pointers. As the reduction rules for 
expressions are largely similar to before we will be ommiting them and only 
focus on the value itself. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h_1 \in \textbf{dom}(\Delta) & v = \Delta(h_1) & v \neq nil}
      {\langle !h_1, \sigma, \rho, \tau, \Delta \rangle \longrightarrow \langle v, 
      \sigma, \rho, \tau, \Delta \rangle} [(Pointer dereferencing)]
      & \\
      \inference {h_1 \in \textbf{dom}(\Delta) & \Delta' = \Delta \uplus \{h_1 \mapsto v_1\}}
        {\langle h_1 := v_1, \sigma, \rho, \tau, \Delta \rangle \longrightarrow \langle v_1, 
        \sigma, \rho, \tau, \Delta' \rangle} [(Pointer assignment)]
      & \\
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta 
        \uplus \{h \mapsto nil\}}
        {\langle \textbf{new}(T), \sigma, \rho, \tau, \Delta \rangle \longrightarrow \langle h, 
        \sigma, \rho, \tau, \Delta' \rangle} [(Pointer allocation)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers}
\end{figure}

\par
Pointer allocation simply allocates a new heap address and add it to the heap, 
we use the type $nil$ to represent the default value. 


\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {v_0 = (h_0,h_1...h_n) & v_1 >= 0 & v_1 <= n} 
        {\langle v_0[v_1], \sigma, \rho,\tau,\Delta \rangle 
          \longrightarrow \langle !h_{v_1}, \sigma, \rho, \tau, \Delta \rangle} [($array$ indexing)]
      & \\
      \inference {v_0 = (h_0,h_1...h_n) & v_1 >= 0 & v_1 \leq n & \Delta' = \Delta \uplus \{h_{v_1} \mapsto v_2\}} 
        {\langle v_0[v_1] := v_2, \sigma, \rho,\tau,\Delta \rangle 
          \longrightarrow \langle v_2, \sigma, \rho, \tau, \Delta' \rangle} [($array$ mutation)]
     & \\
     \inference {v_0 = (h_0,h_1...h_{v_1}) \\ \Delta' = \Delta \uplus \{h_0 \mapsto nil, h_1 \mapsto nil,...h_{v_1} \mapsto nil\}} 
        {\langle \textbf{newarray}(v_1, T), \sigma, \rho,\tau,\Delta \rangle 
          \longrightarrow \langle v_0, \sigma, \rho, \tau, \Delta' \rangle} [($array$ creation)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Arrays}
\end{figure}





\chapter{Related Work}

\chapter{Further Work}

\chapter{Summary and Conclusions} 


\appendix
\singlespacing

\printbibliography

\end{document}
