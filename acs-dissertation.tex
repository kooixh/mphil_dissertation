%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 

\documentclass[a4paper,12pt]{report}
%TC:group tabular 1 1


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Xiu Hong\ Kooi\xspace}
\def\authorcollege{Wolfson College\xspace}
\def\authoremail{xhk20@cam.ac.uk}
\def\dissertationtitle{Exploring Refinement Types in a Mutable Environment}
\def\wordcount{0}


%\usepackage[dvips]{epsfig,graphics} 
\usepackage{epsfig,graphicx,verbatim,parskip,tabularx,setspace,xspace}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{semantic}
\usepackage{float}

\usepackage{tabto}

\newenvironment{tabs}[1]
 {\flushleft\TabPositions{#1}}
 {\endflushleft}

\usepackage[british]{babel}
\usepackage[%
  backend=bibtex      % biber or bibtex
%,style=authoryear    % Alphabeticalsch
 ,style=numeric-comp  % numerical-compressed
 ,sorting=anyt        % no sorting
 ,sortcites=true      % some other example options ...
 ,maxbibnames=99
 ,block=none
 ,indexing=false
 ,citereset=none
 ,isbn=true
 ,url=true
 ,doi=true            % prints doi
 ,natbib=true         % if you need natbib functions
]{biblatex}
\usepackage{biblatex}
\addbibresource{./dissertation.bib}


%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 

\textit{Type systems} \cite{typesystem} have been one of the most extensively researched field in 
Programming Languages. They act as a way from improving the reliability of a 
language by enforcing rules, preventing operations being applied on 
incompatible data. Type systems can be broken down into multiple categories but 
two of the most well known are \textit{Static} \cite{staticTyping} and 
\textit{Dynamic} \cite{dynamicTyping} typing. Mainstream programming 
languages such as \textit{Java} \cite{java}, \textit{C} \cite{c} and \textit{C++} \cite{cpp} 
uses the former while languages like \textit{Python} \cite{python} and 
\textit{JavaScript} \cite{js} uses the latter. 
Over the years, programming languages have included more powerful and flexible 
type systems, languages like \textit{C\#} \cite{cSharp} and \textit{Go} \cite{goInferenceType} allow 
\textit{type inference} \cite{inferenceType}, using a feature called \textit{Reflection} 
Java and Python can even achieve \textit{Duck Typing} \cite{javaDuckType}.

\par
Types are a fundamental way of showing a program's correctness, the use of types 
restricts and therefore eliminates illegal program at compile time. However, a 
even a well-typed program still leaves room for various errors such as 
\begin{enumerate}
  \item {\textbf{Out of index access}} In the case of arrays or buffers, the type checker 
  can guarantee that the programmer is using an integer to index elements. 
  However it makes no guarantee that the index is indeed within the valid range. 
  \item {\textbf{Arithmetic errors}} An arithmetic operation can type check that it is 
  indeed operating on numerical values however it is unable to verify the 
  legality. Forbidden arithmetic operations such as as zero divisors or square 
  root of a negative number cannot be type checked. 
  \item {\textbf{Logical error}} Finally, a type checker cannot verify any logical 
  mistakes made by the programmer. Mistakes are inevitable, while the programmer 
  can ensures that the arugments passed to a function are two integers, there is 
  no way for the type checker to ensure that the result is the sum of the two. 
\end{enumerate}

\par
\textit{Dependent Types} \cite{depenTypeAtWork} looks to be a potential solution 
to the problem, dependent types allow the programmer to create types whose 
definition depends on values. A type system that provides such refined 
control over the values it can take unlocks possibility that are previously 
unavailable such as domain-specific type checking.

\par
A further restriction on dependent types can be found in \textit{Refinement 
Types} \cite{refinementTypes} where one is allowed to specify subtypes 
of existing types. A refinement types is constrained by a decidable predicte, 
bringing a better ease of programming. While dependent types are significantly 
more powerful than refinement types, the latter provides a good balance between 
expressiveness and ease of use.

\section{Overview of Refinement Types}
In this section we will discuss at a very high level the behaviour one would 
expect from refinement types and the benefits of using refinement types. 

\begin{figure}[h] 
  \begin{lstlisting}[mathescape=true] 
  type EvenInt = {v : int | 4 % 2 == 0}
  
  function f(int x) {
    if (x % 2 != 0) 
      throw error ``x has to be even''
    ...
  }
  
  function refined_f(EvenInt i) {
    ...
  }
  \end{lstlisting}
  \caption{Example of Refinement Typed Language}
  \label{code:refine}
\end{figure}

\par
Consider the psedocode below in figure \ref{code:refine}, the function 
\textit{f} checks whether the argument $x$ is even, if it 
is not then it throws a runtime error. Alternative, the function \textit{refined\_f} 
achieves the same through the use of refinement types. \textit{EvenInt} is a 
integer type whose value is guaranteed to be even. If one passes an odd integer 
to the function it will be caught automatically either at compile time or 
runtime. 

\par
Refinement types allows programmer to define much richer and expressive types 
which can be type checked at run time if not compile time. The addition 
of refinement types allow for safer code as it is able to guarentee certain 
properties. Furthermore, using refinement types eliminates the need for many 
trivial error handling code. Around 4\% of code in every program is 
dedicated to error handling \cite{errorHandlingCode}, refinement types will be 
able to reduce the numbers and allow the programmer more time to 
focus on writing the logical part of the code, indirectly 
leading to more robust codebases.

\section{Motivation}
As much as we have studied about type systems, dependent and refinement types 
remains uncommon in the industry. While the theory of dependent types has been 
established several decades ago, only a small number of languages has 
integrate full dependent type support, most of them being functional languages. 
Similarly, refinement types remains mostly a research problem, while several 
programmers have attempted to bring refinement types to the mainstream the  
work remains niche. 

\par
The expressive nature of dependent types allow one to 
define complex mathematical assertations and hence lends itself to 
theorem proving systems. Mutliple functional languages such as \textit{Epigram} 
\cite{epigram} and \textit{Agda} \cite{agda} has 
built in support for dependent typing. However 
mainstream languages such as Java and C++ does not get the luxury. In chapter 2 of 
this dissertation we will be providing an in depth analysis of the current state 
of dependent types in programming languages and answer why dependent types are 
not more prominant in languages, in particular imperative languages.

\par
We note that one of the complexity of adopting dependent and refinement types 
in an imperative programming languages is the presence of mutation. Imperative 
languages relies on statements that changes the state of the program, these 
changes has the potential making refinement types ambiguous. For instance, if 
one defined a refinement type as $\{\upsilon : int\text{ }|\text{ }\upsilon < N\}$, 
what is the behaviour if the value of $N$ changes?

\par
Past research has studied and shown the feasibility of a dependently typed 
imperative language, however these studies focused on expressing the semantics 
of an imperative language and dependent types are often highly 
technical and complex, requiring prerequisite knowledge in the literature. While 
we find these work novel and made important advancedments in the field, 
they fail to caputure how refinement types could relate to 
mainsteam programming languages.

\par
We argue that the the research in the area of dependent types and refinement 
types can be made more accessible. Dependent Type systems presented in 
existing papers often assumes full knowledge of \textit{The Lambda Calculus} 
\cite{lambdaCalculus} and uses the concept of \textit{Monads} \cite{monads} 
for state changes. The semantics of the $\lambda$-calculus is simple and naturally 
relates to functional programming languages, however, when one tries to model 
imperative programming by extending the calculus, we begin to lose the simple 
nature. 

\par
Our project is motivated by the apparent lack of accesible literature on the 
theory of refinement types. We aim to present a simple, restricted framework that 
captures the essence of refinement types. The said framework will be presented as 
an extension to \textit{WHILE language} \cite{whileLanguage}. Created as a tool 
to aid the study of programming language theory, we believe it strongly satisfies 
our requirement of accessibility with its simple syntax and semantics. Using the 
framework, we will study the interactions between mutation and refinement types 
and relates our findings to concepts in mainstream languages. We believe that 
imperative languages proves to be the more popular paradigm in modern 
programming and is more accessible to the majority. 

\par
At the end of the project we aim to achieve the following, 
\begin{enumerate}
  \item Survey the state of dependent and refinement types in different programming 
  languages and analyse their differences.
  \item Describe a refinement typed imperative language based on the WHILE 
  language.
  \item  Explore the ambiguity of refinement types in an environment where 
  mutation is possible and propose a solution to resolve the ambiguity.
  \item Discuss how our work compliments the existing literature and possible 
  future extensions.
\end{enumerate}

\par
This dissertation serves as a document for our findings and is organised as 
follows. This first chapter outlines our motivation for this project and our 
contributions. 

\par
In chapter 2 we provide background on the areas, we first give the 
formal definition of dependent types and how it differs from refinement types. 
The remainder of the chapter is a survey on the current state of 
dependent types and refinement types in existing programming languages. 
Different languages with varying paradigms are explored 
and summarised in order to have a better understanding of the extend of their 
support for these advanced types. A range of different languages across different 
paradigms are studied including Agda, Haskell, Idris, Scala, 
TypeScript and more. Finally, we extensively studied C++ as its templating 
engine bears strong resemblence to refinement types and we observe its limitation. 

\par
In chapter 3 we introduce an imperative language with refinement type support. 
Our language, named Simple-$R$, is a First-Order Programming Language which 
highly resembles the C programming language. Our aim with the language is to 
capture the core behaviour of refinement types, for the pursuit 
of simplicity, the language is kept at a minimal with only the fundamental features. 
In this chapter, we will be defining the syntax, typing rules and semantics 
of a basic language with refinement types support which serves as a basis 
which will be studied throughout the chapter. We then raise 
multiple scenarios that refinement types cause ambiguity in imperative programming. 
We discuss the impact of mutability has on refinement types and 
answer these problems by proposing different solutions that resolves the 
ambiguity and observes how these approaches differs. We draw parallels between 
our mechanisms and similar mechanisms implemented in established languages such 
as C++ and Java. 

\par
In chapter 4 we will discuss our work with regards to the 
existing work done in the area and how it completments the literature.
Finally we will conclude by discussing advanced features that can be integrated 
into our languages and how it can further complicate the language. We will also 
discuss some of the other considerations that need to be taken account when 
thinking about incorporating dependent types into a real language. 


\chapter{Background Research} 
In this chapter we will be reviewing the current knowledge of dependent types 
in different programming languages. It will cover languages with full dependent 
types support as well as some languages with similar concepts and point out how 
it differs from dependent types. Lastly we will summarise all these languages 
and point out some limitations and unknowns. 

\section{Dependent Types and Refinement Types}
In this section we will be providing the definitions of dependent types.

\subsection{Definition of Dependent Types}
At a very high level dependent types are types that depends on the value of 
another type. For example, we can define a type that captures only the even 
integers using the definition 
\verb+type EvenInt := { i : Int | i % 2 = 0}+. In this case we 
can say that the type EvenInt \textit{EvenInt} depends on the type \textit{int}.
Another commonly used example to describe dependent types would be a type like 
\verb+type FixVec<T, N> := { v : Vec<T> | len(v) = N}+, this type definition defines 
a vector or array of elements with type $T$ that always contains $N$ elements.

\subsection{Dependent $\Pi$ Types}
We can capture the definition mathematically using the notion of \textit{dependent 
product types}, i.e. $\Pi$ type. This is also sometimes referred to as 
\textit{dependent function type} as in this definition we construct a function 
$F: A \rightarrow B$. The function $F$ takes an element of type $A$ and 
gives us an element of type $B$ which depends on $A$. We express it 
mathematically using the $\Pi$ notation as
\begin{center}
 \begin{tabular}{l}
   $\prod x: A.  F(x)$
 \end{tabular} 
\end{center}

In this definition, $F(x)$ is the type family for the type $B$ that depends on $A$.
However $F$ could be a constant function, so we can also express the definition 
as $\Pi x:A.B$, in this case $B$ does not depend 
on the value $x$. Using the \textit{EvenInt} example from earlier, 
it can be defined as 
$\Pi x:Int.\text{ }\{ i:Int\text{ }|\text{ }i\text{ }\%\text{ }2\text{ }= 0\}$.

\par
Interestingly, the dependent product type correspond to the 
\textit{forall quantifier} as per 
the \textit{Curry–Howard correspondence}. The idea is that the dependent 
function $F(x)$ correspond to predicate $P(x)$ and thus the dependent product 
type has a one-to-one correspondence to $\forall x: A. P(x)$.

\subsection{Dependent $\Sigma$ Types}
In addition to the dependent product type, we have the notion of \textit{dependent sum 
types}, written as $\Sigma$ type. This is often referred to as the 
\textit{dependent pair type} as the resulting type here is an ordered pair. 
Specifically the resulting pair $\langle a,b \rangle$ is ordered such that the 
second element depends on the first element. The 
mathematical definition is similar to that of the product type
\begin{center}
 \begin{tabular}{l}
   $\langle a,b \rangle :\sum x: A.  F(x)$
 \end{tabular} 
\end{center}
In the case $a:A, b: F(x)$, similarly, $F$ could be a constant function and thus 
the expression is $\Sigma x:A.B$. Consider the following example, 

$\Sigma x: Int.\{y:Int\text{ }|\text{ } y = x * 2\}$, then the type would 
contain values like $\langle 1,2 \rangle$ and $\langle 4,8 \rangle$ where the 
second pair is doubled the first.

\par
Like the dependent product type, the dependent sum type correspond to a 
universal quantifier, in this case, the \textit{existential quantifier}. As 
per the Curry–Howard correspondence, $F(x)$ corresponds to predicate $P(x)$ 
thus $\Sigma x:A.F(x)$ correponds to $\exists x: A. P(x)$.

\par
While both dependent product types and dependent sum types are important to the 
literature, the project itself will mainly focus on the former. we believe that 
the the notion of pair in dependent sum types prove to be redundant in 
the construction a programming language and does not provide any additional 
value. The dependent product type is largely adequate for our goal.

\section{Refinement Types}
Refinement Types is a type system where a certain base type is refined by a 
predicate. A refinement type $A$ is written in the form 
$\{\upsilon : B\text{ }|\text{ }P(\upsilon)\}$. $\upsilon$ is a special variable 
not in the program, $B$ is a base type and $P(\upsilon)$ is the 
\textit{refinement predicate}, a boolean expression 
involving $\upsilon$ and any free variables in the program. Formally, a value 
$i$ is well typed with regards to a refinement type if $P(i)$ evaluates to 
\textit{true}.

\section{Refinement Types vs Dependent Types}

The key differentiating factor between refinement types and dependent types is 
that the latter is unrestricted. A refinement type is restricted predicate 
$P(\upsilon)$ whereas a dependent types is able to rely on a function $P(x)$ 
where there is no algorithm to prove its correctness. One has to manually 
provide the proof for a dependent types. Furthermore, a refinement type $A$ 
that is a refinement on a base type $B$ has a the property $A \preceq B$ 
specifying $A$ is a subtype of $B$, this is not true in a dependent type 
language.

\par
The decidability of refinement types allow one high level of automation and 
provide a simpler understanding. While in many cases dependent types prove to be 
more powerful, refinement types for all intent and purposes does the job in 
providing the improved expressivity for general programming. For this reason, we 
will be basing our project on refinement types. 

\section{Functional Languages}

In this section we will be examining three functional languages with 
dependent typing. Functional languages 
uses the \textit{functional programming} \cite{overviewFP} paradigm which is a programming 
paradigm that constructs program using a series of function applications. In 
this paradigm, functions return values as oppose to altering the state of the 
program. In this programming paradigm, the language focuses on describing 
\textit{what} the program will accomplish.

\par

Many functional languages has the notion of purity, i) A function will always 
return the same value when given the same arguments. ii) The evaluation of a 
function has no side effects (changes to the state of the program).

\subsection{Agda}

\textit{Agda} \cite{agda} is a purely functional language originally developed by Ulf Norell in 
1999 however the first appearance the current version known as Agda 2 is in 
2007. Agda has all the necessary constructs one would expect in a functional 
language such as first-class functions, inductive definitions, pattern matching, 
etc. In addition to being a functional language, Agda also serves an automated theorem prover. 
Agda is one of the few programming language with native dependent type support. 

\par
The code listing below is an example of defining a fixed length vector in 
dependent type. 

\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  data Nat : Set where 
  zero : Nat
  suc  : Nat -> Nat  
  
  data EvenNat : Nat -> Set where
  even-zero  : EvenNat zero
  even-plus2 : {n : Nat} -> EvenNat n -> EvenNat (suc (suc n))
  
  data Vec (A : Set) : Nat -> Set where
  [] : Vec A zero
  _::_ : {n : Nat} -> A -> Vec A n -> Vec A (suc n)
  \end{lstlisting}
  \caption{Dependent Types in Agda}
\end{figure}

\par
While Agda provides dependent type support, it remains a niche language. One of 
the reason being its paradigm, Agda is \textit{purely functional} \cite{purelyFP}, meaning that 
all functions are pure (i.e. not relying on the program state or other mutable 
data). Functional languages are generally considered harder to learn and grasp 
compared to other paradigms \cite{fpHarder}. Furthermore, the general lack of 
awareness and competent users who can program dependent types contribute to Agda 
being a niche language in the programming world and is 
predominantly used for theorem proving.

\subsection{Haskell}
\textit{Haskell} \cite{haskell} is a purely functional programming language first appeared in 1990. In 
contrast to Agda, Haskell is often considered a more general purpose programming 
language. Haskell is among the most popular programming languages and argubly 
the most popular ``pure'' language in the world \cite{pypl}. 
Haskell has even been adopted by software companies such as Facebook \cite{haskellFB}.

\par
Haskell is not a language that supports dependent types natively however many 
extensions has been developed to simulate the experience. 
Generalised Algebraic Data Types (GADTs) are a generalization of the 
algebraic data types, it allows the programmer to 
explicitly write down the types of the constructors \cite{haskellGADT}. 
\begin{figure}[H]
  \begin{lstlisting}
    data Expr = I Int        
          | Add Expr Expr 
          | Mul Expr Expr 
  \end{lstlisting}
  \caption{A GADT defintion for arithmetic operations in Haskell}
\end{figure}

Using the power of GADT one could define dependent types as so

\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat (n :: Nat) where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vec a (n :: Nat) where
      Nil  :: Vec a 0
      (:>) :: a -> Vec a n -> Vec a (n + 1)
  \end{lstlisting}
  \caption{Dependent Types in Haskell}
\end{figure}

\par
Although GADTs provide a way of simulating dependent types in Haskell and 
argubly enough for simple dependent typing enough for many cases. 
Haskell does not qualify as a fully dependent 
language due to the lack of certain features such as dependent functions. There 
have been proposals to add full dependent type support to Haskell however a lot 
of work remains to be done \cite{dependentHaskell, aRoleForDependentHaskell}. 
Furthermore, while Haskell is significantly more well known compared to Agda, it 
still lack the popularity of languages like Java and Python.

\subsection{Idris}
\textit{Idris} \cite{idris} is a dependently typed functional language first 
appeared in 2007. Idris bears similarity with Agda, both in terms of paradigm 
and type system. However the differ in one crucial way, Idris is designed to 
emphasise general purpose programming rather than theorem proving. Earlier one 
we stated that one of the less desirable property of Agda was its niche because 
of its emphasis in theorem proving. Idris provides 
interoperability with systems libraries and C programs, 
as well as language constructs for domain specific language 
implementation \cite{gpIdris}. 

\par
Syntactically Idris is very similar to Agda, dependent types are defined as so: 
\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat :  Nat -> Type where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vect : Nat -> Type -> Type where
      Nil  : Vect 0 a
      (::) : (x : a) -> (xs : Vect n a) -> Vect (n + 1) a
  \end{lstlisting}
  \caption{Dependent Types in Idris}
\end{figure}

\par
While Idris offers interoperability with multiple mainstream programming 
languages such as C and JavaScript, Idris remain predominantly a research tool. 
Idris is not production ready \cite{gpIdris} as it is missing certain libraries 
and more importantly nobody is working on Idris full time. Furthermore Idris is 
still a functional language, hence suffering from the limitation stated earlier. 

\section{Imperative Languages}

In this section we will be discussing dependent typing with regards to imperative 
languages. Imprative languages uses the \textit{imperative programming} 
\cite{imperativeOverview} paradigm, in constrat to the functional 
programming, this pradigm emphasises \textit{how} a program will operate 
by using a series of statements to change the program state.

\par

Imperative languages can be further broken down into different categories, 
mainly Procedural and Object-Orinted. Many of the world's most popular languages 
fall into this two categories, C, FORTRAN, COBOL are examples of procedural 
languages while Java, C#, Kotlin are Object-Oriented Languages. Some languages such 
as C++, Python are multi-paradigm and allows the programmer to write code both 
in a procedural manner or object-oriented manner. 

\par

Currently there is no production ready imperative programming language with 
proper dependent type support. Previous research has look at creating an 
impertaive language with dependent types but these are not available to the 
general programmers. Certain mainstream languages also have aspect that 
resembles dependent types but do not provide the complete feature.

\subsection{Xanadu}
\textit{Xanadu} \cite{xanadu} is a dependently typed imperative language created by a team at 
the University of Cincinnati. The language was implemented in OCaml and was 
said to be available online in the original paper, however the original cited 
location looks to have been taken offline. It is safe to conclude that 
the language itself is also no longer in active development 

\par
There are no examples of the actual language available online except some code 
snippets shown by the author in the original paper. As such we are unable to 
provide any analysis on the language itself.

\par
However, the language is worth a mention here as it shows the feasibility of 
imperative languages having full dependent typing. The research by the authors 
are impressive and it serves as inspiration for our project. 

\par
Our project complements the work by Xi by providing analysis on the problem at 
hand. The original paper merely demonstrated the development and semantics of 
Xanadu, our project aims to discuss more on the topic. 

\subsection{C++ Templates}
\textit{C++ Templates} \cite{cppTemplate} are a way of passing the type of a 
data as a parameter so certain code can be reused. For instance, the same 
sorting algorithm can be used on multiple data types such as \textit{int} and 
\textit{double}, using templates the programmer will not need to write the same 
sorting function multiple times for different data types. 

\par
Templates are often compared to Java's \textit{Generics} \cite{javaGenerics} 
as the C++ equivalent. While this statement is mostly true, C++ templates 
differ in a big way. 
Generics only allow the template parameter to be a class, templates on the other 
hand allow the parameter to be a class, values or pointers. The ability to 
pass values into a template to create types certainly resembles dependent types.

\par
The code listing below is an example of templates with values. It defines the 
struct that represents an integer less than N. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N>
    struct LessThanN {
      int value;
      LessThanN(int x) {
        if (x < N)
            value = x;
        else
           throw ``invalid type'';
      }
    };
  \end{lstlisting}
  \caption{Struct dependent on values using C++ Templates}
\end{figure}

\par
Using the above definition it is possible to define types such as \\
\verb+LessThanN<5> ltf = LessThanN<5>(3)+, this will define a type that will has 
to be less than 5. However, certain questions arise from this definition, 

i) What will happen if the constructor is given an invalid argument? 

ii) What if the template parameter is a variable and its 
value change? 

iii) What if the value of \textit{value} change during execution?

In the subsequent text, the term ``Dependent Value'' will be used to refer to the 
value $N$ and ``Value'' will refer to the actual value held by a LessThanN type, 
i.e. the \textit{value} state in the struct. 

\subsubsection{The Intended Behaviour}
First, we observe the intended behaviour of LessThanN using the following test 
code:
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(3);
      cout << ltf.value; // Prints out 3
      return 0;
    }
  \end{lstlisting}
  \caption{Intended Behaviour of LessThanN in C++}
\end{figure}

\par
As expected, the code compiles perfectly and outputs 3 when executed.

\subsubsection{Invalid Definition of LessThanN}
In order to observe the behaviour of i), we simply have to pass in an 
invalid value into the constructor, i.e. a value greater than N, 
the test is conducted using the code below. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(10); // Error here
      cout << ltf.value; 
      return 0;
    }
  \end{lstlisting}
  \caption{Invalid Definition of LessThanN in C++}
\end{figure}

\par
Interestingly, the code compiles perfectely despite the invalid definition. 
However it fails to execute as the exeception thrown in the \textbf{else} clause 
is left uncaught. This behaviour makes it no better than an simple if statement 
in the constructor. An addition in C++ 11 was the introduction of 
\textit{constexpr} and \textit{static\_assertation}. These allow for certain 
compile time checking, however the values checked must fulfil 
the \textit{constant expression} requiremets \cite{cppConstExpr}. 

\par
Modifying the \textbf{struct} to use the code below we get compile time type 
checking. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N, int M>
    struct LessThanN {
      int value;
      LessThanN() {
        static_assert(M < N, ``type is invalid'');
        value = M;
      }
    };
  \end{lstlisting}
  \caption{LessThanN with Compile Time Type Checking in C++}
  \label{code:compileLTN}
\end{figure}

\par
Now, providing an invalid definition yields a compile time error, with the 
following: 
\verb+LessThanN<10, 12> ltf = LessThanN<10, 12>;+ 

\textbf{static\_assert failed due to requirement `12 $<$ 10' ``type is invalid''}

\subsubsection{Mutation of Template Variable}
In our previous example we have been passing integer literal as the template 
parameter for the dependent value. Often programmers are required to 
work with varied values through variables, how will this effect the behaviour? 

\par
Consider the following hypothetical situation using the struct defined in 
figure \ref{code:compileLTN}: 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>();
    n = 2; // Is ltf still well typed??
  \end{lstlisting}
  \caption{Mutating the Dependent Variable for LessThanN in C++}
\end{figure}

\par
Compiling the above code leads to a compile time error, C++ requires template 
arguments to be constant expressions. In order to use variables as template 
arguments, they have to be defined \textbf{const}. In which case the above 
situation is impossible as the variable $n$ now cannot be changed. 

\subsubsection{Changing The Value of Struct During Execution}
We've showed that it is not possible to change the dependent value in 
the program, however what if the value changes? Will a 
variable be well-typed on one line and ill-typed on the next line? 

\par
Consider the following code: 
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    const int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>(); // Well typed
    ltf.value = 10; // Now ill-typed but not caught
  \end{lstlisting}
  \caption{Mutating the value of LessThanN in C++}
\end{figure}

\par
In order to achieve our intended behaviour there has to be some form of check 
that runs throughout the lifetime of the program, currently there is no native 
support for this form of invariant. However one potential workaround as a 
programmer would be to make the LessThanN type immutable, by setting \textit{value} 
to be a \textbf{const} however that significantly limits the usability of the 
language. 

\par
We see glimpses of dependent typing in certain imperative languages, the 
examples using C++ presented above is one of them. One could argue arrays in 
Java and C++ resembles the fixed size vector however they are quite similar. In 
the subsequent chapters of this dissertation we will define a language to 
address these uncertainties. 


\section{Summary of Dependently Typed Langauge}
\begin{table} [H]
  \begin{tabular}{|p{2cm}|p{2cm}|p{10cm}|}
    \hline
    \textbf{Name} & \textbf{Paradigm} & \textbf{Notes} \\ 
    \hline
    Agda & Purely Functional & Actively developed but 
      Predominantly used for theorem proving rather than general programming. \\ 
    \hline
    Haskell & Functional & Widely used as a general purpose programming language, however not natively dependently typed. \\ 
    \hline
    Idris & Purely Functional & More general purpose compared to Agda however 
      still lacks mainstream recognition. \\
    \hline
    \textit{ATS} \cite{ATS} & Functional & Developed by Xi who created Xanadu, 
      support dependent typing however only for static terms. \\
    \hline
    \textit{F*} \cite{FStar} & Functional & Jointly developed by Microsoft 
    Research and Inria aimed at program verification. Lacks mainstream 
    programming recognition.\\
    \hline
  \end{tabular}
  \caption{Summary of Dependently Typed Language}
\end{table}

\par
The table above shows a number of languages that supports dependent typing, we 
observed that majority of the languages in this category are using the 
functional paradigm. As functional languages pale in comparison to imperative 
languages in terms of populatiry, the general awareness for dependent types 
remains low. 

\par
Our aim for this project is to i) Explore how dependent types should behave in 
an imperative language and how a language can use different mechanism to enable 
this behaviour. ii) Encourage the research into dependent types by extending the 
WHILE language \cite{whileLanguage} to support dependent typing. We chose this 
language because of its simple and familair syntax which at its core resembles 
popular languages such as C. 

\chapter{The Simple-$R$ Language}
We propose Simple-$R$, a basic procedural language with support for refinement 
types. In this chapter we will describe the mechanics of the language in details.

\section{Language Syntax}
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{l l l}
      \textit{Types} & $T$ & $:\text{ }int\text{ }|\text{ }bool\text{ }|
      \text{ }\{x: T\text{ }|\text{ }e\}\text{ }|\text{ }void$\\
      \textit{Functions Type} &  & $:\text{ }T_1, T_2,T_3...T_n\longrightarrow T_0$\\
      \textit{Functions Definition} & $f$ & $:$ $(x_0,x_1,...x_n) \longrightarrow C;e$\\
      \textit{Operators} & $ops$ & $:$ $+$ $|$ $-$ $|$ $\wedge$ $|$ $\vee$ $|$ $<$ $|$ $>$ \\
      \textit{Expressions} & $e$ & $:$ $vals$ $|$ $\textbf{void}$ $|$ $x$ $|$ $e_1$ $ops$ $e_2$ 
      $|$ $f(e_1...e_n)$ \\
      \textit{Commands} & $C$ & $:$ $C_1;C_2$ $|$ \textbf{skip} $|$ $x\text{ }:= e_1$ 
      $|$ \textbf{while} $e_1$ \textbf{do} $C_1$ $|$ \\ 
        & & \; \textbf{if} $e_1$ \textbf{then} $C_1$ \textbf{else} $C_2$ $|$ 
        $\textbf{begin } D;C_1\textbf{ end}$ \\
      \textit{Declarations} & $D$ & $:$ $\textbf{var } x : T = e$ \\
      \textit{Variables} & $vars$& $:$ $x \in {a,b,c...z}$\\
      \textit{Values} & $vals$& $:$ $\forall v \in \mathbb{Z}$ $|$ $\forall v \in \mathbb{B}$\\
      \textit{Variable Types Context} & $\Gamma$& $:$ $vars \mapsto T$\\
      \textit{Variable Values Context} & $\sigma$& $:$ $vars \mapsto vals$
    \end{tabular}
  \end{center}
  \caption{Language Syntax for Simple-$R$}
\end{figure}

\par
Figure 3.1 shown above is the syntax of Simple-$R$, the paragraphs below 
explains the language in details. In constrast to other literatures in this area, 
Simple-$R$ is a \textit{First Order Programming Language} \cite{FOL} modelled 
after the WHILE \cite{whileLanguage} programming language but with functions.
Rather than building it on the $\lambda$-calculus as one would in 
a Higher Order Language, we opted for a ``C-like'' syntax, with concepts such as 
expressions, commands and top-level functions.

\par
In order to achieve simplicity and observe the core behaviour of dependent 
types, the language is kept at a minimum with only the necessary construct. 

\paragraph{Types} The Simple-$R$ language has support the following four data types. 
\begin{itemize}
  \item The basic integer type \textit{int}
  \item The basic boolean type \textit{bool}
  \item The refinement type, written as $\{x: A\text{ }|\text{ }e\}$. This defines 
  a type that is a refinement of type $A$ that satisfies a boolean expression $e$.
  \item The \textit{void} type to represent empty or null. Commands are modelled 
  as having the $void$ type.
\end{itemize}

\paragraph{Functions}
Functions Type are defined as $(T_1, T_2,T_3...T_n \longrightarrow T_0)$, 
it takes a up to $n$ types and returning a type. Note that functions are 
not first-class in this language, unlike a higher order 
language, functions types are its own entity and are distinct from the regular 
types. This distinction ensures that functions cannot be passed to 
other functions, nor can it return a function as a result. One can compare 
functions in Simple-$R$ to functions in C or Java. The function body is a 
command however it must end in an expression as the return value. Note that the 
return keyword is ommited. Functions return can be difficult to represent, to achieve 
a simply model for functions, we came to the decision to disallow return in the 
middle of the function, values can only be returned at the very end of the 
function.

\paragraph{Operators}
The language supports the following built in operators.
\begin{itemize}
  \item Integer addition using the $+$ operator writte in an infix notation.
  \item Integer subtraction using the $-$ operator written in an infix notation.
  \item Integer inequality $<$ as the less than operator.
  \item Integer inequality $>$ as the greater than operator.
  \item Logical conjunction using the $\wedge$ operator written in an infix 
  notation.
  \item Logical disjunction using the $\vee$ operator written in an infix 
  notation.
\end{itemize}

\paragraph{Expressions} The following expressions make up the language.
\begin{itemize}
  \item Variables and values represents the most basic form of an expression.
  \item The four operators which operates on two other expressions $e_1$ 
  and $e_2$ and return an expression.
  \item The function call $f(e_1..e_n)$ invokes function $f$ with arguments 
  $e_1..e_n$ and return the result. Functions are classified as expression as 
  one can utilise the computed result in other expressions. 
  \item $\textbf{void}$ is used as the return value for a function that returns 
  a $void$ type.
\end{itemize}

\paragraph{Commands} Commands are statements that can be executed to perform an 
actions. Simple-$R$ supports the following commands,
\begin{itemize}
  \item The assignment statement $(:=)$ assigns an expression $e_1$ to variable 
  $x$, note $x$ must have already been declared. 
  \item The \textbf{if then} and \textbf{while do} statements are the standard 
  control flow operations one would expect.
  \item The \textbf{skip} statement is use to indicate an empty expression and 
  does not perform any meaningful action. 
  \item The \textbf{begin ... end} command allows one to open a new scope. A 
  begin statement is followed by a variable declaration $D$, the declared 
  variable would then me accessible in the scope of command $C_1$. Upon reaching 
  \textbf{end}, the variable is out of scope and deallocated. 
\end{itemize}

\paragraph{Declaration} Declarations are the method one use declare new construct 
in the program. We start the language off having the most basic variable declaration 
$\textbf{var }x : T = e$ which declare a new variable $x$ of type $T$ and 
initialise it the resulting value of expression $e$.

\paragraph{Variables and Values} In Simple-$R$, all variables are allocated 
locally, we use $x$ to denote a variable. Variables can take values as suggested by the types, all the integer 
literals $\mathbb{Z}$, booleans $\mathbb{B}$ and $nil$ which is $void$ type. 

\paragraph{Variable Values Context} Variables are mapped to values in the program 
context $\sigma$. Each variable is allowed to only appear once in 
the context. We use \textbf{dom}($\sigma$) to retrive the domain which represent 
the set of declared variables. We use the notation $\sigma(x)$ 
to retrieve the value bound to variable $x$.

\paragraph{Variable Types Context} Variables are also mapped to their types 
in the type context $\Gamma$. Each variable is allowed to only appear once in 
the context. This context will be used to type check the program using the 
typing judgement in the next section.

\section{Typing Rules}
This section defines the typing rules for the Simple-$R$ language.

\par
We begin by defining the typing judgements. The typing judgements used in 
Simple-$R$ takes the form of the standard notation. 
\begin{center}
  $\Gamma \vdash e : T$\\
  $\Gamma \vdash_{C} C : void$\\
  $\Gamma \vdash_{D} D \dashv \Gamma'$\\
\end{center}
This first and second judgement represents that expression $e$ 
under the context $\Gamma$ has the type $T$. The third states that a declaration 
produces the output context $\Gamma'$.

\par
Using the judgement rule we can easily define the fist few typing rules for base 
values \textit{int}, \textit{bool}, $nil$ and variables.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\forall n \in \mathbb{Z}$, $\Gamma \vdash n : int$ & 
      $\forall b \in \mathbb{B}$, $\Gamma \vdash b : bool$ & 
      $\Gamma \vdash_{C} \textbf{skip} : void$ & 
      $x : T, \Gamma \vdash x : T$  & 
      $\Gamma \vdash \textbf{void} : void$
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}

\par
The remaining typing rules for the operators, statements and function  
calls are presented below. First we define the 
basic rules in figure \ref{fig:basic_typecheck}, 
most of the typing rule are straightforward and what one would expect from the 
type checker. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int}
        {\Gamma \vdash e_1 + e_2 : int}[(\textbf{op} $+$)] \text{ }
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int} 
        {\Gamma \vdash e_1 - e_2 : int}[(\textbf{op} $-$)] & \\
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int}
        {\Gamma \vdash e_1 < e_2 : bool}[(\textbf{op} $<$)] \text{ }
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int} 
        {\Gamma \vdash e_1 > e_2 : bool}[(\textbf{op} $>$)] & \\
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool}
        {\Gamma \vdash e_1 \wedge e_2 : bool}[(\textbf{op} $\wedge$)] \text{ }
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool} 
        {\Gamma \vdash e_1 \vee e_2 : bool}[(\textbf{op} $\vee$)] & \\
      \inference {\Gamma \vdash e_1: bool \\ \Gamma \vdash C_1: void & \Gamma \vdash C_2: void}
        {\Gamma \vdash_{C} \text{\textbf{if }} e_1 \text{\textbf{ then }} 
        C_1 \text{\textbf{ else }} C_2: void}[(\textbf{if else})]
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash C_1: void}
        {\Gamma \vdash_{C} \text{\textbf{while }} e_1 \text{\textbf{ do }} C_1 : void} [(\textbf{while do})] & \\
      \inference {\Gamma \vdash x: T & \Gamma \vdash e_1: T} 
        {\Gamma \vdash_{C} x := e_1 : void} [($:=$)] \text{ }
      \inference {\Gamma \vdash C_1: void & \Gamma \vdash C_2: void} 
        {\Gamma \vdash_{C} C_1;C_2 : T_2} [(concatenation $;$ $C$)] \text{ }
      & \\
      \inference {\Gamma \vdash e_1: T_1} 
        {\Gamma \vdash_{D} \textbf{var } x : T_1 = e_1 \dashv \Gamma'} [($vars$ Declaration)]
      & \\
      \inference {\Gamma \vdash D_1 \dashv \Gamma' & \Gamma' \vdash_{C} C_1 : void} 
        {\Gamma \vdash_{C} \textbf{begin }D_1;C_1\textbf{ end}} [(Begin scope)]     
    \end{tabular}
  \end{center}
\caption{Basic Typing Rules for Simple-$\Pi$}
\label{fig:basic_typecheck}
\end{figure}

\subsubsection{Functions}
For a function call, we use the type judgement above. We use  
first order logic to write $f(e_1...e_n)$ as an n-nary function of 
type $T_1$ to $T_n$, then the arguments $e_1$ to $e_n$ must be of same type. 
Evaluation of the function will then satisfy the return type $T_0$.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {f : T_1,T_2...T_n \longrightarrow T_0 \\ 
      \Gamma \vdash e_1 : T_1 & \Gamma \vdash e_2 : T_2 &...& \Gamma \vdash e_n : T_n}
        {\Gamma \vdash f(e_1...e_n): T_0}[(\textit{functions})]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Functions in Simple-$R$}
\end{figure}

\subsubsection{Refinement Types}
Finally we define typing rules for a refinement types. A refinement type 
is represented in our system as $\{\upsilon : T\text{ }|\text{ }e\}$ and is 
constructed by a base type $T$ and a refinement predicate $e$ which may contain 
the free variable $\upsilon$ and any free variables in the program. A refinement 
type represent all values of $T$ where the expression $e[u/\upsilon]$ holds. 

\par
We define the typing rule for refinement types using the idea of 
\textit{universes} \cite{martinLof} in type theory, using the 4th judgement form 
$\Gamma \vdash A : Type$ to represent that $A$ is a type. 

\par
We begin by defining the formation rule for a refinement type. 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash \upsilon : T & \Gamma \vdash e : bool}
        {\Gamma \vdash \{\upsilon : T\text{ }|\text{ }e\}: Type}[(Refinment Type formation)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Refinement Types in Simple-$R$}
\end{figure}


\par
While functional languages such as Liquid Haskell has shown the ability of type 
checking refinement types statically at compile time, with the presence of 
mutation in our language it turns out to be difficult. The refinement predicate 
may contains variables whose value is only available at runtime or could have 
changed since declaration. To mitigate this, we adopted a type checking appraoch 
that validates as much as possible statically and defers complicated type 
checking until runtime. 

\par
During compile type, the type checker validates that if one is expecting a 
refinement type with base type $T$ then it is provided an expression $e$ of type 
$T$, note that the expression might not be valid refinement type, the refinement 
predicate might evaluates to false. However, this check will be checked 
dynamically at runtime. We will discuss runtime type checking later in the text. 

\par
Our static refinement type checking rule is defined below.
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1 : T}
      {\Gamma \vdash e_1 : \{\upsilon : T\text{ }|\text{ }e\}} [(Refine Base Static)]
    \end{tabular}
  \end{center}
\end{figure}

Additionally, we defining the typing rule for a subtypes, 
we express $A$ is a subtype of $B$ as $A \preceq B$. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      
      $\Gamma \vdash \{\upsilon : T\text{ }|\text{ }e\} \preceq T$ (Subtype Base 1)
      & \\
      \inference {\Gamma \vdash \forall \upsilon_1 : T\text{ }s.t.\text{ }e_1 \Rightarrow e_2[\upsilon_1/\upsilon_2]}
      {\Gamma \vdash \{\upsilon_1 : T_1\text{ }|\text{ }e_1\} \preceq \{\upsilon_2 : T_1\text{ }|\text{ }e_2\}} [(Subtype Base 2)]
      & \\ 
      \inference {\Gamma \vdash T_1 \preceq T_2 & \Gamma \vdash T_1 \preceq T_3} 
      {\Gamma \vdash T_1 \preceq T_2} [(Subtype Trans)]
      & \\
      $\Gamma \vdash T_1 \preceq T_1$ (Subtype Reflex)
    \end{tabular}
  \end{center}
\end{figure}

\par
The four subtype judgement defined above allows us to perform perform basic 
polymorphism. (Subtype Base 1 & 2) defines the basic definition of subtype. The 
first states that a refinement type of $T$ is trivially a subtype of $T$ and the 
second states that a refinement type $A$ is a subtype of another 
refinement type $B$ if the set of values in $A$ is a subset of or equal 
the values in $B$. (Subtype Trans) defines the transitivity of subtype and 
(Subtype Reflex) defines the reflexivity. 

\par
One should be able to use a value of type $T_1$ in a context 
expecting type $T_2$ provided $T_1$ is a subtype of $T_2$. For example, an 
expression $e$ of type containing all even natural numbers $EvenNat$ when passed 
to a context expecting a type $Nat$ should be valid. 

\par
We enable this behaviour using the judgement below.
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
       \inference {\Gamma \vdash T_1 \preceq T_2 & \Gamma \vdash e : T_1} 
      {\Gamma \vdash e : T_2} [(Subtype)]
    \end{tabular}
  \end{center}
\end{figure}

\par
In this section we covered the typing rules for Simple-$R$, typing rules are a 
way of allowing us to statically check the correctness of our program with 
regards to typing rules. Refinement types are hard to verify statically because 
of the dynamic behaviour when evaluating the refinement predicate. In the next 
section we will analyse the dynamic behaviour of the language. 

\section{Operational Semantics}
In this section we will define the \textit{Operational Semantics} 
\cite{operationalSemantics} for the Simple-$R$ language 
using the \textit{Structural Operational Semantics} \cite{plotkinSOS} (SOS) rules.

\par
Throughout the text we will be extending the syntax defined in the 
previous chapter in order to accomodate more features. 
We will use the following metavariables and notations throughout our 
definitions.

\renewcommand\labelitemii{$\blacksquare$}
\begin{itemize}
  \item The metavarible $op$ as one of a range of operators. 
  \item The metavariable $v$ to range over all values.
  \item The uppercase letters $A,B,C,T$ to range over all types.
  \item Greek letters ($\alpha$, $\pi$, $\upsilon$) to define local variables in 
  the formuli. 
  \item The following notations to operate on states. 
    \begin{itemize}
      \item $\sigma + \{x \mapsto v\}$ adds $\{x \mapsto v\}$ to $\sigma$ provided initially $x \notin\textbf{dom}(\sigma)$. 
      \item $\sigma[x \mapsto v]$ or $\sigma \uplus \{x \mapsto v\}$ updates $\sigma$ such that now $\sigma(x) = v$.
      \item $\sigma \setminus \{x\}$ to remove $x$ from $sigma$, provided that $x \in \textbf{dom}(\sigma)$.
    \end{itemize}
  \item $\langle e, \sigma \rangle \Longrightarrow \langle e', \sigma \rangle$ as the transition relation for expression.
  \item $\langle C, \sigma \rangle \longrightarrow \langle C', \sigma' \rangle$ and $\langle C, \sigma \rangle \longrightarrow \sigma'$ as the transition relation for commands.
\end{itemize}

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {v = v_1 + v_2}{\langle v_1 + v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $+$)] \text{ }
      \inference {v = v_1 - v_2}{\langle v_1 - v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $-$)]
      & \\
      \inference {v = v_1 < v_2}{\langle v_1 < v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $<$)] \text{ }
      \inference {v = v_1 > v_2}{\langle v_1 > v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $>$)]
      & \\
      \inference {v = v_1 \wedge v_2}{\langle v_1 \wedge v_2, \sigma \rangle \Longrightarrow \langle v, \sigma \rangle}[(op $\wedge$)] \text{ }
      \inference {v = v_1 \vee v_2}{\langle v_1 \vee v_2, \sigma \rangle \Longrightarrow \langle v, \sigma \rangle}[(op $\vee$)]
      & \\
      \inference {\langle e_1, \sigma\rangle \Longrightarrow \langle e_1', \sigma \rangle}
        {\langle e_1\text{ }op\text{ }e_2, \sigma  
        \rangle \Longrightarrow \langle e_1'\text{ }op\text{ }e_2, \sigma \rangle}[($op$ $expr$)]
      \text{ }
      \inference {\langle e_2, \sigma\rangle \Longrightarrow \langle e_2', \sigma \rangle}
        {\langle v\text{ }op\text{ }e_2, \sigma  
        \rangle \Longrightarrow \langle v\text{ }op\text{ }e_2', \sigma \rangle}[($op$ $expr$ 2)]
      & \\
      $\langle v, \sigma \rangle \Longrightarrow \sigma$ ($vals$) evaluation
      \text{ }
      \inference {x \in \textbf{dom}(\sigma)}{\langle x, \sigma \rangle \Longrightarrow \langle \sigma(x), \sigma \rangle}[($vars$) evaluation] 
    \end{tabular}
  \end{center}
  \caption{Basic Evaluation Rules for Simple-$R$ Expression}
  \label{fig:sos_expr}
\end{figure}

\par
Figure \ref{fig:sos_expr} defines the reduction rules for expression, importantly, expressions 
are not able to modify the state of the program. If one defines a singular value 
it performs no meaningful action. We next define the evaluation rules for 
commands. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle \text{\textbf{skip}}, \sigma \rangle \longrightarrow \sigma$ (\textbf{skip})
      \text{ }
      \inference {\langle C_1, \sigma \rangle \longrightarrow\sigma'}
        {\langle C_1;C_2, \sigma \rangle \longrightarrow \langle C_2, \sigma' \rangle}[($C_1;C_2$)]
      & \\
      $\langle \text{\textbf{if }\textit{true}} \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle C_1, \sigma\rangle$ (\textbf{if} true)
      & \\
      $\langle \text{\textbf{if }\textit{false}} \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle C_2, \sigma\rangle$ (\textbf{if} false)
      & \\
      \inference {\langle e_1, \sigma \rangle\Longrightarrow\langle e_1', \sigma \rangle}
        {\langle \text{\textbf{if }} e_1 \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle \textbf{if } e_1' \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle}[(\textbf{if} $expr$)] 
      & \\
      $\langle \text{\textbf{while }} e_1 \text{\textbf{ do }} C_1, \sigma \rangle \longrightarrow \langle 
        \text{\textbf{if }} e_1 \text{\textbf{ then }} C_1;
        (\text{\textbf{while }} e_1 \text{\textbf{ do }} C_1) \text{\textbf{ else }} \textbf{skip}, \sigma \rangle$ (\textbf{while do})      
      & \\
      \inference {x \in \textbf{dom}(\sigma)} 
      {\langle x := v, \sigma \rangle \longrightarrow \sigma[x \mapsto v]} [(assign 1)] \text{ }
      \inference {\langle e, \sigma \rangle \Longrightarrow \langle e', \sigma \rangle} 
      {\langle x := e, \sigma \rangle \longrightarrow \langle x := e', \sigma \rangle} [(assign 2)]
     \end{tabular}
  \end{center}
  \caption{Operational Semantics for Simple-$R$ Commands}
  \label{fig:sos_commands}
\end{figure}

\par
Figure \ref{fig:sos_commands} defines the operational semantics for the basic commands 
in the language. The semantics for $\textbf{begin }D;C \textbf{ end}$ and functions 
will be covered in the subsequent sections.

\subsection{Scoping}
Scoping has an important role in programming languages, variables can be defined 
in scopes and are unavailable once outside. While there are many different 
variables that does not follow this rule, such as static variables and global 
variables. The current design of Simple-$R$ supports only local variables which 
heavily relies on scoping. 

\par
In order to help us formalise the notion of scopes we define a new notation, 
$\Longrightarrow^{*}$ and $\longrightarrow^{*}$ as a multi-step evaluation. 
The evaluation rule $\langle e, \sigma \rangle \Longrightarrow^{*} 
\langle v, \sigma' \rangle$ simply 
evaluate the expression $e$ one or more times until it evaluates to a value $v$. 
The same applies for a multistep evaluation for commands, 
$\langle C, \sigma \rangle \longrightarrow^{*} \sigma'$ execute the command $C$ 
until there is no evaluation rules to apply. 

\par
Using a multi step evaluation, We can easily define the scoping rules as shown 
in figure \ref{fig:scoping_rules}.
  
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \textbf{dom}(\sigma) 
      & \langle C_1, \sigma' \rangle \longrightarrow^{*} \sigma''} 
      {\langle\textbf{begin var }x : T = v_0; C_1 \textbf{ end}, \sigma \rangle 
      \longrightarrow \sigma'' \setminus \{x\}} [(\textbf{begin end} values)] 
      & \\
      \footnotesize
      \inference {\langle e_1, \sigma \rangle \Longrightarrow \langle e_1', \sigma \rangle} 
      {\langle \textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma \rangle 
      \Longrightarrow \langle\textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma \rangle} 
      [(\textbf{begin end} $expr$)]
      \normalsize
    \end{tabular}
  \end{center}
  \caption{Scoping Rules for Simple-$R$}
  \label{fig:scoping_rules}
\end{figure}

\par
The \textbf{begin in} statement opens a new scope $\sigma'$ which 
assigns $x$ the value $v$, this scope allows the command $C_1$ to be evaluated 
using a multi step evaluation. Notice that the resulting state 
uses the $\setminus$ operator which removes all the variables 
in the set $\{x\}$ from the domain of $\sigma$. 

\par
This is necessary as it is possible to modify the range of $\sigma$ through 
assignments but not the domain. Upon exiting a scope the alteration to the program 
should still be visible, the only difference is that the variable $x$ is no longer in 
the state, i.e. has ran out of scope.

\par
The multi-step evaluation provides us to easily express scoping rules, 
the alternative would be to model an explicit call stack, which complicates the 
formulas and syntax.

\subsection{Functions}
Functions in almost all imperative language operates in their own scope. In many 
cases they do not have the access to the local variables out of their scope however 
one can pass data using arguments. Functions in Simple-$R$ are call by values, 
changing the value of an argument in the function does not change the value in 
the outside scope. Our multi-step evaluation rule defined previously helps us 
evaluate functions in their own scope. 

\par
In order to define the operational semantics of a function we will need to 
specify the function body. We define a mapping 
\textit{fns} $: f \mapsto ((x_1, x_2...x_n), C_1;e)$, 
using this mapping allows us to retrieve the body of a function. Since functions 
definition cannot be changed at runtime, this does not need to be part of the 
configuration and can be consider as a static context.

\par
We can then evalute the function body which using the multi-step evaluation.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\textit{fns}(f) = ((x_1..x_n), C_1;e_1) & \langle C_1, \sigma' 
      \rangle \longrightarrow^{*} \sigma''
        \\ \sigma' = \{x_1 \mapsto v_1 ... x_n \mapsto v_n\} & \langle e_1, \sigma'' \rangle \Longrightarrow^{*} \langle v, \sigma'' \rangle}
      {\langle f(v_1...v_n), \sigma \rangle \Longrightarrow \langle v, \sigma \rangle} [(function call vals)]
      & \\
      \inference {\langle e_k, \sigma \rangle \Longrightarrow \langle e_k', \sigma' \rangle}
      {\langle f(v_0...v_{k - 1},e_k...e_n), \sigma \rangle \Longrightarrow \langle f(v_0...v_{k - 1}, e_{k}'...e_n), \sigma \rangle} [(function call expr)]
    \end{tabular}
  \end{center}
  \caption{Functions Semantics for Simple-$R$}
\end{figure}

\par
The first rule (function call vals) resembles the evaluation rule for 
variable declaration but it differs in a crucial way, in the new context for a 
function call, none of the variables from the previous scope transfer over, only 
the argument values are copied. We then evaluates the function body until it 
evaluates to a value which is then returned to the caller's context. Unlike 
scopes, functions only update its local state which is dellalocated upon return. 
It cannot change the caller's state. 

\par
The second rule (function call $expr$) evaluates the expression passed into the 
function as arguments. Our language defines a strict behaviour that all 
arguments are evaluated in the order they are passed in, i.e. from left to right 
and arguments are call-by-value.

\subsection{Runtime Refinement Type Checking}
A declaration of a variable that is a refinement type requires specific 
evaluation rules. When one declare 
a variable of a refinement type, the language has to ensure that the refinement 
predicate evaluates to true. While we have defined a statically typed language, even in a statically 
typed language, there are cases when the type of some data cannot be determined 
statically. Gordon Plotkin discussed the idea of dynamically checking a static 
language in this work \cite{dynamicCheckStaticLanguage}.

\par
Languages like Java are generally considered a statically typed language  
however certain typing properties are impossible to check at compile time. In 
order to address this, Java employs a combination of static and dynamic checking. For example, 
consider downcasting in Java using the classes \verb|A|, \verb|B extends A| and 
\verb|C extends B|. The expression \verb|A x = new B();(C) x| 
is valid at compile time as there is a possibility it will succeed at 
runtime, however in this case it fails at runtime as \verb|x| is not type \verb|C|. Note 
that in some cases like \verb|Integer i = 10; (String) i|, 
casting fails at compile time because there is no way for it to succeed at all. 

\par
The refinement predicate proves to be undecideable at compile time, one might 
require access to program state for values of variables in order 
to evaluate the refinement predicate. In many cases, 
only constants and constant expressions are available at compile time. 
Interestingly, Cormac Flanagan proposed a similar idea dubbed \textit{Hybrid Type 
Checking} \cite{hybridTypeChecking} to verify the correctness of Dependent Types and Refinement Types 
in a $\lambda$-calculus. The paper inspired our idea by proposing a type checker that is 
``a synthesis of these two approaches that enforces precise interface 
specifications, via static analysis where possible, but also via 
dynamic checks where necessary''.

\par
Previously we demonstrated how refinement types are checked statically in Simple-$R$,
now we show how one can type check refinement types dynamically at runtime. We 
define a special form of typing judgement to type check refinement types 
dynamically.


\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\sigma, \Gamma \vdash_{R} e_1 : \{\upsilon : T \text{ }|\text{ }e\}$
    \end{tabular}
  \end{center}
  \caption{Typing Judgement for Refinement Types}
  \label{fig:refine_judgement}
\end{figure}

\par
Figure \ref{fig:refine_judgement} shows a typing judgement for refinement 
types which has the ability to access the runtime state $\sigma$. We can then 
perform a type check on refinement type using the rule defined below. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference{\Gamma \vdash e_1 : T_1 & \langle e[e_1/\upsilon], \sigma \rangle \Longrightarrow^{*} \langle \textit{true}, \sigma \rangle}
      {\sigma, \Gamma \vdash_{R} e_1 : \{\upsilon : T_1\text{ }|\text{ }e\}} [(Runtime Refine)]
    \end{tabular}
  \end{center}
  \caption{Type Checking Refinement Types}
  \label{fig:refine_typecheck}
\end{figure}

\par
During runtime, the typing judgement in figure \ref{fig:refine_typecheck} 
asserts that an expression $e_1$ is a valid refinement type if it 
evaluates to the base type $T_1$ and the refinement predicate $e[e_1/\upsilon]$ 
evaluates to true under state $\sigma$.

\par
Our type check rule looks to capture the behaviour of refinement type however it 
turns out the current definition is underspecified. In the next section we 
will put forward certain ambiguities with the design and discuss different choices 
one can make to address them.

\section{Refinement Types and Variables}

\subsection{Ambiguity of Refinement Types with Mutation}

Programming languages often have a wide range of features, often the team behind 
the language have to put extensive thought into the design decisions. As there 
are often multiple way to handle a certain feature, rarely is there a definite 
answer to which is the most optimal.

\par
This seemingly undecideable problem is known as \textit{feature interactions} 
\cite{featInteract}, it describes the problem in some situations multiple 
features would modify the behaviours of each others. The same applies to 
refinement types, which can be seen as a feature. For instance, the inclusion 
of refinement types would modify the behaviour of assignments and vice versa. 
This section will cover the different ways of handling refinement types and how 
they interact with other features.
Consider these few ambiguity of using variables to define dependent types. For 
instance: 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{begin var }$y\text{ }:\text{ } int = 10;$ \\
    \tab\textbf{begin typedef }$BoundedIntY$ = $\{i : Int\text{ }|\text{ } i < y\}$; \\ 
    \tab\tab\textbf{begin var }$x\text{ }:\text{ }BoundedIntY = 4;y := 5$\textbf { end} \\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Mutation to Free Variables in Refinement Predicate}
  \label{fig:amb_refinement_vars}
\end{figure}

\par
The simple program demonstrated in figure \ref{fig:amb_refinement_vars} declares a 
bounded integer type $BoundedIntY$ whose value cannot be greater than another integer $y$, 
a free variable in the program. A variable $x$ is declared to be of type 
$BoundedIntY$ with the appropriate value. Later in the program, the value of $y$ 
changes. resulting to $x$ now being ill-typed. The behaviour is now undefined, 
should $x$ still be well-typed, or is the behaviour invalid? This section will 
discuss this problem in detail. 

\subsection{Type Declaration}
First we need to introduce a new declaration statement for type declaration, 
in the example above we used the statement (\textbf{typedef} $x = T$) to denote a 
new type $T$ with the name $x$, this declaration statement resembles variable 
declaration and has the following typing judgement. 

\begin{center}
  \begin{tabular} {c}
    \inference{\Gamma \vdash T : Type} {\Gamma \vdash_{D} \textbf{typedef } x = T \dashv \Gamma'}  
  \end{tabular}
\end{center}
  
\par
We need to add this construct into our syntax. In our current syntax, 
we have a context mapping $vars$ to $vals$, We now need to add a similar mapping \
for types, We use $\tau$ to represent the type name map. 

\par
The syntax is extended by adding the following: 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Declaration} & $D$ & $:$ ... $|$ \textbf{typedef }$x = T$\\
      \textit{Type Name Context} & $\tau$& $:$ $vars \mapsto T$ \\
    \end{tabular}
  \end{center}
  \caption{Type Name Context Extension for Simple-$R$}
\end{figure}

\par
In our operational semantics, our signature is updated from $\langle C, \sigma \rangle$ 
to $\langle C, \sigma, \tau \rangle$ in order to incorporate this new feature. 
All previous operational semantics should be updated consistently.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference { 
      \langle C_1, \sigma, \tau' \rangle \longrightarrow \langle \sigma', \tau' \rangle\\
      x \notin \text{\textbf{dom}}(\sigma) & x \notin \textbf{dom}(\tau) & \tau' = \tau + \{x \mapsto T\}}
      {\langle \textbf{begin typedef }x = T;C_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau \rangle}[(\textbf{typedef})] \text{ }    
    \end{tabular}
  \end{center}
\end{figure}

\par
Note that unlike the rule for variable declaration, we did not have to remove 
the type name $x$ from the context after evaluation. This is because unlike 
variables, types cannot change after declaration. The new type simply goes 
out of scope, hence the new type context will simply be our initial one. 

\par
The operational semantic above simply adds a new type definition with name $x$ 
into the Type Name context $\tau$. Importantly, the variable $x$ cannot have 
already been defined as a value variable in $\sigma$ and a type of the same name 
can not already be defined. Logically it is equivalent to the semantics for 
variable declaration.

\par
We complete our evaluation to specify how a variable is declared using a type 
name. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {y \in \textbf{dom}(\tau) & T = \tau(y)} 
      {\langle\textbf{begin var }x : y = e_1;C_1\textbf{ end}, \sigma, \tau \rangle 
      \longrightarrow \langle\textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma, \tau \rangle }
    \end{tabular}
  \end{center}
\end{figure}

\subsection{Complete Immutability}
The main issue one encounters when associating refinement types with imperative 
languages is the presence of mutability and assignments. The obvious way to 
work around this problem is to remove the ability to make changes to the state 
of the program, all variables declared are final.

\par
Using this approach does definitely resolves the uncertainty the usability of 
the language is poor. Imperative programming relies on state changes, forbidding 
that go against the paradigm. However, if we strategically enforce immutability 
we can resolve the ambiguity while preserving a flexible imperative style 
language. In the next few sections we will discuss two approaches that 
improve the specification of our type checker through restricting changes to 
variables. 

\subsection{Immutability in Refinement Types}
In order to avoid feature interaction between refinement types and assignments, we 
observe that it is suffice to require free varibles appearing in a refinement 
predicate to be immutable. This approach improves flexibility of our language as 
one will still be able to have mutability in context irrelevant to refinement 
types. 

\par
In order to capture the notation of immutable types, the set of variables $vars$ 
is partitioned into two different distinct catogories. Mutable and immutable, we 
define a predicate $is\_immutable$ that specify if a given variable is immutable. 
$is\_immutable(x)$ holds if and only if $x$ is immutable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Declaration} & $D$ & $:$ $...\text{ }|\text{ }\textbf{const }x : T = e_1$
    \end{tabular}
  \end{center}
  \caption{Immutable Variable Context for Simple-$R$}
\end{figure}
 
One can declare an immutable variable similar to defining a mutable 
variable, using the \textbf{const} $x : T = e$ statement. We establish the following 
rules for immutable variables. 

\par
The typing judgement which appears identical to that of variable declaration. 

\begin{center}
  \begin{tabular} {c}
    \inference {\Gamma \vdash e_1: T_1} 
        {\Gamma \vdash_{D} \textbf{const } x : T_1 = e_1 \dashv \Gamma'} [($vars$ Declaration)]
  \end{tabular}
\end{center}

\par
The operational semantics describing the process of creating a immutable 
variable is similar to the one for regular mutable variables. The only oddity 
here is extending the assignment statement to only accept the latter. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      \langle C_1, \sigma', \tau \rangle \longrightarrow^{*} \langle \sigma'', \tau' \rangle 
      \\ \sigma' = \sigma + \{x \mapsto v\} & x \notin \textbf{dom}(\sigma)} 
      {\langle \textbf{begin const }x : T = v;C_1\textbf{ end}, \sigma, \tau \rangle 
      \longrightarrow \langle \sigma'' \setminus \{x\}, \tau' \rangle} [(\textbf{let in} values)] 
      & \\
      \footnotesize
      \inference {\langle e_1, \sigma, \tau \rangle \Longrightarrow \langle e_1', \sigma, \tau \rangle} 
      {\langle \textbf{begin const }x : T = e_1;C_1\textbf{ end}, \sigma,\tau \rangle 
      \longrightarrow \langle \textbf{begin const }x : T = e_1';C_1\textbf{ end}, \sigma, \tau \rangle}
      [(\textbf{const in} $expr$)]
      \normalsize
      & \\
      \inference {x \in \textbf{dom}(\sigma) & \neg is\_immutable(x)} 
      {\langle x := v, \sigma, \tau \rangle \longrightarrow \langle \sigma[x \mapsto v], \tau \rangle} [(assignment $vals$)]
    \end{tabular}
  \end{center}
  \caption{Immutable Variables Rules for Simple-$R$}
\end{figure}

\par
Once we define the ability to define immutable variables, we can utilise it in 
our type definition. First we refine our specification for \textbf{typedef} 
with regards to refinement types using the evaluation rules.

\par
We require a new notation to capture all the variables that appear in an 
expression $e$, we use the notation \textit{free\_vars}$(e)$ to give the set of all 
variables that appear in an expression $e$.

\par
Notice that in our syntax the refinement predicate is simply a boolean 
expression, this means that it is not possible for the refinement predicate to 
declare any new variables within it. So it is easy to see that for a refinement 
predicate $e$, $\textit{free\_vars}(e) \subseteq \textbf{dom}(\sigma)$, note that 
$\upsilon$ is not a free variable. 

\par
Using the new notation we can easily verify that all free variables in a 
refinement predicate $is\_immutable$ using the evaluation defined below. The same 
applies when one declare a variable of type $\{\upsilon : T\text{ }|\text{ }e\}$ 
without using the \textbf{typedef} command.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      x \notin \text{\textbf{dom}}(\sigma) & x \notin \textbf{dom}(\tau) \\
      \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_immutable(\alpha)
      \\ \langle C_1, \sigma, \tau + \{x \mapsto \{\upsilon :T\text{ }|\text{ }e\}\} 
      \rangle \longrightarrow \langle \sigma', \tau \rangle}
      {\langle \textbf{begin typedef } x = \{\upsilon :T\text{ }|\text{ }e\};C_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \sigma', \tau \rangle}
      & \\
      \inference {
      x \notin \text{\textbf{dom}}(\sigma) & x \notin \textbf{dom}(\tau) \\
      \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_immutable(\alpha)
      \\ \langle C_1, \sigma + \{x \mapsto v\} , \tau
      \rangle \longrightarrow \langle \sigma', \tau \rangle}
      {\langle\textbf{begin var }x : \{\upsilon : T\text{ }|\text{ }e\} = v;C_1 \textbf{ end}, \sigma, \tau, \mathcal{R} \rangle 
      \longrightarrow \langle \sigma'' \setminus \{x\}, \tau \rangle}
    \end{tabular}
  \end{center}
\end{figure}

\par
We address the ambiguity brought up using this semantic. The program in figure 
\ref{fig:amb_refinement_vars} is no longer a valid program as 
$y$ is a mutable variable and is forbidden from appearing in a refinement type. 
One would have to rewrite the declaratio of $y$ using \textbf{const} which 
forbids it from being assigned to after initialisation. 
It is easy to see by restricting free variables in the refinement predicate we ensure 
that the expression stays the same throughout its existence, avoiding any 
complications regarding mutation.

\par
The approach laid out here is a simple approach to dealing with the ambiguity of 
having mutability and refinement types. Interestingly, C++ utilises the same 
strategy for templates values, where a value passed into a template must be a 
constant expression. 

\par
We could potentially adapt a clever approach used by the Java programming 
language to overcome variable mutation in Anonymous classes. Java requires that 
any variables accessed by an anonymous class that is part of 
its enclosing scope to be final or \textit{effectively final} 
\cite{effectFinal}. An effectively final variable is a variable that is not 
declared immutable but its value is not changed after declaration. While this 
does improves some flexibity as one do not need to use the \textbf{const} 
statement for declaration, it behave the same for all intents and purposes. 
For this reason we consider this additional feature as future consideration and 
out of scope for this current project. 

\par
One significant strong point in requiring constants in the refinement predicate 
is that one can easily have compile time checking. In programming languages 
the value of immutable variables are often available at compile time, this 
allows one to have a compiler with capabilities of evaluating the refinement 
predicate and type check a refinement type at compile time rather than at run 
time. 

\par
The limitation of this approach is of course the fact that one has to strategically 
declare the variables needed, in some cases one might not be able to declare 
immutable variable but still want the ability to define a refinement type.

\subsection{Refinement Predicate Closure}
If we further analyse our design, we notice that our main concern is for the 
refinement predicate to stay static, any changes in the program context should 
not change its definition. In this section, we propose a design which allows us 
to keep variables in a refinement predicate constant without the need of 
defining the variables immutable.

\par
First we recap two ideas commonly found in programming language, \textit{Closures} 
\cite{closures} and \textit{Pass By Value} \cite{pbv}.
In languages such as JavaScript, Python and Ruby, a closure is simply a  
function enclosed with an environment. Closures have access to 
variables from the calling context, even if the original variable goes out of 
scope. Semantically, a closures can be modelled as a data structure mapping 
functions to environment as demonstrated in the extended lambda calulus proposed by 
Gerald J. Sussman and Guy L. Steele Jr in this paper \cite{closureLambdaOp}. 

\par
In C/C++, \textit{pass by value} \cite{pbv} is a way of passing a 
parameter into a function in a way that any modification to the 
parameter in the function does not reflect changes outside and vice versa. In 
order to make free variables in a predicate independent, we designed a similar 
approach where we bind free variables with a value. 

\par
Taking the example program in figure \ref{fig:amb_refinement_vars} if the 
variable $y$ in the refinement predicate is different from the variable 
$y$ in the program state, then any changes to the variable $y$ will not 
affect the type definition and the program 
will stay well typed.

\par
Our appraoch is to have the predicate to evaluate in a different environment, we 
denote that every refinement predicate has their own evaluation context, this 
will be the program context at the time of the type definition. We define a new 
mapping $\mathcal{R}$.

\begin{center}
  $\mathcal{R}: T \mapsto (\sigma, \tau)$   
\end{center}

The mapping $\mathcal{R}$ is used to associate a refinement type with its 
evaluation context. The said context is simply the $\sigma, \tau$ at the time of 
the refinement type creation.

\par
We formalise this behaviour in the evaluation rules below. Our signature is now 
$\langle C, \sigma, \tau, \mathcal{R} \rangle$, previously defined operational 
semantics should be updated as such. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {
      \langle C_1, \sigma, \tau + \{y \mapsto \{\upsilon : A\text{ }|\text{ }e\}\}, \mathcal{R}'
      \rangle \longrightarrow^{*} \langle \sigma', \tau, \mathcal{R} \rangle      
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}}
      {\langle\textbf{begin typedef } y = \{\upsilon : T\text{ }|\text{ }e\};C_1;e_1\textbf{ end}, 
      \sigma, \tau, \mathcal{R} \rangle \longrightarrow \langle \sigma', \tau, \mathcal{R} \rangle} 
      & \\
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \textbf{dom}(\sigma) 
      & \langle C_1, \sigma', \tau, \mathcal{R} \rangle \longrightarrow^{*} \langle 
      \sigma'', \tau, \mathcal{R} \rangle
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}} 
      {\langle\textbf{begin var }x : \{\upsilon : T\text{ }|\text{ }e\} = v_0; C_1 \textbf{ end}, \sigma, \tau, \mathcal{R} \rangle 
      \longrightarrow \langle \sigma'' \setminus \{x\}, \tau, \mathcal{R} \rangle}
    \end{tabular}
  \end{center}
  \caption{Evaluation of Refinement Type with Closures}
\end{figure}

\par
We define $\sigma_1$ and $\tau_1$ as a copy of the program state $\sigma$ and 
$\tau$ and attach this to the type using the context $\mathcal{R}$. 

\par
In order to type check refinement types with closures, we update our refinement 
typing judgement with the addition of $\mathcal{R}$

\begin{center}
  \begin{tabular} {c}
    $\mathcal{R},\Gamma \vdash_{R} x : \{\upsilon : T\text{ }|\text{ }e\}$
  \end{tabular}
\end{center}

\par
Our new typing judgement now retrieves the associated context from $\mathcal{R}$ 
and evaluates appropriate, the new rule is defined in figure. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference{\Gamma \vdash e_1 : T_1 
      & (\sigma, \tau) = \mathcal{R}(\{\upsilon : T_1\text{ }|\text{ }e\}) 
      & \langle e[e_1/\upsilon], \sigma, \tau \rangle \Longrightarrow^{*} \langle \textit{true}, \sigma, \tau \rangle}
      {\mathcal{R}, \Gamma \vdash_{R} e_1 : \{\upsilon : T_1\text{ }|\text{ }e\}} 
    \end{tabular}
  \end{center}
  \caption{Type Checking a Refinement Type with $\mathcal{R}$}
\end{figure}


\par
The typing judgement behaves similar to our initial judgement, the only 
exception here is the context being evaluated in. When type checking against a 
refinment type, the evaluation context is retrieved from $\mathcal{R}$, the 
predicate $e[e_1/\upsilon]$ is then evaluated under the context.

\par
It address the ambiguity in figure \ref{fig:amb_refinement_vars} by specifying 
a concrete behaviour. $BoundedIntY$ being bounded to $10$ throughout, even when 
the free variable $y$ is reassigned to another value.
 
\par
Unlike C++, this form of sematics allows one to utilise non-constant expression 
in type definition. This is achieved by fixing a refinement type with an 
environement as one does in closures. 
 
\subsection{Summary}
In this section, we proposed a scenario where our refinement type checker is 
underspecified in the presence of mutation. We proposed two different approaches 
to complete our specification, approach one utilise constants and immutable 
variables to disallow modification of free variables used in a refinement 
predicate. The second utilises closures and value bindings to ensure 
consistency. 

\par
While the proposed solutions are effective in dealing with mutation on local 
variables. As the language starts incorporating more features, our current 
design becomes underspecified yet again. In the next section, we will analyse 
the behaviour of our system in the presence of dynamic memory allocation.

\section{Refinement Types and Pointers}
We previously proposed a set of rules that specify behaviour of refinement 
types with regards to local variables and we learn that we can keep behaviour 
consistent if we restrict changes to the variable. However, our solution does 
not accomodate for reference variables and pointers. If a refinement type 
relies on pointers in the refinement predicate then the simple act of declaring 
them immutable is not enought. Pointers value can be altered through aliasing. 

\par
In this section we will first extend our syntax with the notion of dynamically 
allocated memory. Later we will study the feature interaction between 
pointers and refinement types in order to identify a consistent behaviour. 

\subsection{Introducing Heap Allocated Memory}
In programming languages, there are three different types of memory allocation, 
static, stack and heaps \cite{heapVsStack}. While we have not explicitly 
discussed our memory management model, it is rather obvious that Simple-$R$ 
operates on a stack based model. It is apparent in the behaviour of local 
variables which are inaccesible once out of scope as discussed in our scoping rules. 

\subsubsection{Syntax Extension}
First we will have to extend our syntax to accomodate these new features, we define 
the new syntax in figure \ref{fig:ptr_syntax}. For simplicity and safety, 
we have ommited the need for manual memory management and we 
assumme that \textit{Automatic Garbage Collection} \cite{GC} is present in 
the language. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Types} & $T$ & $:$ $...\text{ }|\text{ }T\text{ \textit{ref }}$ \\
      \textit{Expressions} & $e$ & $:$ $...\text{ }|\text{ }!e_1\text{ }|\textbf{ new}(T, e_1)$\\
      \textit{Commands} & $C$ & $:$ $...$ $|$ $!e_1 := e_2$ \\
      \textit{Values} & $vals$& $:$ $...\text{ }|\text{ }h \in \{h_1,h_2, h_3...\} $ \\
      \textit{Heap} & $\Delta$& $:$ $h \mapsto vals$\\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$R$}
  \label{fig:ptr_syntax}
\end{figure}

\paragraph{Types}
We introduce a new type, $T$ \textit{ref} as a reference type that behaves like 
a pointer in C/C++, like pointers, references are typed and the value of a reference 
is a heap address. 

\paragraph{Expressions}
The following expressions are introduced into the language, unlike C/C++ 
where one is allowed to retrieve the address of a local variable, in our 
system one may only create a pointer through the use of \textbf{new} as 
one would in a language like Java.
\begin{itemize}
  \item $!e_1$ to dereference the heap address held by expression $e_1$.
  \item \textbf{new}($T, e_1$) to allocate and return a $T$ \textit{ref} with the 
  value obtained after evaluating $e_1$.
\end{itemize}

\paragraph{Commands}
We add a new command that dereference a heap address and modifies its underlying 
value. The command $!e_1 := e_2$ changes the value at heap address $h_1$ to the 
value after evaluating $e$.

\paragraph{Values}
We added two new values to the language, $h$ is simply a heap address in the set 
$\{h_0, h_1, h_2...\}$ and $nil$ as an empty reference. 

\paragraph{Heap}
Finally, we define a heap context $\Delta$ as a mapping from heap address to values.  
It represents the set of heap addresses that are currently in use and we use 
the notation, $\Delta(h)$ to get the value held at a particular heap address. 

\subsubsection{Typing Rules}
We first define the typing judgement for the base types for references. 

\begin{center}
   $\Gamma \vdash h : T\textit{ ref}$ (Heap address type)
\end{center}

\par
We define the rest of the typing judgement as shown below. 
The typing judgements are straightforward, 
dereferencing a heap address of type $T \textit{ref}$ yields a value of type $T$ and 
allocating a new heap address with type $T$ gets a reference of the same type.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1 : T\textit{ ref}}{\Gamma \vdash !e_1 : T}[(dereferencing)]
      \text{ }
      \inference {\Gamma \vdash e_1 : T}{\Gamma \vdash \textbf{new}(T, e_1) : T\textit{ ref}}[(\textbf{new} ref)]
      & \\
      \inference {\Gamma \vdash e_2 : T & \Gamma \vdash e_1 : T\textit{ ref}} {\Gamma \vdash_{C}\text{ }!e_1 := e_2 : void}
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Ref Type}
\end{figure}


\subsubsection{Basic Operational Semantics}
Lastly, we define the operational semantics for the new expressions in figure 
\ref{fig:sos_pointers}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {
      \langle e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle e_1', \sigma, \tau, \Delta \rangle}
      {\langle !e_1, \sigma, \tau, \Delta \rangle \Longrightarrow 
      \langle !e_1', \sigma, \tau, \Delta \rangle} [(Deref expr)]
      \text{ }
      \inference {h_1 \in \textbf{dom}(\Delta) & v = \Delta(h_1)}
      {\langle !h_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle v, 
      \sigma, \tau, \Delta \rangle} [(Deref)]
      & \\
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle e_1', \sigma, \tau, \Delta \rangle}
        {\langle !e_1 := e_2, \sigma, \tau, \Delta \rangle \Longrightarrow \langle !e_1' := e_2, 
        \sigma, \tau, \Delta' \rangle} [(P-Assign expr 1)]
      & \\
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle e_1', \sigma, \tau, \Delta \rangle}
        {\langle !h_1 := e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle !h_1 := e_1', 
        \sigma, \tau, \Delta' \rangle} [(P-Assign expr 2)]
      & \\
      \inference {h_1 \in \textbf{dom}(\Delta) & \Delta' = \Delta[h_1 \mapsto v_1]}
        {\langle !h_1 := e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle void, 
        \sigma, \tau, \Delta' \rangle} [(P-Assign)]
      & \\
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle e_1', \sigma, \tau, \Delta \rangle}
        {\langle \textbf{new}(T, e_1), \sigma, \tau, \Delta \rangle \Longrightarrow \langle \textbf{new}(T, e_1), 
        \sigma, \tau, \Delta' \rangle} [(P-Alloc expr)]
      & \\
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta + \{h \mapsto v\}}
        {\langle \textbf{new}(T, v), \sigma, \tau, \Delta \rangle \Longrightarrow \langle h, 
        \sigma, \tau, \Delta' \rangle} [(P-Alloc)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers}
  \label{fig:sos_pointers}
\end{figure}

\par
Pointers are allocated using the \textbf{new} expression which takes a type $T$ 
and a value $v$, the evaluation rules allocated a new heap address $h$ that is 
not currently present, assigns it the value $v$ and returns the address. The 
value can be retrieved and modified through dereferencing, shown in the first two 
rules. 

\subsection{Ambiguity of Refinement Types and Pointers}
The introduction of pointers provides the programmer with multiple new tools. 
Features such as pass-by-reference and aliasing are now at their disposal. 
However with the introduction of new features, the feature interaction problem 
arises once again and the relation between pointers and refinement types is 
unclear. Throughout the text we showed that we can avoid ambiguous behaviour 
between mutation and refinement types using immutability or closures. This appears 
not to be the case with pointers, to show that consider the code snippet in figure
\ref{fig:amb_refinement_pointers}. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{begin const }$y\text{ }:\text{ } int\textit{ ref} = \textbf{new}(int, 10);$\\
    \tab\textbf{begin typedef }$BoundedIntY$ = $\{i : int\text{ }|\text{ }i <\text{ }!y\}$; \\ 
    \tab\tab\textbf{begin var }$z\text{ }:\text{ }BoundedIntY = 6;!y := 5$\textbf { end} \\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Ambiguity of Pointers in Refinement Predicate}
  \label{fig:amb_refinement_pointers}
\end{figure}

\par
In this scenario, we declare a constant $y$ as a pointer to an int, 
initialised with the value 10. The expression $!y := 5$ indirectly modifies 
the definition of the type $BoundedIntY$, making $z$ ill-typed. 

\par
Our previously defined semantics proves to be underspecified and does not 
provide a definite behaviour. The appraoch where we require all free variables in a 
refinement predicate to be constant however this is not sufficient for pointers. 
A constant pointer variable simply restrict the address held by the pointer to be 
changed, manipulating the underlying value is still very much possible. 
Moreover, using closures also fails to prevent the ambiguity as one can easily 
modify the heap address and have he changes reflect within the closure. Our  
semantics resemble Java's \textit{final} mechanics, whereby while the reference variable 
cannot change, the underlying value can. For instance, in Java,  
\verb|final A x = new A()| declares a ``constant'' \verb|x| of type \verb|A|, while 
\verb|x = y| is forbidden, the value of \verb|x| can still be modified 
using \verb|x.value = 10|.

\par
In order to address this case, our previously proposed semantics has to be 
extended to address two different features. One is to prevent the pointer from 
modifying the underlying heap address and no aliases should be able to modify 
the address indirectly.

\par
In C/C++, one is able to declare a pointer to a constant, we would require 
the same mechanism in Simple-$R$. It is important to note the 
difference between an immutable pointer and a pointer 
to an immutable. The latter allows the pointer variable to change. In order to 
concrete differentiate the two in a definite manner, we introduce 
a new predicate $is\_nonrewriteable(h)$ to specify if the value held at a 
specific memory address is immutable. The $is\_nonrewriteable(h)$ predicate 
holds if and only if the heap address $h$ is a constant and cannot be modified. 

\par
While this predicate behaves exactly as the $is\_immutable(x)$ predicate defined 
previously, we made the distinction between the two as the one operates on variables 
and the other operates on heap addresses. 

\par
In order for one to define an immutable pointer we added a new expression 
\textbf{newconst}$(T, e_1)$ which allocates a constant value and return its 
pointer. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}      
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ \textbf{newconst}}(T, e_1)$ \\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$R$}
\end{figure}

\par
The typing judgement in figure \ref{fig:tj_const_ptr} above formalises the 
typing rules for this new expression. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e : T} 
        {\Gamma \vdash \textbf{newconst}(T, e): T \textit{ ref}}[(\textbf{newconst} type)] 
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Pointer to Constants}
  \label{fig:tj_const_ptr}
\end{figure}

\par
Notice that unlike C/C++, Simple-$R$ does not have the notion of 
\textit{referencing}, the only way to obtain a pointer is through the use of 
\textbf{new} or \textbf{newconst}. This form of semantic avoids pitfalls in C/C++ 
where one gives a pointer to a constant the address of a mutable variable as 
demonstrated in the program below.
\begin{center}
  \begin{tabular}{l}
    \verb|int x = 10;| &
    \verb|const int *p = &x;|&
    \verb|x = 5;|&
  \end{tabular}
\end{center}

\par
The lack of referencing allows us to define semantics that completely forbid 
modification on a heap location. We define the operational semantics for the 
new expression in figure \ref{fig:sos_const_ptr}, the rules simply restrict the 
ability to modify the value of a constant heap address.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \Longrightarrow \langle e_1', \sigma, \tau, \Delta \rangle}
        {\langle \textbf{newconst}(T, e_1), \sigma, \tau, \Delta \rangle 
        \Longrightarrow \langle \textbf{newconst}(T, e_1), 
        \sigma, \tau, \Delta' \rangle} [(PConst-Alloc expr)]
      & \\
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta + \{h \mapsto v\}}
      {\langle \textbf{newconst}(T, v), \sigma, \tau, \Delta \rangle \Longrightarrow \langle h, 
      \sigma, \tau, \Delta' \rangle} [(PConst-Alloc)]
      & \\
      \inference {h_1 \in \textbf{dom}(\Delta) & \neg is\_nonrewritable(h_1) & \Delta' = \Delta[h_1 \mapsto v_1]}
      {\langle !h_1 := v_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v_1, 
      \sigma, \tau, \Delta' \rangle} [(P-Assign)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers to Constants}
  \label{fig:sos_const_ptr}
\end{figure}

\par
The introduction of immutable heap address allows us to specify a concrete 
behaviour for refinement types in the presence of pointers. Adopting a similar 
strategy to our previous restriction, we require all pointers present in a 
refinement predicate to not only be a constant itself but it must also be 
referencing a constant value. In the following text, assume that we are 
adopting and extending the semantics discussed in section 3.4.3 where we 
restrict mutation on free variables in a refinement predicate. 

\par
We define a new predicate that will be used in our definition, $is\_ref(x)$ 
returns true if and only if $x$ is a pointer variable.
\par
Formally, $is\_ref(x) \Leftrightarrow \Gamma(x) = T\textit{ ref}$.

\par
The new specification is defined in figure \ref{fig:immu_pointer_typedef}.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      a \notin \text{\textbf{dom}}(\sigma) & a \notin \textbf{dom}(\tau) \\
      \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_immutable(\alpha)
      \\
      \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_ref(\alpha) \Rightarrow is\_nonrewriteable(\sigma(\alpha))
      \\ \langle C_1, \sigma, \tau + \{a \mapsto \{\upsilon :T\text{ }|\text{ }e\} 
      \rangle \longrightarrow \langle \sigma', \tau \rangle}
      {\langle \textbf{begin typedef } a = \{\upsilon :T\text{ }|\text{ }e\};C_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \sigma', \tau \rangle}[(Refine def)]
    \end{tabular}
  \end{center}
  \caption{Typedef refinement types with pointers}
  \label{fig:immu_pointer_typedef}
\end{figure}

\par
The new specification retains all constraints present and make a crucial 
new addition. In addition to all variables being immutable, a new rule states 
that all pointer variables in the expression must to be pointing to a constant. 
This ensures that the value pointed 
to by the pointer would not change throughout the type's existence. Furthermore, 
we can be sure that any aliases to the heap 
address will not be able to modify the memory address because of the rules 
specified in figure \ref{fig:sos_const_ptr}.

\par
The example program showed previously in figure \ref{fig:amb_refinement_pointers} 
is now an invalid program. To make it valid we adopted the newly defined rules 
and rewrote it in figure \ref{fig:valid_ptr_program}.

With our newly defined rules the program in figure \ref{fig:amb_refinement_pointers} 
becomes invalid, we can rewrite our program to be correct as shown in the example below. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{begin const }$y\text{ }:\text{ } int\textit{ ref} = \textbf{newconst}(int, 10);$\\
    \tab\textbf{begin typedef }$BoundedIntY$ = $\{i : int\text{ }|\text{ }i <\text{ }!y\}$; \\ 
    \tab\tab\textbf{begin var }$z\text{ }:\text{ }BoundedIntY = 6;\textbf{skip}$\textbf { end} \\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Pointers in Refinement Types}
  \label{fig:valid_ptr_program}
\end{figure}


\subsubsection{Refinement Type Closure and Pointers}
Recall that our second approach uses closures to handle refinement type, 
this approach can easily be modified to work with pointers using a 
similar strategy. If one declares a refinement type $T$, then in addition to 
the context being copied, we require any pointer variables in the refinement 
predicate to be constant. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {
      \langle C_1, \sigma, \tau + \{y \mapsto \{\upsilon : A\text{ }|\text{ }e\}\}, \mathcal{R}'
      \rangle \longrightarrow^{*} \langle \sigma', \tau, \mathcal{R} \rangle
      \\ \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_ref(\alpha) \Rightarrow is\_nonrewriteable(\sigma(\alpha))      
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}}
      {\langle\textbf{begin typedef } y = \{\upsilon : T\text{ }|\text{ }e\};C_1;e_1\textbf{ end}, 
      \sigma, \tau, \mathcal{R} \rangle \longrightarrow \langle \sigma', \tau, \mathcal{R} \rangle} 
      & \\
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \textbf{dom}(\sigma) 
      & \langle C_1, \sigma', \tau, \mathcal{R} \rangle \longrightarrow^{*} \langle 
      \sigma'', \tau, \mathcal{R} \rangle
      \\ \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_ref(\alpha) \Rightarrow is\_nonrewriteable(\sigma(\alpha))
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}} 
      {\langle\textbf{begin var }x : \{\upsilon : T\text{ }|\text{ }e\} = v_0; C_1 \textbf{ end}, \sigma, \tau, \mathcal{R} \rangle 
      \longrightarrow \langle \sigma'' \setminus \{x\}, \tau, \mathcal{R} \rangle}
    \end{tabular}
  \end{center}
  \caption{Evaluation of Refinement Type with Closures}
\end{figure}

\par
In this section we extended our language to include advanced features such 
as pointers and aliasing. We observed how introducing new form of 
variables brings new types of mutation into the language and therefore 
requires us to adapt new strategies in our specification. We presented  
a new system that characterised the behaviour of pointers in the context of 
refinement types. Our system forbids mutation on heap locations which ensures 
consistency in refinement types. Finally, we incorporate these new requirements 
into our language, extending our previously defined semantics. 

\section{Summary}
In this chapter we constructed Simple-$R$, an imperative programming language with native 
support for refinement types. We distinguished our 
system apart from exisiting work by basing the underlying calculus 
on a simple ``\textit{WHILE}'' language 
rather than the $\lambda$-calculus, to the best of our knowledge this form of 
specification has not been done previously. The syntax and semantics of our 
language remsembles C/C++, enhancing the accessibility of our work.

\par
Throughout the chapter we demonstrated how type checking refinement types 
statically proves to be undecidable in our system, we drew parallels by comparing 
type checking mechanics of established languages such as downcasting in Java 
where the validity of types cannot be checked at compile time. 
Adopting a similar strategy, we presented a form of hybrid type checking 
that overcomes this problem, our type checker verifies as much as possible 
statically and defers more complex verification to be done dynamically. 

\par
However, we observed that naive runtime type checking has ambiguities 
because of the presence of mutation. We identified these underspecifications and 
proposed two ideas that concretely characterise the behaviour of refinement 
types in a mutable environment. Our first approach is based on the 
idea of immutable variables and forbidding mutation on variables associated 
with the refinement predicate. The second approach utilises the notion of closures, 
a copy of the state is made at the time of type declaration and the copied 
state is used for type checking. 

\par
Finally, we explored the idea of adding dynamically allocated memory into the 
language and how it leads to more ambiguity. We discussed the difference between 
immutable reference variable and an immutable object using practical examples in 
Java and C/C++. Concluding the chapter, we addressed these ambiguities by 
formalising new semantics that completes the language.


\chapter{Further Work}

\chapter{Related Work}

\chapter{Summary and Conclusions} 


\appendix
\singlespacing

\printbibliography

\end{document}
