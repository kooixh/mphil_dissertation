%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 

\documentclass[a4paper,12pt]{report}
%TC:group tabular 1 1


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Xiu Hong\ Kooi\xspace}
\def\authorcollege{Wolfson College\xspace}
\def\authoremail{xhk20@cam.ac.uk}
\def\dissertationtitle{Investigating the Behaviour of Dependent Types in an Imperative Programming Language}
\def\wordcount{0}


%\usepackage[dvips]{epsfig,graphics} 
\usepackage{epsfig,graphicx,verbatim,parskip,tabularx,setspace,xspace}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{semantic}
\usepackage{float}

\usepackage{tabto}

\newenvironment{tabs}[1]
 {\flushleft\TabPositions{#1}}
 {\endflushleft}

\usepackage[british]{babel}
\usepackage[%
  backend=bibtex      % biber or bibtex
%,style=authoryear    % Alphabeticalsch
 ,style=numeric-comp  % numerical-compressed
 ,sorting=none        % no sorting
 ,sortcites=true      % some other example options ...
 ,maxbibnames=99
 ,block=none
 ,indexing=false
 ,citereset=none
 ,isbn=true
 ,url=true
 ,doi=true            % prints doi
 ,natbib=true         % if you need natbib functions
]{biblatex}
\usepackage{biblatex}
\addbibresource{./dissertation.bib}


%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 
\textit{Type systems} \cite{typesystem} have been one of the most extensively researched field in 
Programming Languages. They act as a way from improving the reliability of a 
language by enforcing rules, preventing operations being applied on 
incompatible data. Type systems can be broken down into multiple categories but 
two of the most well known are \textit{Static} \cite{staticTyping} and 
\textit{Dynamic} \cite{dynamicTyping} typing. Mainstream programming 
languages such as \textit{Java} \cite{java}, \textit{C} \cite{c} and \textit{C++} \cite{cpp} 
uses the former while languages like \textit{Python} \cite{python} and 
\textit{JavaScript} \cite{js} uses the latter. 
Over the years, programming languages have included more powerful and flexible 
type systems, languages like \textit{C\#} \cite{cSharp} and \textit{Go} \cite{goInferenceType} allow 
\textit{type inference} \cite{inferenceType}, using a feature called \textit{Reflection} 
Java and Python can even achieve \textit{Duck Typing} \cite{javaDuckType}.
\par
However, as much as we have studied about type systems, \textit{Dependent Types} 
\cite{depenTypeAtWork} remains uncommon in the industry. While the theory of dependent types has been 
established several decades ago, only a small number of languages has 
integrate full dependent type support, most of them being functional languages. 
Dependent types allows the programmer to create types whose definition depends 
on a value. A type system that provides such refined control over the values it 
can take unlocks possibility that are previously unavailable such as 
domain-specific type checking at compile time. Furthermore, it acts as a built 
in ``error-handling'' code and could potentially 
reduces the lines of code a programmer needs to write. An in depth 
definition of dependent types is provided in the next section.

\par
The expressive nature of dependent types allow one to define complex 
mathematical assertations and hence lends itself to theorem proving systems. 
Mutliple functional languages such as \textit{Epigram} 
\cite{epigram} and \textit{Agda} \cite{agda} has 
built in support for dependent typing. However they remain niche and more 
mainstream languages like Java and C++ does not get the luxury. In chapter 2 of 
this dissertation we will be providing an in depth analysis of the current state 
of dependent types in programming languages and answer why dependent types are 
not more prominant in languages, in particular imperative languages.

\par
Multiple past research has studied and show the feasibility of an dependently typed 
imperative language. These studies has expressed the semantics of 
how an imperative languages would interact with dependent types and in some 
cases created a new language from the ground up. While we find these work novel 
and provided highly technical explanation to the field, they fail to caputure 
how this could relate to mainsteam programming languages. Furhtermore, the 
semantics provided in these studies are very complex with advanced language 
features, we propose that a more simple and barebone definiton will allow easier 
access to the literature and motivate more studies into dependenty types. 

\par
This dissertation serves as a document for our findings and is organised as 
follows. This first chapter serves as an introduction to dependent types and the 
motivation behind our work.

\par
Chapter 2 if a survey on the current state of dependent types 
in programming languages. Different languages with varying paradigm are explored 
and summarised in order to better understand the extend of their support 
for dependent types. Functional lanaguages and theorem provers are studied to 
understand how dependent types behave in their natural environment. We 
extensively studied C++ as its templating engine bears strong resemblence to 
dependent types and we observe its limitation. 
We conclude the chapter by proposing how our project will address these limitations. 

\par
In chapter 3 we will be introducing a dependently typed imperative language. 
Our language, named Simple-$\Pi$ is a First-Order Programming Language which 
highly resembles the C programming language. Our aim with the language is to 
capture the core behaviour of dependent types and thus for the pursuit 
of simplicity is kept at a minimal with 
only the fundamental features. In this chapter, we will be 
defining the syntax, typing rules and semantics 
of a basic language with dependent types support which serves as a basis 
which will be studied throughout the chapter. 
We then present the semantics of Simple-$\Pi$, in addition 
to the basic operational semantics, we will raise
multiple scenarios that dependent types cause ambiguity in imperative programming. 
We start by discussing the impact of mutability has on dependent types and 
answer the problem by proposing different solutions to resolve the 
ambiguity and observes how these approaches differs. 
We follow up our findings by introducing pointers and how the approach used to 
address mutability can be adapted to handle alias variables. Finally we conclude 
the chapter by showing an example of building arrays with dependent types. 

\par
In chapter 4 we will discuss our work with regards to the 
existing work done in the area and how it completments the literature.
Finally we will conclude by discussing advanced features that can be integrated 
into our languages and how it can further complicate the language. We will also 
discuss some of the other considerations that need to be taken account when 
thinking about incorporating dependent types into a real language. 

\section{What Are Dependent Types}
In this section we will be providing the definitions of dependent types.

\subsection{Basic Definition}
At a very high level dependent types are types that depends on the value of 
another type. For example, we can define a type that captures only the even 
integers using the definition 
\verb+type EvenInt := { i : Int | i % 2 = 0}+. In this case we 
can say that the type EvenInt \textit{EvenInt} depends on the type \textit{int}.
Another commonly used example to describe dependent types would be a type like 
\verb+type FixVec<T, N> := { v : Vec<T> | len(v) = N}+, this type definition defines 
a vector or array of elements with type $T$ that always contains $N$ elements.

\subsection{Dependent $\Pi$ Types}
We can capture the definition mathematically using the notion of \textit{dependent 
product types}, i.e. $\Pi$ type. This is also sometimes referred to as 
\textit{dependent function type} as in this definition we construct a function 
$F: A \rightarrow B$. The function $F$ takes an element of type $A$ and 
gives us an element of type $B$ which depends on $A$. We express it 
mathematically using the $\Pi$ notation as
\begin{center}
 \begin{tabular}{l}
   $\prod x: A.  F(x)$
 \end{tabular} 
\end{center}

In this definition, $F(x)$ is the type family for the type $B$ that depends on $A$.
However $F$ could be a constant function, so we can also express the definition 
as $\Pi x:A.B$, in this case $B$ does not depend 
on the value $x$. Using the \textit{EvenInt} example from earlier, 
it can be defined as 
$\Pi x:Int.\text{ }\{ i:Int\text{ }|\text{ }i\text{ }\%\text{ }2\text{ }= 0\}$.

\par
Interestingly, the dependent product type correspond to the 
\textit{forall quantifier} as per 
the \textit{Curry–Howard correspondence}. The idea is that the dependent 
function $F(x)$ correspond to predicate $P(x)$ and thus the dependent product 
type has a one-to-one correspondence to $\forall x: A. P(x)$.

\subsection{Dependent $\Sigma$ Types}
In addition to the dependent product type, we have the notion of \textit{dependent sum 
types}, written as $\Sigma$ type. This is often referred to as the 
\textit{dependent pair type} as the resulting type here is an ordered pair. 
Specifically the resulting pair $\langle a,b \rangle$ is ordered such that the 
second element depends on the first element. The 
mathematical definition is similar to that of the product type
\begin{center}
 \begin{tabular}{l}
   $\langle a,b \rangle :\sum x: A.  F(x)$
 \end{tabular} 
\end{center}
In the case $a:A, b: F(x)$, similarly, $F$ could be a constant function and thus 
the expression is $\Sigma x:A.B$. Consider the following example, 

$\Sigma x: Int.\{y:Int\text{ }|\text{ } y = x * 2\}$, then the type would 
contain values like $\langle 1,2 \rangle$ and $\langle 4,8 \rangle$ where the 
second pair is doubled the first.

\par
Like the dependent product type, the dependent sum type correspond to a 
universal quantifier, in this case, the \textit{existential quantifier}. As 
per the Curry–Howard correspondence, $F(x)$ corresponds to predicate $P(x)$ 
thus $\Sigma x:A.F(x)$ correponds to $\exists x: A. P(x)$.

\par
While both dependent product types and dependent sum types are important to the 
literature, the project itself will mainly focus on the former. we believe that 
the the notion of pair in dependent sum types prove to be redundant in 
the construction a programming language and does not provide any additional 
value. The dependent product type is largely adequate for our goal.

\section{Overview of a Dependently Typed Language}
In this section we will discuss at a very high level the behaviour one would 
expect from a dependently typed language, its benefits and use cases.

\subsection{Language Behaviour}
The key behaviour we are interested in is regarding compile time type checking. 
For instance, using the example above, if a type is defined as an \textit{EvenInt} 
then if at any point in the code it becomes odd then it should be caught at 
compile time. 

\par
Consider the psedocode below: 
\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  function f(int x) {
    if (x \% 2 == 0) {
      ...
    }
    throw error ``x has to be even''
  }
  
  function dependent_f(EvenInt i) {
    ...
  }
  \end{lstlisting}
  \caption{Dependenty Typed Language Behaviour}
\end{figure}

\par
The function \textit{f} above checks whether the argument $x$ is even, if it 
isn't then it throws a runtime error. If dependent type is available, then if an 
invalid argument is passed in it should signal an error at compile time, saving the 
error handling code as shown in \textit{dependent\_f}. 

\subsection{Benefits of Dependent Types}
As we seen in the previous subsection, dependent types allows programmer to 
define much richer and expressive types that can be checked at compile time. The 
addition of dependent types allow for safer code as it is able to guarentee certain 
properties. 

\par
Furthermore, using dependent types eliminates the need for many trivial error 
handling code. Around 4\% of code in every program is dedicated to error 
handling \cite{errorHandlingCode}, dependent types will be able to reduce the 
numbers and allow the programmer more time to write the logical part of the 
code, indirectly leading to more robust codebases.

\par
Consider a banking system where users are able to transfer and withdraw 
money using a function, 
in order to prevent overdraft one might be able to define a function that takes 
a type \textit{Amount$<$T$>$}, a double type that is always 
greater than 0 and less than \textit{T}, where \textit{T} is the current balance in the account. 
This approach guarantees the amount is always valid without the need of writing 
error handling code. This example demonstrated using an object-oriented style 
language by Vasconcelos \cite{objOritentedDependentType}.


\section{Motivation}
Dependent types appears to be one of the niche fields in programming language 
theory and type theory research. I argue that this is the result of the 
difficult barrier of entry. Research in dependent types presented are usually 
highly complex and requires substantial prerequisite. Type systems presented in 
these paper often assumes full knowledge of \textit{The Lambda Calculus} 
\cite{lambdaCalculus} or uses the concept of \textit{Monads} \cite{monads}. 
While these are established framework commonly used to express and reason about 
computation, with the addition of normal types and dependent types, the 
underlying logic becomes hard to follow. 

\par
Similarly, research in the area that branch away from the convention of building 
a dependent type system on the lambda calculus often showed highly complex 
language features such as object orientation and dynamic memory allocation. The 
purpose of these research often are to demonstrate the feasibility of 
incorporating dependenet types in complex languages rather than providing an 
overview of the concept. 

\par
Our project is motivated by the apparent lack of accesible literature on the 
theory of dependent types. We aim to present a simple, restricted framework that 
captures the essence of dependent types. The said framework will be presented as 
an extension to \textit{WHILE language} \cite{whileLanguage}. Created as a tool 
to aid the study of programming language theory, we believe it strongly satisfy our 
requirement of accessibility with its simple syntax and semantics. 

\par
At the end of the project we aim to achieve the following, i) Survey the state 
of dependently typed languages and their differences, ii) Describe a dependently 
typed language based on the WHILE language, iii) Explore the ambiguity of 
dependent types in an imperative environments, iv) Demonstrate the use of 
dependent types to build further language features, v) Discuss how our work 
compliments the literature. 



\chapter{Background: State of Dependently Typed in Language} 
In this chapter we will be reviewing the current knowledge of dependent types 
in different programming languages. It will cover languages with full dependent 
types support as well as some languages with similar concepts and point out how 
it differs from dependent types. Lastly we will summarise all these languages 
and point out some limitations and unknowns. 

\section{Functional Languages}

In this section we will be examining three functional languages with 
dependent typing. Functional languages 
uses the \textit{functional programming} \cite{overviewFP} paradigm which is a programming 
paradigm that constructs program using a series of function applications. In 
this paradigm, functions return values as oppose to altering the state of the 
program. In this programming paradigm, the language focuses on describing 
\textit{what} the program will accomplish.

\par

Many functional languages has the notion of purity, i) A function will always 
return the same value when given the same arguments. ii) The evaluation of a 
function has no side effects (changes to the state of the program).

\subsection{Agda}

\textit{Agda} \cite{agda} is a purely functional language originally developed by Ulf Norell in 
1999 however the first appearance the current version known as Agda 2 is in 
2007. Agda has all the necessary constructs one would expect in a functional 
language such as first-class functions, inductive definitions, pattern matching, 
etc. In addition to being a functional language, Agda also serves an automated theorem prover. 
Agda is one of the few programming language with native dependent type support. 

\par
The code listing below is an example of defining a fixed length vector in 
dependent type. 

\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  data Nat : Set where 
  zero : Nat
  suc  : Nat -> Nat  
  
  data EvenNat : Nat -> Set where
  even-zero  : EvenNat zero
  even-plus2 : {n : Nat} -> EvenNat n -> EvenNat (suc (suc n))
  
  data Vec (A : Set) : Nat -> Set where
  [] : Vec A zero
  _::_ : {n : Nat} -> A -> Vec A n -> Vec A (suc n)
  \end{lstlisting}
  \caption{Dependent Types in Agda}
\end{figure}

\par
While Agda provides dependent type support, it remains a niche language. One of 
the reason being its paradigm, Agda is \textit{purely functional} \cite{purelyFP}, meaning that 
all functions are pure (i.e. not relying on the program state or other mutable 
data). Functional languages are generally considered harder to learn and grasp 
compared to other paradigms \cite{fpHarder}. Furthermore, the general lack of 
awareness and competent users who can program dependent types contribute to Agda 
being a niche language in the programming world and is 
predominantly used for theorem proving.

\subsection{Haskell}
\textit{Haskell} \cite{haskell} is a purely functional programming language first appeared in 1990. In 
contrast to Agda, Haskell is often considered a more general purpose programming 
language. Haskell is among the most popular programming languages and argubly 
the most popular ``pure'' language in the world \cite{pypl}. 
Haskell has even been adopted by software companies such as Facebook \cite{haskellFB}.

\par
Haskell is not a language that supports dependent types natively however many 
extensions has been developed to simulate the experience. 
Generalised Algebraic Data Types (GADTs) are a generalization of the 
algebraic data types, it allows the programmer to 
explicitly write down the types of the constructors \cite{haskellGADT}. 
\begin{figure}[H]
  \begin{lstlisting}
    data Expr = I Int        
          | Add Expr Expr 
          | Mul Expr Expr 
  \end{lstlisting}
  \caption{A GADT defintion for arithmetic operations in Haskell}
\end{figure}

Using the power of GADT one could define dependent types as so

\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat (n :: Nat) where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vec a (n :: Nat) where
      Nil  :: Vec a 0
      (:>) :: a -> Vec a n -> Vec a (n + 1)
  \end{lstlisting}
  \caption{Dependent Types in Haskell}
\end{figure}

\par
Although GADTs provide a way of simulating dependent types in Haskell and 
argubly enough for simple dependent typing enough for many cases. 
Haskell does not qualify as a fully dependent 
language due to the lack of certain features such as dependent functions. There 
have been proposals to add full dependent type support to Haskell however a lot 
of work remains to be done \cite{dependentHaskell, aRoleForDependentHaskell}. 
Furthermore, while Haskell is significantly more well known compared to Agda, it 
still lack the popularity of languages like Java and Python.

\subsection{Idris}
\textit{Idris} \cite{idris} is a dependently typed functional language first 
appeared in 2007. Idris bears similarity with Agda, both in terms of paradigm 
and type system. However the differ in one crucial way, Idris is designed to 
emphasise general purpose programming rather than theorem proving. Earlier one 
we stated that one of the less desirable property of Agda was its niche because 
of its emphasis in theorem proving. Idris provides 
interoperability with systems libraries and C programs, 
as well as language constructs for domain specific language 
implementation \cite{gpIdris}. 

\par
Syntactically Idris is very similar to Agda, dependent types are defined as so: 
\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat :  Nat -> Type where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vect : Nat -> Type -> Type where
      Nil  : Vect 0 a
      (::) : (x : a) -> (xs : Vect n a) -> Vect (n + 1) a
  \end{lstlisting}
  \caption{Dependent Types in Idris}
\end{figure}

\par
While Idris offers interoperability with multiple mainstream programming 
languages such as C and JavaScript, Idris remain predominantly a research tool. 
Idris is not production ready \cite{gpIdris} as it is missing certain libraries 
and more importantly nobody is working on Idris full time. Furthermore Idris is 
still a functional language, hence suffering from the limitation stated earlier. 

\section{Imperative Languages}

In this section we will be discussing dependent typing with regards to imperative 
languages. Imprative languages uses the \textit{imperative programming} 
\cite{imperativeOverview} paradigm, in constrat to the functional 
programming, this pradigm emphasises \textit{how} a program will operate 
by using a series of statements to change the program state.

\par

Imperative languages can be further broken down into different categories, 
mainly Procedural and Object-Orinted. Many of the world's most popular languages 
fall into this two categories, C, FORTRAN, COBOL are examples of procedural 
languages while Java, C#, Kotlin are Object-Oriented Languages. Some languages such 
as C++, Python are multi-paradigm and allows the programmer to write code both 
in a procedural manner or object-oriented manner. 

\par

Currently there is no production ready imperative programming language with 
proper dependent type support. Previous research has look at creating an 
impertaive language with dependent types but these are not available to the 
general programmers. Certain mainstream languages also have aspect that 
resembles dependent types but do not provide the complete feature.

\subsection{Xanadu}
\textit{Xanadu} \cite{xanadu} is a dependently typed imperative language created by a team at 
the University of Cincinnati. The language was implemented in OCaml and was 
said to be available online in the original paper, however the original cited 
location looks to have been taken offline. It is safe to conclude that 
the language itself is also no longer in active development 

\par
There are no examples of the actual language available online except some code 
snippets shown by the author in the original paper. As such we are unable to 
provide any analysis on the language itself.

\par
However, the language is worth a mention here as it shows the feasibility of 
imperative languages having full dependent typing. The research by the authors 
are impressive and it serves as inspiration for our project. 

\par
Our project complements the work by Xi by providing analysis on the problem at 
hand. The original paper merely demonstrated the development and semantics of 
Xanadu, our project aims to discuss more on the topic. 

\subsection{C++ Templates}
\textit{C++ Templates} \cite{cppTemplate} are a way of passing the type of a 
data as a parameter so certain code can be reused. For instance, the same 
sorting algorithm can be used on multiple data types such as \textit{int} and 
\textit{double}, using templates the programmer will not need to write the same 
sorting function multiple times for different data types. 

\par
Templates are often compared to Java's \textit{Generics} \cite{javaGenerics} 
as the C++ equivalent. While this statement is mostly true, C++ templates 
differ in a big way. 
Generics only allow the template parameter to be a class, templates on the other 
hand allow the parameter to be a class, values or pointers. The ability to 
pass values into a template to create types certainly resembles dependent types.

\par
The code listing below is an example of templates with values. It defines the 
struct that represents an integer less than N. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N>
    struct LessThanN {
      int value;
      LessThanN(int x) {
        if (x < N)
            value = x;
        else
           throw ``invalid type'';
      }
    };
  \end{lstlisting}
  \caption{Struct dependent on values using C++ Templates}
\end{figure}

\par
Using the above definition it is possible to define types such as \\
\verb+LessThanN<5> ltf = LessThanN<5>(3)+, this will define a type that will has 
to be less than 5. However, certain questions arise from this definition, 

i) What will happen if the constructor is given an invalid argument? 

ii) What if the template parameter is a variable and its 
value change? 

iii) What if the value of \textit{value} change during execution?

In the subsequent text, the term ``Dependent Value'' will be used to refer to the 
value $N$ and ``Value'' will refer to the actual value held by a LessThanN type, 
i.e. the \textit{value} state in the struct. 

\subsubsection{The Intended Behaviour}
First, we observe the intended behaviour of LessThanN using the following test 
code:
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(3);
      cout << ltf.value; // Prints out 3
      return 0;
    }
  \end{lstlisting}
  \caption{Intended Behaviour of LessThanN in C++}
\end{figure}

\par
As expected, the code compiles perfectly and outputs 3 when executed.

\subsubsection{Invalid Definition of LessThanN}
In order to observe the behaviour of i), we simply have to pass in an 
invalid value into the constructor, i.e. a value greater than N, 
the test is conducted using the code below. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(10); // Error here
      cout << ltf.value; 
      return 0;
    }
  \end{lstlisting}
  \caption{Invalid Definition of LessThanN in C++}
\end{figure}

\par
Interestingly, the code compiles perfectely despite the invalid definition. 
However it fails to execute as the exeception thrown in the \textbf{else} clause 
is left uncaught. This behaviour makes it no better than an simple if statement 
in the constructor. An addition in C++ 11 was the introduction of 
\textit{constexpr} and \textit{static\_assertation}. These allow for certain 
compile time checking, however the values checked must fulfil 
the \textit{constant expression} requiremets \cite{cppConstExpr}. 

\par
Modifying the \textbf{struct} to use the code below we get compile time type 
checking. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N, int M>
    struct LessThanN {
      int value;
      LessThanN() {
        static_assert(M < N, ``type is invalid'');
        value = M;
      }
    };
  \end{lstlisting}
  \caption{LessThanN with Compile Time Type Checking in C++}
  \label{code:compileLTN}
\end{figure}

\par
Now, providing an invalid definition yields a compile time error, with the 
following: 
\verb+LessThanN<10, 12> ltf = LessThanN<10, 12>;+ 

\textbf{static\_assert failed due to requirement `12 $<$ 10' ``type is invalid''}

\subsubsection{Mutation of Template Variable}
In our previous example we have been passing integer literal as the template 
parameter for the dependent value. Often programmers are required to 
work with varied values through variables, how will this effect the behaviour? 

\par
Consider the following hypothetical situation using the struct defined in 
figure \ref{code:compileLTN}: 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>();
    n = 2; // Is ltf still well typed??
  \end{lstlisting}
  \caption{Mutating the Dependent Variable for LessThanN in C++}
\end{figure}

\par
Compiling the above code leads to a compile time error, C++ requires template 
arguments to be constant expressions. In order to use variables as template 
arguments, they have to be defined \textbf{const}. In which case the above 
situation is impossible as the variable $n$ now cannot be changed. 

\subsubsection{Changing The Value of Struct During Execution}
We've showed that it is not possible to change the dependent value in 
the program, however what if the value changes? Will a 
variable be well-typed on one line and ill-typed on the next line? 

\par
Consider the following code: 
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    const int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>(); // Well typed
    ltf.value = 10; // Now ill-typed but not caught
  \end{lstlisting}
  \caption{Mutating the value of LessThanN in C++}
\end{figure}

\par
In order to achieve our intended behaviour there has to be some form of check 
that runs throughout the lifetime of the program, currently there is no native 
support for this form of invariant. However one potential workaround as a 
programmer would be to make the LessThanN type immutable, by setting \textit{value} 
to be a \textbf{const} however that significantly limits the usability of the 
language. 

\par
We see glimpses of dependent typing in certain imperative languages, the 
examples using C++ presented above is one of them. One could argue arrays in 
Java and C++ resembles the fixed size vector however they are quite similar. In 
the subsequent chapters of this dissertation we will define a language to 
address these uncertainties. 


\section{Summary of Dependently Typed Langauge}
\begin{table} [H]
  \begin{tabular}{|p{2cm}|p{2cm}|p{10cm}|}
    \hline
    \textbf{Name} & \textbf{Paradigm} & \textbf{Notes} \\ 
    \hline
    Agda & Purely Functional & Actively developed but 
      Predominantly used for theorem proving rather than general programming. \\ 
    \hline
    Haskell & Functional & Widely used as a general purpose programming language, however not natively dependently typed. \\ 
    \hline
    Idris & Purely Functional & More general purpose compared to Agda however 
      still lacks mainstream recognition. \\
    \hline
    \textit{ATS} \cite{ATS} & Functional & Developed by Xi who created Xanadu, 
      support dependent typing however only for static terms. \\
    \hline
    \textit{F*} \cite{FStar} & Functional & Jointly developed by Microsoft 
    Research and Inria aimed at program verification. Lacks mainstream 
    programming recognition.\\
    \hline
  \end{tabular}
  \caption{Summary of Dependently Typed Language}
\end{table}

\par
The table above shows a number of languages that supports dependent typing, we 
observed that majority of the languages in this category are using the 
functional paradigm. As functional languages pale in comparison to imperative 
languages in terms of populatiry, the general awareness for dependent types 
remains low. 

\par
Our aim for this project is to i) Explore how dependent types should behave in 
an imperative language and how a language can use different mechanism to enable 
this behaviour. ii) Encourage the research into dependent types by extending the 
WHILE language \cite{whileLanguage} to support dependent typing. We chose this 
language because of its simple and familair syntax which at its core resembles 
popular languages such as C. 

\chapter{The Simple-$\Pi$ Language}
To address the uncertainties introduced in the previous chapter and provide a 
base for research in dependent types among imperative languages, we look to 
define a basic language called Simple-$\Pi$. This chapter will introduce 
the language's syntax and typing rules. The language follows 
the imperative paradigm, specifically a procedural language.

\section{Language Syntax}
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{l l l}
      \textit{Types} & $T$ & $:\text{ }int\text{ }|\text{ }bool\text{ }|\text{ }\Pi x: A.P(x)
      \text{ }|\text{ }void$\\
      \textit{Functions} & $f$ & $:\text{ }T_1, T_2,T_3...T_n\longrightarrow T_0$\\
      \textit{Operators} & $ops$ & $:$ $+$ $|$ $-$ $|$ $\wedge$ $|$ $\vee$ \\
      \textit{Expressions} & $e$ & $:$ $vals$ $|$ $x$ $|$ $x\text{ }:= e_1$ $|$ 
        $e_1$ $ops$ $e_2$ $|$ $e_1;e_2$ $|$ $f(e_1...e_n)$ \\ 
        & & \; $|$ \textbf{skip} $|$ \textbf{return} $e_1$ $|$ 
        \textbf{while} $e_1$ \textbf{do} $e_2$ \\ & & \;
        $|$ \textbf{if} $e_1$ \textbf{then} $e_2$ \textbf{else} $e_3$ $|$ 
        \textbf{let var } $x = e_1$ \textbf{in} $e_2$ \textbf{end}\\
      \textit{Variables} & $vars$& $:$ $x \in {a,b,c...z}$\\
      \textit{Values} & $vals$& $:$ $\forall v \in \mathbb{Z}$ $|$ $\forall v \in \mathbb{B}$ 
        $|$ $nil$\\
      \textit{Variable Types Context} & $\Gamma$& $:$ $vars \mapsto T$\\
      \textit{Variable Values Context} & $\sigma$& $:$ $vars \mapsto vals$
    \end{tabular}
  \end{center}
  \caption{Language Syntax for Simple-$\Pi$}
\end{figure}

\par
Figure 3.1 shown above is the syntax of Simple-$\Pi$, the paragraphs below 
explains the language in details. In constrast to other literatures in this area, 
Simple-$\Pi$ is a \textit{First Order Programming Language} \cite{FOL} modelled 
after the C programming language rather than a Higher Order Language. As is the 
nature of first order programming, functions cannot be passed as arguments or 
returned as result. 

\par
In order to achieve simplicity and observe the core behaviour of dependent 
types, the language is kept at a minimum with only the necessary construct. 

\paragraph{Types} The Simple-$\Pi$ language has support the following four data types. 
\begin{itemize}
  \item The basic integer type \textit{int}
  \item The basic boolean type \textit{bool}
  \item The dependent product type, written as $\Pi x: A.P(x)$, is used to 
  define a type $B$ that depends on the variable $x$ of type A.
  \item The \textit{void} type to represent empty or null.
\end{itemize}

\paragraph{Functions}
Functions are defined in Simple-$\Pi$ as $(T_1, T_2,T_3...T_n \longrightarrow T_0)$, 
taking a up to $n$ types and returning a type. Note that functions are 
not first-class in this language, unlike a higher order 
language, functions are not types in this case, functions cannot be passed to 
other functions, nor can it return a function as a result. One can compare 
functions in Simple-$\Pi$ as functions in C or Java. 

\paragraph{Operators}
The language supports the following built in operators.
\begin{itemize}
  \item Integer addition using the $+$ operator writte in an infix notation.
  \item Integer subtraction using the $-$ operator written in an infix notation.
  \item Logical conjunction using the $\wedge$ operator written in an infix 
  notation.
  \item Logical disjunction using the $\wedge$ operator written in an infix 
  notation.
\end{itemize}

\paragraph{Expressions} The following expressions make up the language.
\begin{itemize}
  \item Variable and values represents the most basic form of an expression.
  \item The four operators are expressions operator on two other expressions $e_1$ 
  and $e_2$
  \item The assignment statement $(:=)$ assigns an expression $e_1$ to variable 
  $x$, note $x$ must have already been declared. 
  \item The \textbf{if then} and \textbf{while do} statements are the standard 
  control flow operations one would expect.
  \item The function call $f(e_1..e_n)$ invokes function $f$ with arguments 
  $e_1..e_n$ and return the result.
  \item The \textbf{skip} statement is use to indicate an empty expression and 
  does not perform any meaningful action. 
  \item The \textbf{let} statement is used to bind new variables in an 
  expression. It is modelled after the same statement in Haskell, where \textbf{let var } 
  $x = e_1$ \textbf{in} $e_2$ \textbf{end} declare a variable $x$ with the value after 
  evaluating $e_1$, the variable is then available in the scope $e_2$ until 
  \textbf{end}.
  \item The \textbf{return} represents the termination of a function call and 
  end of scope. It returns an expression to the previous scope. 
\end{itemize}

\paragraph{Variables and Values} In Simple-$\Pi$, all variable are reference 
variables, as one would expect in imperative programming. We use $x$ to denote a 
variable. Variables can take values as suggested by the types, all the integer 
literals $\mathbb{Z}$, booleans $\mathbb{B}$ and $nil$ which is $void$ type. 
While values have a 1-on-1 correspondance with a type, it is obvious that a 
dependent type in the language will be a subset of either 
$\mathbb{Z}$ or $\mathbb{B}$ and as such will have already been a member of 
values.

\paragraph{Variable Values Context} Variables are mapped to values in the program 
context $\sigma$. Each reference variable is allowed to only appear once in 
the context. We use \textbf{dom}($\sigma$) to retrive the domain which represent 
the set of declared variables. We will use the notation $\sigma(x)$ 
to retrieve the value bound to variable $x$.

\paragraph{Variable Types Context} Variables are also mapped to their types 
in the type context $\Gamma$. Each variable is allowed to only appear once in 
the context. This context will be used to type check the program using the 
typing judgement in the next section.

\section{Typing Rules}
This section defines the typing rules for the Simple-$\Pi$ language.

\par
We begin by defining the typing judgement. The typing judgement used in 
Simple-$\Pi$ takes the form of the standard notation. 
\begin{center}
  $\Gamma \vdash e : T$
\end{center}
This judgement represents that expression $e$ under the context $\Gamma$ has the 
type $T$.

\par
Using the judgement rule we can easily define the fist few typing rules for base 
values \textit{int}, \textit{bool}, $nil$ and variables.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\forall n \in \mathbb{Z}$, $\Gamma \vdash n : int$ & 
      $\forall b \in \mathbb{B}$, $\Gamma \vdash b : bool$ & 
      $\Gamma \vdash nil : void$ & 
      $x : T, \Gamma \vdash x : T$ & 
      $\Gamma \vdash \textbf{skip} : void$
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}

\par
The remaining typing rules for the operators, statements and function  
calls are presented below. First we define the 
basic rules in figure 3.3, 
most of the typing rule are straightforward and what one would expect from the 
type checker. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int}
        {\Gamma \vdash e_1 + e_2 : int}[(\textbf{op} $+$)] \text{ }
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int} 
        {\Gamma \vdash e_1 - e_2 : int}[(\textbf{op} $-$)] & \\
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool}
        {\Gamma \vdash e_1 \wedge e_2 : bool}[(\textbf{op} $\wedge$)] \text{ }
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool} 
        {\Gamma \vdash e_1 \vee e_2 : bool}[(\textbf{op} $\vee$)] & \\
      \inference {\Gamma \vdash e_1: bool \\ \Gamma \vdash e_2: T & \Gamma \vdash e_3: T}
        {\Gamma \vdash \text{\textbf{if }} e_1 \text{\textbf{ then }} 
        e_2 \text{\textbf{ else }} e_3: T}[(\textbf{if else})]
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: T}
        {\Gamma \vdash \text{\textbf{while }} e_1 \text{\textbf{ do }} e_2 : void} [(\textbf{while do})] & \\
      \inference {\Gamma \vdash x: T & \Gamma \vdash e_1: T} 
        {\Gamma \vdash x := e_1 : T} [($:=$)] \text{ }
      \inference {\Gamma \vdash e_1: T_1 & \Gamma, x : T_1 \vdash e_2: T_2} 
        {\Gamma \vdash \textbf{let var } x = e_1 \textbf{ in } e_2 \textbf{ end }: T_2} [(\textbf{let in})] \text{ }
      & \\
      \inference {\Gamma \vdash e_1: T_1 & \Gamma \vdash e_2: T_2} 
        {\Gamma \vdash e_1;e_2 : T_2} [(concatenation $;$)] \text{ }
    \end{tabular}
  \end{center}
\caption{Basic Typing Rules for Simple-$\Pi$}
\end{figure}

\par
For a function call, we use the type judgement above. We use  
first order logic to write $f(e_1...e_n)$ as an n-nary function of 
type $T_1$ to $T_n$, then the arguments $e_1$ to $e_n$ must be of same type. 
Evaluation of the function will then satisfy the return type $T_0$.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e: T} 
        {\Gamma \vdash \textbf{return } e: T} [(\textbf{return})] \text{ }
      & \\
      \inference {f : T_1,T_2...T_n \longrightarrow T_0 \\ 
      \Gamma \vdash e_1 : T_1 & \Gamma \vdash e_2 : T_2 &...& \Gamma \vdash e_n : T_n}
        {\Gamma \vdash f(e_1...e_n): T_2}[(\textit{functions})]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Functions in Simple-$\Pi$}
\end{figure}


\par
In this section we covered the typing rules for Simple-$\Pi$, typing rules are a 
way of allowing us to statically check the correctness of our program with 
regards to typing rules. However, we are not able to analyse their dynamic 
behaviour. 

\newpage 

\section{Operational Semantics}
In order to express the behaviour of the language we will have to define its semantics. 
We will build up the semantics gradually, starting from the basic 
operational semantics and eventaully formalising the behavour of certain 
non-trivial behaviour involving dependent types such as reassignments and 
pointers. In this section we will define the \textit{Operational Semantics} 
\cite{operationalSemantics} for the Simple-$\Pi$ language 
using the \textit{Structural Operational Semantics} \cite{plotkinSOS} (SOS) rules.

\par
Throughout the text we will be extending the syntax defined in the 
previous chapter in order to accomodate more features. 
We will use the following metavariables and notations throughout our 
definitions.

\renewcommand\labelitemii{$\blacksquare$}
\begin{itemize}
  \item The metavarible $op$ as one of a range of operators. 
  \item The metavariable $v$ to range over all values.
  \item The uppercase letters $A,B,C,T$ to range over all types.
  \item Greek letters ($\alpha$, $\pi$, $\upsilon$) to define local variables in 
  the formuli. 
  \item The following notations to operate on states. 
    \begin{itemize}
      \item $\sigma + \{x \mapsto v\}$ adds $\{x \mapsto v\}$ to $\sigma$ provided initially $x \notin\textbf{dom}(\sigma)$. 
      \item $\sigma[x \mapsto v]$ or $\sigma \uplus \{x \mapsto v\}$ updates $\sigma$ such that now $\sigma(x) = v$.
      \item $\sigma - \{x\}$ to remove $x$ from $sigma$, provided that $x \in \textbf{dom}(\sigma)$.
    \end{itemize}
\end{itemize}
    
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle v_1;e_1, \sigma \rangle \longrightarrow \langle e_1, \sigma \rangle$ ($vals$ evaluation) 
      \text{ }
      \inference {x \in \textbf{dom}(\sigma)}{\langle x, \sigma \rangle \longrightarrow \langle \sigma(x), \sigma\rangle}[($vars$) evaluation] 
      & \\
      \inference {v = v_1 + v_2}{\langle v_1 + v_2, \sigma \rangle \longrightarrow \langle v, \sigma\rangle}[(op $+$)] \text{ }
      \inference {v = v_1 - v_2}{\langle v_1 - v_2, \sigma \rangle \longrightarrow \langle v, \sigma\rangle}[(op $-$)]
      & \\
      \inference {v = v_1 \wedge v_2}{\langle v_1 \wedge v_2, \sigma \rangle \longrightarrow \langle v, \sigma \rangle}[(op $\wedge$)] \text{ }
      \inference {v = v_1 \vee v_2}{\langle v_1 \vee v_2, \sigma \rangle \longrightarrow \langle v, \sigma \rangle}[(op $\vee$)]
      & \\
      \inference {\langle e_1, \sigma\rangle \longrightarrow \langle e_1', \sigma\rangle}
        {\langle e_1\text{ }op\text{ }e_2, \sigma  
        \rangle \longrightarrow \langle e_1'\text{ }op\text{ }e_2, \sigma' \rangle}[($op$ $expr$)]
      & \\
      \inference {\langle e_2, \sigma\rangle \longrightarrow \langle e_2', \sigma\rangle}
        {\langle v\text{ }op\text{ }e_2, \sigma  
        \rangle \longrightarrow \langle v\text{ }op\text{ }e_2', \sigma' \rangle}[($op$ $expr$ 2)]
      & \\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle}
        {\langle e_1;e_2, \sigma \rangle \longrightarrow \langle e'_1;e_2, \sigma' \rangle}[($e_1;e_2$)]
      & \\
      $\langle \text{\textbf{skip}};e2, \sigma \rangle \longrightarrow \langle e2, \sigma \rangle$ (\textbf{skip})
      & \\
      $\langle \text{\textbf{if }\textit{true}} \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle e_1, \sigma\rangle$ (\textbf{if} true)
      & \\
      $\langle \text{\textbf{if }\textit{false}} \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle e_2, \sigma\rangle$ (\textbf{if} false)
      & \\
      \inference {\langle e_0, \sigma\rangle \longrightarrow \langle e_0', \sigma \rangle}
        {\langle \text{\textbf{if }} e_0 \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle \longrightarrow \langle \textbf{if } e_0' \text{\textbf{ then }} e_1 \text{\textbf{ else }} 
        e_2, \sigma \rangle}[(\textbf{if} $expr$)] 
      & \\
      $\langle \text{\textbf{while }} e_0 \text{\textbf{ do }} e_1, \sigma \rangle \longrightarrow \langle 
        \text{\textbf{if }} e_0 \text{\textbf{ then }} e_1;
        (\text{\textbf{while }} e_0 \text{\textbf{ do }} e_1) \text{\textbf{ else }} \textbf{skip}, \sigma \rangle$ (\textbf{while do})
      & \\
      \inference {x \in \textbf{dom}(\sigma)} 
      {\langle x := v, \sigma \rangle \longrightarrow \langle v, \sigma[x \mapsto v] \rangle} [(assignment $vals$)] \text{ }
      & \\
      \inference {\langle e, \sigma \rangle \longrightarrow \langle e', \sigma' \rangle} 
      {\langle x := e, \sigma \rangle \longrightarrow \langle x := e', \sigma'\rangle} [(assignment $expr$)] \text{ }
     \end{tabular}
  \end{center}
  \caption{Operational Semantics for Simple-$\Pi$}
\end{figure}

\subsection{Scoping}
Scoping has an important role in imperative languages, variables can be defined 
in scopes and are unavailable once outside. While there are many different 
variables that does not follow this rule, such as static variables, global 
variables and reference variables. For simplicity, we will focus initially on local 
variables. 
\par
In order to help us formalise the notion of scopes we define a new notation, 
$\longrightarrow^{*}$ as a multi-step evaluation. The evaluation rule 
$\langle e, \sigma \rangle \longrightarrow^{*}  \langle v, \sigma' \rangle$ simply 
evaluate the expression $e$ one or more times until it evaluates to a value $v$. 

\par
Using a multi step evaluation, We can easily define the scoping rules as shown 
below.
  
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \sigma 
      \\ \langle e_1, \sigma' \rangle \longrightarrow^{*} \langle v_1, \sigma'' \rangle} 
      {\langle\textbf{let var }x = v_0 \text{\textbf{ in }} e_1 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle v_1, '' - \{x\} \rangle} [(\textbf{let in} values)] 
      & \\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma'\rangle} 
      {\langle \textbf{let var }x = e_1 \text{\textbf{ in }} e_2 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle\textbf{let var }x = e_1' \text{\textbf{ in }} e_2\text{\textbf{ end}}, \sigma' \rangle} 
      [(\textbf{let in} $expr$)]
    \end{tabular}
  \end{center}
  \caption{Scoping Rules for Simple-$\Pi$}
\end{figure}

\par
Figure 4.2 above defines the scoping rules for Simple-$\Pi$.

\par
The \textbf{let in} statement opens a new scope $\sigma'$ which 
assigns $x$ the value $v$, the in expression, $e_1$ is then evaluated with the 
new context using the multi-step evaluation until it no longer can be evaluted, 
the resulting expression is passed back to the original context.

\par 
Notice that in the first rule above (\textbf{let in } values), the resulting state 
uses the notation $-$, recall that the operator removes all the variables in the set 
$\{x\}$ from the domain of $\sigma$. 

\par
This is necessary as in a scope it is possible to change the state of the 
program. More importantly, upon exiting a scope the alteration to the program 
will still hold, the only difference is that the variable $x$ is no longer in 
the state, i.e. has ran out of scope.

\par
The multi-step evaluation provides us to much more easily express scoping rules, 
the alternative would be to model an explicit call stack, which complicates the 
formulas.

\subsection{Functions}
Functions in almost all imperative language operates in their own scope. In many 
cases they do not have the access to the local variables out of their scope however 
one can pass data using arguments. Functions in Simple-$\Pi$ are call by values, 
changing the value of an argument in the function does not change the value in 
the outside scope. Our multi-step evaluation rule defined previously helps us 
evaluate functions in their own scope. 

\par
In order to define the operational semantics of a function we will need to 
specify the function body. We define a mapping \textit{fns} $: f \mapsto ((x_1, x_2...x_n), e)$, 
using this mapping allows us to retrieve the body of a function. Since functions 
definition cannot be changed at runtime, this does not need to be part of the 
configuration and can be consider as a static context.

\par
We begin defining the evaluation rules for functions, first we define the 
operational semantics for the \textbf{return } statement which simply evaluates 
to the value returned. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle \textbf{return } v, \sigma \rangle \longrightarrow \langle v, \sigma \rangle$ (\textbf{return} value)
      &\\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle} {\langle \textbf{return } e_1, 
      \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle} [(\textbf{return} nil)]
    \end{tabular}
  \end{center}
  \caption{Evaluation Rules for Return Statement}
\end{figure}

\par
We can then evalute the function body which using the multi-step evaluation.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {((x_1..x_n), e_{body}) = \textit{fns}(f) 
        \\ \sigma' = \{x_1 \mapsto v_1 ... x_n \mapsto v_n\} & \langle e_{body}, \sigma' \rangle \longrightarrow^{*} \langle v, \sigma'' \rangle}
      {\langle f(v_1...v_n), \sigma \rangle \longrightarrow \langle v, \sigma \rangle} [(function call vals)]
      & \\
      \inference {\langle e_k, \sigma \rangle \longrightarrow \langle e_k', \sigma' \rangle}
      {\langle f(v_0...v_{k - 1},e_k...e_n), \sigma \rangle \longrightarrow \langle f(v_0...v_{k - 1}, e_{k}'...e_n), \sigma' \rangle} [(function call expr)]
    \end{tabular}
  \end{center}
  \caption{Functions Semantics for Simple-$\Pi$}
\end{figure}

\par
The first rule (function call vals) resembles the evaluation rule for 
\textbf{let in} but it differs in a crucial way, in the new context for a 
function call, none of the variabels from the previous scope transfer over, only 
those of the argument are copied. We then evaluates the function body until it 
evaluates to a value which is then returned to the caller's context. Unlike 
scopes, functions cannot alter the program's state. 

\par
The second rule (function call $expr$) evaluates the expression passed into the 
function as arguments. Our language defines a strict behaviour that all 
arguments are evaluated in the order they are passed in, i.e. from left to right. 

\section{Dependent Types and Variables}
Programming languages often have a wide range of features, often the team behind 
the language have to put extensive thought into the design decisions. As there 
are often multiple way to handle a certain feature, rarely are there a definite 
answer to which is the most optimal.

\par
This seemingly undecideable problem is known as \textit{feature interaction} 
\cite{featInteract}, it describes the problem in some situations multiple 
features would modify the behaviours of each others. The same applies to 
dependent types, which is a feature itself. For instance, the inclusion of dependent types 
would modify the behaviour of assignments and vice versa. This section 
will cover the different ways of handling dependent types and they interact with 
other features.

\subsection{Hoare Logic}
In order to formalise the specification of our language we opted to use 
\textit{Hoare Logic} \cite{hoare}. The \textit{Hoare Triple} is defined as follows: 

\begin{figure}[H]
  \begin{center}
    $\{P\}C\{Q\}$
  \end{center}
  \caption{Hoare Triple}
\end{figure}
The Hoare triple simply expresses that given precondition $P$ holds then after executing $C$ 
and $C$ terminates, the postcondition $Q$ will hold.

\par
We chose Hoare Logic as our preferred system because of its simple to understand 
notation. While Hoare Logic is a powerful tool that can become complex when 
reasoning about the correctness of a program we are mainly interested in using 
the Hoare notation as a tool for specifications. We will be using the 
precondition to specify in which state the programmer is allowed to perform 
certain commands and what must be the resulting state after execution. While the 
same formalisation can be achieved using Structures Operational Semantics, the 
Hoare Triple provides a much more concise notation. 


\subsection{The Ambiguity of Dependent Types}
Consider the ambiguity of using variables to define dependent types. For 
instance: 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let var }$y\text{ }:\text{ } int = 10$ \textbf{ in } \\
    \tab\textbf{let typedef }$BoundedIntY$ = $\Pi y : int. \{i : Int\text{ }|\text{ }i < y\}$ \textbf{ in } \\ 
    \tab\tab\textbf{let var }$x\text{ }:\text{ }BoundedIntY = 4$ \textbf{ in }$y := 5$\textbf { end} \\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Mutation to Variable Depended On}
\end{figure}

\par
How would this behaviour work in practice? Recall from chapter 2 we proposed the 
question of what should happen when the value bound to the variable change. In 
this subsection we will define different methods to handle this behaviour and 
formalise their specification.

\par
First we need to introduce a new expression for type definition, in the example 
above we used the expression (\textbf{let typedef} $x = T$ \textbf{ in }$e_1$ \textbf {end}) 
to denote a new type $T$ with the name $x$ that exists in the scope of $e_1$. 
This definition is similar to the \textbf{let in} expression defined previously. 

In our example, we mean 
that a new type named $BoundedIntY$ is created. We need to add this construct 
into our syntax. In our current syntax, we have a context for variables and 
values, We would also need a similar mapping for types, We use $\tau$ to 
represent the type name map. 

\par
The syntax is extended by adding the following: 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expression} & $e$ & $:$ ... $|$ \textbf{let typedef }$x = T\textbf{ in } e_1$ \textbf{ end} \\
      \textit{Type Name Context} & $\tau$& $:$ $vars \mapsto T$ \\
    \end{tabular}
  \end{center}
  \caption{Type Name Context Extension for Simple-$\Pi$}
\end{figure}

\par
We then define the operational semantics: 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\langle e_1, \sigma, \tau' \rangle \longrightarrow^{*} \langle v, \sigma', \tau'' \rangle 
      \\ x \notin \text{\textbf{dom}}(\sigma) & x \notin \textbf{dom}(\tau) & \tau' = \tau + \{x \mapsto T\}}
      {\langle \textbf{let typedef }x = A \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau'' - \{x\}\rangle}[(\textbf{typedef})] \text{ }    
    \end{tabular}
  \end{center}
\end{figure}

\par
The operational semantic above simply adds a new type definition with name $x$ 
into the Type Name context $\tau$. Importantly, the variable $x$ cannot have 
already been defined as a value variable n $\sigma$ and a type of the same name 
can not already be defined. Logically it is equivalent to the semantics for 
\textbf{let in}.


\subsection{Total Immutability}
The main issue one encounters when associating dependent types with imperative 
languages is the presence of mutability and assignments. The obvious way to 
work around this problem is to remove the ability to make changes to the state 
of the program. In other words, all defined variables are constant. 

\par
While this approach does allow for a type system that depends on values, it is 
only partial dependent typing as the values depended on has to be available at 
compile time whereas a fully dependently typed language is able to depend on 
value at runtime.

\par
The approach proposed in this subsection does not encompass the intended behaviour we 
sought after however we decided to formalise it for completeness and serves as 
a building block for our language. 

\par
To achieve complete immutability immutability we can simply ``disable'' the 
reassignment feature. We could remove the assignment operator $(:=)$ from our 
syntax and will achieve immutability. This will avoid any complications 
regarding dependent types as 
if they are well typed during definition it will stay well typed. 

\par
Using this approach does definitely resolves the uncertainty the usability of 
the language is poor. Imperative programming relies on state changes, forbidding 
that go against the paradigm. 

\subsection{Immutability For Dependent Variables}
We observe that only variables associated with dependent typing needs to be 
immutable to prevent any uncertain behaviours. To improve the flexibility of our 
language, we could loosen the restrictions by having only the depenent variables 
be immutable. 


\par
In order to capture the notation of immutable types, the set of variables $vars$ 
is partitioned into two different distinct catogories. Mutable and immutable, we 
define a predicate $is\_immutable$ that specify if a given variable is immutable. 
$is\_immutable(x)$ holds if and only if $x$ is immutable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ }
        \textbf{let const }x = e_1 \textbf{ in }e_2\textbf{ end}$
    \end{tabular}
  \end{center}
  \caption{Immutable Variable Context for Simple-$\Pi$}
\end{figure}
 
One can declare an immutable variable as though they are defining a mutable 
variable, using the \textbf{let const in} statement. We define the semantics as 
below, we will use the following notation $x \in \Sigma$ to state that $x$ is 
immutable.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\langle e_1, \sigma' \rangle \longrightarrow^{*} \langle v, \sigma'' \rangle \\ \sigma' = \sigma + \{x \mapsto v\}} 
      {\langle \text{\textbf{let const }}x = v \text{\textbf{ in }} e_1 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle v, \sigma'' - \{x\} \rangle} [(\textbf{let in} values)] 
      & \\
      \inference {\langle e_1, \sigma \rangle \longrightarrow \langle e_1', \sigma' \rangle} 
      {\langle \text{\textbf{const }}x = e_1 \text{\textbf{ in }} e_2 \text{\textbf{ end}}, \sigma \rangle 
      \longrightarrow \langle \text{\textbf{const }}x = e_1' \text{\textbf{ in }} e_2\text{\textbf{ end}}, \sigma' \rangle} 
      [(\textbf{const in} $expr$)]
      & \\
      \inference {x \in \textbf{dom}(\sigma) & \neg is\_immutable(x)} 
      {\langle x := v, \sigma \rangle \longrightarrow \langle \text{\textbf{skip}}, \sigma[x \mapsto v] \rangle} [(assignment $vals$)] \text{ }
    \end{tabular}
  \end{center}
  \caption{Immutable Variables Rules for Simple-$\Pi$}
\end{figure}

\par
Once we defined the ability to define immutable variables, we can utilise it in 
our type definition. First we refine our specification for \textbf{typedef} 
with regards to dependent types using the evaluation rules.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      a \notin \text{\textbf{dom}}(\sigma) & is\_immutable(x) & a \notin \textbf{dom}(\tau) 
      \\ \langle e_1, \sigma, \tau + \{a \mapsto \Pi x : A.P(x)\} \rangle 
      \longrightarrow^{*} \langle v, \sigma', \tau' \rangle}
      {\langle \textbf{typedef } a = \Pi x :A .P(x) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau' - \{a\}\rangle}[(\textbf{typedef}) $\Pi$]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics Dependent Type Definition}
\end{figure}


\par
We can capture the behaviour of the statement using Hoare Logic 
by using the following formuli, 
in order to be more consise with our notation we declare some variables local to 
the rule.

\par
We construct our Hoare Triple as follows, first we declare 
the expression that we would like to evaluate, we do this in two parts.

Let $\{S\}e_1\{T\}$ be a Hoare triple and we have a type declaration incorporating 
$e_1$ which will be evaluted in our Hoare Logic as $E$

\begin{center}
  $E = \textbf{let typedef }a = \Pi x. P(x) \textbf{ in } e_1 \textbf{ end }$
\end{center}
\par

In order to prevent confusion between our postcondition and our dependent type 
function, we delcare precondition as $Q$ on our type declaration $E$
\begin{center}
  $Q = a \notin \textbf{dom}(\tau) \wedge a \notin \textbf{dom}(\sigma) \wedge is\_immutable(x)$
\end{center}

\par
The Hoare logic can then be written as

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}      
      \inference{\{\tau(a) = \Pi x. P(x) \wedge S\}e_1\{T\}}{\{Q\}E\{T\}}
    \end{tabular}
  \end{center}
\end{figure}


\par
The precodition $Q$ ensures that a type declaration is possible in the context, 
and we can evaluate the expression $e_1$ and satisfy the postcondition. Notice 
that we did not require the $S$ to hold with the precondition $Q$ as it 
potentially could relies on the type declaration to have had happend before it 
holds.

\par
The approach laid out here is a simple approach to dealing with the ambiguity of 
having mutability and dependent types. Interestingly, C++ utilise the same 
strategy templates, where a value passed into a template must be a constant 
expression. 

\par
The limitation of this approach is of course the fact that our dependent values 
must be available at compile time, eliminating some flexibility. Our next 
appraoch will look to improve on this limitation. 

\subsection{Passing by Value}

If we further analyse our design, we notice that if our dependent type is 
constructed using a value then we would not have the problem of variable change. 
In languages such as C/C++, \textit{pass by value} \cite{pbv} is a way of 
passing a parameter into a function in a way that any modification to the 
parameter in the function does not reflect changes outside and vice versa. The 
same cocept is used for functions in Simple-$\Pi$.

\par
The similar approach can be taken in our definitions for dependent types. For 
instance, taking the example in figure 4.2, if the variable $y$ in the dependent 
type function is different from the variable $y$ in the program state, then any 
changes to the variable $y$ will not effect the type definition and the program 
will stay well typed.
 
\par
In subsection 4.1.2 we defined the functions' evaluation rules using scopes. 
We will be adapating a similar approach for our dependent type functions. If 
$\Pi x : A. P(x)$ is a dependent type that depends on $x$ of type $A$ then we have  
$\Pi x : A.P(x) \in $ \textit{dfns}, \textit{dfns} behaves like \textit{fns}, 
holding the definitions of all dependent type functions. The only difference 
here is that a dependent type only takes a singular parameter. 

\par
We first require modification to our \textbf{return} statement, which at the 
moment only returns expressions, as dependent type functions return types, we 
need to accomodate that. We define a special return statement, \textbf{return } 
$T$, this statement is only to be used with dependent type function. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Expressions} & $e$& $:$ $\textbf{return }T$ \\
    \end{tabular}
  \end{center}
  \caption{Return statement for Types in Simple-$\Pi$}
\end{figure}

We define the typing rule for this return statement using the idea of 
\textit{universes} \cite{martinLof} 
in type theory, using the notation $\Gamma \vdash A : Type$ we say that $A$ is a 
type. 

We define the formation rule for a dependent type as so: 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash A : Type \\ \Gamma, x : A \vdash P(x) : Type} 
        {\Gamma \vdash \Pi x. P(x) : Type}[($\Pi$ F)] \text{ }
    \end{tabular}
  \end{center}
  \caption{Typing Rules for the Dependent Product Type}
\end{figure}

\par
The dependent product type formation rule ($\Pi$ F) defines the rules in order 
for a dependent product type to be formed. Similarly, we define the 
type judgement for a \textbf{return }$T$ statement, it 
returns a type. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference{\Gamma \vdash A : Type}{\Gamma \vdash \textbf{return } A : Type} [(\textbf{return }T)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}


\par
Using the return statement above, when one define a dependent type, our 
semantics will evaluate the function until a type is returned. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      
     \scriptsize
     \inference {\langle e_1, \sigma, \tau \rangle \longrightarrow \langle e_1', \sigma', \tau' \rangle}
      {\langle\textbf{let typedef } x = \Pi e_1 : A.P(e_1) \textbf{ in }e_2\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \textbf{let typedef } x = \Pi e_1' : A.P(e_1') \textbf{ in }e_2\textbf{ end}, \sigma, \tau \rangle} 
      & \\
     \footnotesize
     \inference {((x_1), e_{body}) = \textit{dfns}(\Pi v : A.P(v)) 
      \\ \sigma' = \{x_1 \mapsto v\} &  \langle e_{body} , \sigma, \tau \rangle \longrightarrow^{*} \langle \textbf{return }T, \sigma, \tau \rangle}
      {\langle\textbf{let typedef } x = \Pi v : A.P(v) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \textbf{let typedef } x = T \textbf{ in }e_1\textbf{ end}, \sigma, \tau \rangle}
    \normalsize
    \end{tabular}
  \end{center}
  \caption{Evaluation of Dependent Type Functions}
\end{figure}

\par 
The rule above formalise the semantics for dependent type definitions in 
Simple-$\Pi$. The dependent type function is evaluated in its own scope. Note 
that in our evalutation the \textbf{typedef} statement is being written 
repeatedly such that we are able to pass back \textbf{return} $T$ to 
\textbf{typedef}. If we were to use the same evaluation as our previous return 
statement then $T$ would have to be an expression and could potentitally results 
in further complications. 

\par
As with the previous example, we caputure the behaviour with Hoare Logic as 
follows. To improve readability, we use local variables to represent certain 
expressions. 

\par
We use $E$ to represent the main expression under evaluation, in this example we 
is defined as

\begin{center}
  $E = \textbf{let typedef }y = \Pi x : A.P(x) \textbf{ in }e_1\textbf{ end}$  
\end{center}

\par
As we did previously, we define a triple $\{S\}e_1\{T\}$ as an arbitrary hoare 
logic over expression $e_1$. Our triple can then be defined as 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference{\{\tau(y) = \Pi \alpha : A.P(\alpha) \wedge S\}e_1\{T\}}{\forall \alpha : A\{\alpha = x\}E\{T\}}
    \end{tabular}
  \end{center}
\end{figure}

\par
In the above formula, we are using a local variable $\alpha$ to represent 
passing by value, we are formalising that the variable program varaible $x$ is 
distinct from $\alpha$ and mutation of $x$ does to reflect on $\alpha$. The 
dependent type bound to $y$ depends on $\alpha$ and not $x$.

\par
Unlike C++, this form of sematics allows one to utilise non-constant expression 
in type definition. This is achieved by taking the \textit{rvalue} \cite{cpplrvalues} 
of an expression rather than the \textit{lvalue}. The clear advantage of this 
appraoch is the improved flexibility given to the programmer which allow more 
variables to be associated with types. 

\par
Whit this approach does provide more flexibility in comparison to 
C++ templates it is still has certain limitations. The most obvious is the fact 
that the programmer might sometimes be looking for dependent types 
whose definitions changes with the value of the variable. 

\subsection{Dynamic Dependent Types}
In this subsection we will be presenting an approach to handling dependent types 
in imperative languages called \textit{Dynamic Dependent Types}. It is a type 
that will allow the definition of dependent types to change during runtime and 
still guarantees a well-typed program. 

\par
Notice that in figure 4.5, the variable $x$ is 
of type $BoundedIntY$ and has the value 4 which is well typed. In the next line, 
the value of $y$ is reassigned the value 5. In this approach, rather than having 
no effect on the type definition, the type of $BoundedIntY$ changes with the 
value $y$, being now bounded to $5$. In our example, $x$ is still well typed so 
everything is valid. 


\par
However, consider the following examples with certain values replaced. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let }$y\text{ }:\text{ } int = 10$ \textbf{ in } \\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y. \{i : Int\text{ }|\text{ }i < y\}$; \\ 
    \tab\textbf{let }$x\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in }$y := 5$\textbf { end }\textit{// Error}\\
    \textbf {end}
  \end{tabs}  
  \caption{Ill-Typed Dynamically Changing Dependent Types}
\end{figure}

\par
If the reassignment of $y$ causes $x$ to be ill-type as demonstrated in the 
example above, then the type checker should flag it at compile time. 

\par
In order to do this we need will need to type check all variables against its 
type after an assignment. We can use the typing judgement to perform the 
type checking by only allowing assignment if the all variables of a dependent 
type that depnds on $x$ holds after reassignment of $x$.

\par
Notice that our current value variable context does not 
provide the type that a variable possess, we only have the value. 
In order to formalise the behaviour in Hoare Logic, we will need to typing 
information of a variable. We are able to retrive this information from the 
Variable Type Context $\Gamma$, however we for a better and more concise 
notation we decided to use the syntax defined below.

\par
First we modified the value variable context as shown below:
 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Variables Values Context} & $\sigma$& $:$ $vars \mapsto vals : T$ 
    \end{tabular}
  \end{center}
  \caption{Extended Value Variable Context with Type}
\end{figure}

This means that a varible now maps to a value with type $T$. The notation of 
$\sigma(x)$ to retrieve a value used in previous semantics still hold, now we 
can write $\sigma(x) = \alpha : \beta$ which gets $\alpha$ the value of $x$ 
and $\beta$ the type of $x$. This notation allows us to apply the universal 
quantifier.


\begin{figure}[H]
  \begin{center}
   \begin {tabular} {c} 
     \inference {x \in \sigma
     \\ \forall \alpha : \Pi x. P(x) \in\textbf{rng}(\sigma)\text{ }s.t.\text{ }\alpha : \Pi v. P(v)} 
          {\langle x := v, \sigma, \tau \rangle \longrightarrow \langle v, \sigma', \tau' \rangle}
    \end{tabular}
  \end{center}
  \caption{Dynamic Dependedent Type Reassignment Rule}
\end{figure}


The rule above states that for all $\alpha$ of a type $\Pi x.P(x)$ it will be 
well typed for $\Pi v.P(v)$, the new value of $x$. Our logic here works simply 
by using the concept of type membership, which similar to the the 
concept of set membership in set theory \cite{RussellMathematicalLA}. 
The above statement can simply be rewritten in logic as 
$\forall \alpha \in A\text{ }s.t.\text{ }\alpha \in B$.

\par
We capture the behaviour of dynamic dependent types in hoare logic by  
extending the definition of the Hoare Logic for assignment, recall the axiom
\begin{center}
  $\{P[e/x]\}x := e\{P\}$
\end{center}
The axiom simply states that, in some predicate $P$ holds after the assignment, 
it holds before the assignment.

\par
We define $\phi$ as a local function $T \longrightarrow \{vals\}$, defined as 

\begin{center}
  $\phi(A) = \{v\text{ }|\text{ }x \in \sigma \wedge \sigma(x) = v : A\}$  
\end{center}

\par
Given a type $A$, the function $\phi$ returns the set of all values in the 
state $\sigma$ that has type $A$.

\begin{figure}[H]
  \begin{center}
    $\forall \gamma \in \mathcal{P}(\sigma)\{\forall v \in \phi(\Pi x : A.P(x)) 
    \text{ }s.t.\text{ }v : \Pi e : A. P(e) \wedge P[e/x]\}
    x:= e\{P\}$ 
  \end{center}
  \caption{Dynamic Dependedent Type Reassignment Rule}
\end{figure}


\par
The Hoare Logic above reiterates this behaviour by stating that in order for the 
assignment to be evaluated, all values $v$ with type $\Pi x : A.P(x)$ in the state 
will have to be well typed with regards to the new value of $x$.

\par
The Dynamic Dependent Types approach presented here gives the highest degree of 
flexibility, it allows the expression of complex logic which is able to alter 
the types of values at runtime. However, it comes at the cost of potentially 
expensive type checking. Checking the type compatability of all values of a 
certain type during assignment introduces major overhead. Implementing a 
language of this flexibility might be unobtainable for language with performance 
requirements. 

\subsection{Summary}
This section presented multiple solution to achieving reassignment in a 
dependently typed language. All approaches has their own advantages and 
disadvantages. The dynamic dependent types approach while flexible and useful, 
the act of typing checking and converting the types of multiple variable is a 
big overhead and might be detremental in practice. 

\section{Pointers and Vectors}
In this next section we will be presenting dependently typing with regards to 
arrays. The introduction of arrays ties in closely with pointers and aliasing, 
the behaviours of these additional features will be discussed and specified in this 
section.

\subsection{Heap Memory}
In programming languages, there are three different types of memory allocation, 
static, stack and heaps \cite{heapVsStack}. While we have not explicitly 
discussed our memory management model, it is rather obvious that Simple-$\Pi$ 
operates on a stack based model. It is apparent in the behaviour of locals 
variable which are inaccesible once out of scope as discussed in subsection 
4.1.1. While arrays can be allocated on the stack, since we are dealing 
with dependent types and arrays are likely to be dynamic, we have decided to use heap 
memory to handle arrays. 

\subsubsection{Syntax Extension}
First we will have to extend our syntax to accomodate these new features, the 
new syntax is shown in figure 4.14 below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Types} & $T$ & $:$ $...\text{ }|\text{ }T\text{ \textit{ref }}$ \\
      \textit{Expressions} & $e$ & $:$ $...\text{ }|\text{ }!e_1\text{ }|\textbf{ new}(T)|\textbf{ new}(T, v)$\\
     \textit{Values} & $vals$& $:$ $...\text{ }|\text{ }h$ \\
     \textit{Heap} & $\Delta$& $:$ $h \in \{h_1,h_2, h_3...\} \mapsto vals$\\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$\Pi$}
\end{figure}

\par
We introduced two new types, $T$ \textit{ref} is a reference type, it behaves 
like a pointer in C/C++, like pointers, references are typed and its value is a heap address. 


\par
We introduced the following expressions into the language:
\begin{itemize}
  \item $!e_1$ to dereference the $T$ \textit{ref} represented by $e_1$.
  \item \textbf{new}($T$) to allocate and return a $T$ \textit{ref} without specifying the value 
  which will be assigned $nil$.
  \item \textbf{new}($T, v$) to allocate and return a $T$ \textit{ref} with the 
  value $v$.
\end{itemize}
\par
For simplicity, we have ommited the need for manual memory management and memory 
deallocation.

\par
Values are extended such that it now includes heap address $h$

\par
Finally, Heap $\Delta$ is a set of heap addresses $\{h_0, h_1, h_2...\}$ currently in use, 
realisticly $\Delta$ will be a finite mapping however, in our case we are assuming 
$\Delta$ be an infinite set of heap addresses as we consider cases of 
insufficient memory out of scope for our project. We use the notation, $\Delta(h)$ 
to get the value held at a particular heap address. 

\subsubsection{Typing Rules}

We first define the base types for heap address and array values. As it is the 
case with many languages, the $nil$ value is a reference type.
\begin{center}
   $\Gamma \vdash nil : T\text{ }ref$ ($nil$ reference type)
\end{center}

\par
We define the rest of the typing judgement as shown below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma(\Delta(h)) = T} 
        {\Gamma \vdash h : T\text{ }ref}[(heap address type)]
      \text{ }
      \inference {\Gamma \vdash e_1 : T\text{ }ref}{\Gamma \vdash !e_1 : T}[(dereferencing)]
      & \\
      $\Gamma \vdash \textbf{new}(T) : T\textit{ ref}$ (\textbf{new} reference 1)
      \text{ }
      \inference {\Gamma \vdash v : T}{\Gamma \vdash \textbf{new}(T, v) : T\textit{ ref}}[(\textbf{new} reference 2)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Ref Type}
\end{figure}

\par
The typing judgement above are straightforward, in the first rule, we check the 
type $T$ of the underlying value at heap address $h$ then $h$ is of type $T$ 
\textit{ref}.

\subsubsection{Basic Operational Semantics}
Lastly, we need to define the operational semantics for the new addition. We 
begin by defining the SOS rules for pointers. As the reduction rules for 
expressions are largely similar to before we will be ommiting them and only 
focus on the value itself. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h_1 \in \textbf{dom}(\Delta) & v = \Delta(h_1) & h_1 \neq nil}
      {\langle !h_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v, 
      \sigma, \tau, \Delta \rangle} [(Pointer dereferencing)]
      & \\
      \inference {h_1 \in \textbf{dom}(\Delta) & h_1 \neq nil & \Delta' = \Delta \uplus \{h_1 \mapsto v_1\}}
        {\langle !h_1 := v_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v_1, 
        \sigma, \tau, \Delta' \rangle} [(Pointer assignment)]
      & \\
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta 
        \uplus \{h \mapsto v\}}
        {\langle \textbf{new}(T, v), \sigma, \tau, \Delta \rangle \longrightarrow \langle h, 
        \sigma, \tau, \Delta' \rangle} [(Pointer allocation)]
      & \\
        $\langle \textbf{new}(T), \sigma, \tau, \Delta \rangle \longrightarrow \langle nil, 
        \sigma, \tau, \Delta' \rangle$ ($nil$ pointer allocation)
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers}
\end{figure}

\par
Pointers are allocated in two ways, with and without a value. The first rule for 
pointer allocation allocates a new heap address and assigns it the value passed 
in. Calling \textbf{new} without specifying a value, follows the second 
pointer allocation rule ($nil$ pointer allocation) which evaluates to a $nil$ reference. 
A $nil$ reference is not allocated in the state $\Delta$ and cannot be deference 
or assigned to. 

\subsection{Aliases in Dependent Types}
Previously we explored the behaviour of variables in dependent types and 
proposed three different solutions to address the ambiguity when depending on 
variables. It is important to note that we only considered 
local variables, the notions of pointers and references will complicate matters. 
In this subsection we will discuss the potential pitfalls when dependent types 
involves pointers. 
 
\par
First let us consider the following code snippet, assuming we are utilise 
approach 1 defined previously to address variables in dependent types.

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let const }$y\text{ }:\text{ } int \textit{ ref} = \textbf{new}(int, 10)$\textbf{ in } \\
    \textbf{let const }$x\text{ }:\text{ }int\textit{ ref} = y$\textbf{ in } \\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y : int\text{ ref}. \{i : Int\text{ }|\text{ }i < !y\}$ \textbf{ in } \\ 
    \tab\tab\textbf{let var }$z\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in }$!x := 5$\textbf { end }\\
    \tab\textbf {end} \textbf{end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Changing Values of Aliases within Dependent Types}
\end{figure}

\par
In the above scenario, a pointer to an $int$ $y$ is declared, another variable $x$ 
acts as its alias, i.e. both $x$ and $y$ points to the same memory address. The 
expression $!x := 5$ indirectly modified the definition of the type 
$BoundedIntY$, making $z$ ill-typed. Our defined semantics does not have a way 
to prevent this,

\par
In order to address this case, some of our previous proposed solutions 
to the problem will need to be extended. While it is perfectly reasonable to 
restrict mutation simply by marking a local variable \textit{const}, 
the same can't be done with pointers. A constant 
pointer variable simply restrict the address held by the pointer to be change, 
manipulating the underlying value is still very much possible.

\par
A possible approach would be to extend the previously defined semantics to 
operate on memory location as well as local variables. In C/C++, one is able to 
declare a pointer to a constant, we would require the same in Simple-$\Pi$. It 
is important to note the difference between an immutable pointer and a pointer 
to an immutable. The latter allows the pointer variable to change. In order to 
concrete differentiate the two in a definite manner, we introduce 
a new predicate $is\_nonrewriteable(h)$ to specify if a 
certain heap address can be modified. 

\par
$is\_nonrewriteable(h)$ holds if and only if the heap address $h$ is a const and cannot 
be rewritten. The predicate operates directly on heap address rather than 
pointers itself as 
it is possible to have a pointer to a pointer which will invalidate the 
predicate. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}      
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ \textbf{newconst}}(T, v)$ \\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$\Pi$}
\end{figure}


\par
We first need to extend our syntax to have a way of declaring pointers to 
constant. In the pursuit of simplicity, we include a new expression 
\textbf{newconst}$(T, v)$ to our language, this creates a new pointer to $T$ and 
assigns the value $v$. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash v : T} 
        {\Gamma \vdash \textbf{newconst}(T, v): T \textit{ ref}}[(\textbf{newconst} type)] 
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Pointer to Constants}
\end{figure}

\par
Notice that unlike C/C++, it is not possible to define a constant $nil$ pointer. 
The reason for this is because we believe that a constant $nil$ pointer 
serves no purpose and using the $nil$ value is adequate in all operations. 

\par
The figure above formalises the typing judgement for this new expression and 
its behaviour is captured using the evaluation rules defined in figure 4.27 
below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta 
      \uplus \{h \mapsto v\}}
      {\langle \textbf{newconst}(T, v), \sigma, \tau, \Delta \rangle \longrightarrow \langle h, 
      \sigma, \tau, \Delta' \rangle} [(\textbf{newconst} 1)]
      & \\
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle e_1', \sigma', \tau', \Delta' \rangle}
      {\langle \textbf{newconst}(T, e_1), \sigma, \tau, \Delta \rangle \longrightarrow \langle \textbf{newconst}(T, e_1'), 
      \sigma', \tau', \Delta' \rangle} [(\textbf{newconst} 2)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers to Constants}
\end{figure}

\par
Additionally, we need to restrict the ability to rewrite memory location that 
are deemed non-rewriteable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h_1 \in \textbf{dom}(\Delta) & \neg is\_nonrewritable(h_1) & \Delta' = \Delta \uplus \{h_1 \mapsto v_1\}}
      {\langle !h_1 := v_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v_1, 
      \sigma, \tau, \Delta' \rangle} [(Pointer assignment)]
    \end{tabular}
  \end{center}
  \caption{Restricting Write to Immutable Memory Locations}
\end{figure}


\par
The introduction of immutable memory locations will allow us to specify the 
behaviour of pointers in dependent types. We formalise the behaviour by 
decomposing the operational semantics defined in figure 4.10, 
stipulating different behaviours for values and references. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      \sigma(x) \notin \Delta &
      a \notin \text{\textbf{dom}}(\sigma) & is\_immutable(x) & a \notin \textbf{dom}(\tau) 
      \\ \langle e_1, \sigma, \tau + \{a \mapsto \Pi x : A.P(x)\} \rangle 
      \longrightarrow^{*} \langle v, \sigma', \tau' \rangle}
      {\langle \textbf{typedef } a = \Pi x :A .P(x) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau' - \{a\}\rangle}[(\textbf{typedef}) $\Pi$ vals]  
      & \\
      \inference {
      \sigma(x) \in \Delta &
      a \notin \text{\textbf{dom}}(\sigma) &  a \notin \textbf{dom}(\tau) \\ is\_immutable(x) & is\_nonrewriteable(\sigma(x)) \\
      & \langle e_1, \sigma, \tau + \{a \mapsto \Pi x : A.P(x)\} \rangle 
      \longrightarrow^{*} \langle v, \sigma', \tau' \rangle}
      {\langle \textbf{typedef } a = \Pi x :A .P(x) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau' - \{a\}\rangle}[(\textbf{typedef}) $\Pi$ refs] 
    \end{tabular}
  \end{center}
  \caption{Operational Semantics Dependent Type Definition with Pointers}
\end{figure}


\par
The appropriate rule is applied during evaluation, the top rule 
(\textbf{typedef} $\Pi$ vals) is evaluated if the variable depended on $x$ is 
a local variable and not a reference. In this case, our previous logic would hold, 
$x$ must be a constant. If, however, $x$ is a pointer variable, then we would have 
to apply the second rule which asserts that in addition to $x$ being a constant, 
preventing it to be reassigned to a different heap address, 
the underlying memory location held by $x$ must not be rewriteable. 

\par
With our newly defined rules the program in figure 4.24 becomes invalid, 
we can rewrite our program to be correct as shown in the example below. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let const }$y\text{ }:\text{ } int \textit{ ref} = \textbf{newconst}(int, 10)$\textbf{ in }\\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y : int\text{ ref}. \{i : Int\text{ }|\text{ }i < !y\}$ \textbf{ in } \\ 
    \tab\tab\textbf{let var }$z\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in skip end}\\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Valid use of Pointers in Dependent Types}
\end{figure}


\par
In this subsection we have adapted our first approach to accomodate advance 
language features such as heap addresses and aliasing. While minor changes are 
needed to adapt the reamining two approaches to accomodate, we decided to leave 
them out of scope for the current project and as an open future work.


\subsection{Vectors using Dependent Types}


\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Types} & $T$ & $:$ $...\text{ }|\text{ } T \text{ }array$ \\
      \textit{Expressions} & $e$ & $:$ $...\text{ }|\text{ }e_1[e_2]\text{ }
        |\text{ }e_1[e_2] := e_3\text{ }|\text{ }\textbf{size}(e_1)$ \\
        & & \; $|\text{ }\textbf{newarray}(e_1, T)$\\
     \textit{Values} & $vals$ & $:$ $...\text{ }|\text{ }(h_0,h_1...h_n)$
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$\Pi$}
\end{figure}

\par
$T$ $array$ is an array type. Like most languages, arrays are typed 
and all elements in the array must be of type $T$.

We introduced the following expressions into the language:
\begin{itemize}
  \item $e_1[e_1]$ to index an element in an array, like C/C++, arrays are 
  0-indexed. $e_1[e_2] := e_3$ to assign values into arrays.
  \item \textbf{size}$(e_1)$ to retrive the size of an array.
  \item \textbf{newarray}$(e_1, T)$ to allocate a new array of $T$ that is of 
  \textbf{size}$(e_1)$.
\end{itemize}



\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {v_0 = (h_0,h_1...h_n) & v_1 >= 0 & v_1 \leq n} 
        {\langle v_0[v_1], \sigma,\tau,\Delta \rangle 
          \longrightarrow \langle !h_{v_1}, \sigma, \tau, \Delta \rangle} [($array$ indexing)]
      & \\
      \inference {v_0 = (h_0,h_1...h_n) & v_1 >= 0 & v_1 \leq n & \Delta' = \Delta \uplus \{h_{v_1} \mapsto v_2\}} 
        {\langle v_0[v_1] := v_2, \sigma,\tau,\Delta \rangle 
          \longrightarrow \langle v_2, \sigma, \tau, \Delta' \rangle} [($array$ mutation)]
     & \\
     \inference {v_0 = (h_0,h_1...h_{v_1}) \\ \Delta' = \Delta \uplus \{h_0 \mapsto nil, h_1 \mapsto nil,...h_{v_1} \mapsto nil\}} 
        {\langle \textbf{newarray}(v_1, T), \sigma,\tau,\Delta \rangle 
          \longrightarrow \langle v_0, \sigma, \tau, \Delta' \rangle} [($array$ creation)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Arrays}
\end{figure}



\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1 : T\text{ }array & \Gamma \vdash e_2 : int} 
        {\Gamma \vdash e_1[e_2] : T}[($array$ indexing)]
      & \\
      \inference {\Gamma(h_0) = T\textit{ ref} & \Gamma(h_1) = T\textit{ ref} &...& \Gamma(h_n) = T\textit{ ref}} 
        {\Gamma \vdash (h_0,h_1...h_n) : T\text{ }array}[($array$ type)] 
      & \\
      \inference {\Gamma \vdash e_1 : T\text{ }array & \Gamma \vdash e_2 : int \\ \Gamma \vdash e_3 : T} 
        {\Gamma \vdash e_1[e_2] := e_3 : T}[($array$ mutation)] 
      & \\
      \inference {\Gamma \vdash e_1 : T\text{ }array} 
        {\Gamma \vdash \textbf{size}(e_1) : int}[(\textbf{size} of $array$)]
      & \\
      \inference {\Gamma \vdash e_1 : int} 
        {\Gamma \vdash \textbf{newarray}(e_1, T) : T\text{ }array}[(\textbf{newarray} formation)]
    \end{tabular}
  \end{center}
  \caption{More Typing Rules for the Array and Ref Type}
\end{figure}



\chapter{Related Work}

\chapter{Further Work}

\chapter{Summary and Conclusions} 


\appendix
\singlespacing

\printbibliography

\end{document}
