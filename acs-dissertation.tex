%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 

\documentclass[a4paper,12pt]{report}
%TC:group tabular 1 1


%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Xiu Hong\ Kooi\xspace}
\def\authorcollege{Wolfson College\xspace}
\def\authoremail{xhk20@cam.ac.uk}
\def\dissertationtitle{Investigating the Behaviour of Refinement Types in a Mutable Environment}
\def\wordcount{0}


%\usepackage[dvips]{epsfig,graphics} 
\usepackage{epsfig,graphicx,verbatim,parskip,tabularx,setspace,xspace}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{semantic}
\usepackage{float}

\usepackage{tabto}

\newenvironment{tabs}[1]
 {\flushleft\TabPositions{#1}}
 {\endflushleft}

\usepackage[british]{babel}
\usepackage[%
  backend=bibtex      % biber or bibtex
%,style=authoryear    % Alphabeticalsch
 ,style=numeric-comp  % numerical-compressed
 ,sorting=none        % no sorting
 ,sortcites=true      % some other example options ...
 ,maxbibnames=99
 ,block=none
 ,indexing=false
 ,citereset=none
 ,isbn=true
 ,url=true
 ,doi=true            % prints doi
 ,natbib=true         % if you need natbib functions
]{biblatex}
\usepackage{biblatex}
\addbibresource{./dissertation.bib}


%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
\listoffigures
\listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 
\textit{Type systems} \cite{typesystem} have been one of the most extensively researched field in 
Programming Languages. They act as a way from improving the reliability of a 
language by enforcing rules, preventing operations being applied on 
incompatible data. Type systems can be broken down into multiple categories but 
two of the most well known are \textit{Static} \cite{staticTyping} and 
\textit{Dynamic} \cite{dynamicTyping} typing. Mainstream programming 
languages such as \textit{Java} \cite{java}, \textit{C} \cite{c} and \textit{C++} \cite{cpp} 
uses the former while languages like \textit{Python} \cite{python} and 
\textit{JavaScript} \cite{js} uses the latter. 
Over the years, programming languages have included more powerful and flexible 
type systems, languages like \textit{C\#} \cite{cSharp} and \textit{Go} \cite{goInferenceType} allow 
\textit{type inference} \cite{inferenceType}, using a feature called \textit{Reflection} 
Java and Python can even achieve \textit{Duck Typing} \cite{javaDuckType}.
\par
However, as much as we have studied about type systems, \textit{Dependent Types} 
\cite{depenTypeAtWork} remains uncommon in the industry. While the theory of dependent types has been 
established several decades ago, only a small number of languages has 
integrate full dependent type support, most of them being functional languages. 
Dependent types allows the programmer to create types whose definition depends 
on a value. A type system that provides such refined control over the values it 
can take unlocks possibility that are previously unavailable such as 
domain-specific type checking at compile time. Furthermore, it acts as a built 
in ``error-handling'' code and could potentially 
reduces the lines of code a programmer needs to write. An in depth 
definition of dependent types is provided in the next section.

\par
The expressive nature of dependent types allow one to 
define complex mathematical assertations and hence lends itself to 
theorem proving systems. Mutliple functional languages such as \textit{Epigram} 
\cite{epigram} and \textit{Agda} \cite{agda} has 
built in support for dependent typin.  However they remain niche and more 
mainstream languages like Java and C++ does not get the luxury. In chapter 2 of 
this dissertation we will be providing an in depth analysis of the current state 
of dependent types in programming languages and answer why dependent types are 
not more prominant in languages, in particular imperative languages.

\par
Multiple past research has studied and show the feasibility of an dependently typed 
imperative language. These studies has expressed the semantics of 
how an imperative languages would interact with dependent types and in some 
cases created a new language from the ground up. While we find these work novel 
and provided highly technical explanation to the field, they fail to caputure 
how this could relate to mainsteam programming languages. Furhtermore, the 
semantics provided in these studies are very complex with advanced language 
features, we propose that a more simple and barebone definiton will allow easier 
access to the literature and motivate more studies into dependenty types. 

\par
A further restriction on dependent types can be found in \textit{Refinement 
Types} \cite{refinementTypes}. Refinement types allows one to specify subtypes 
of existing types, dependent types on the other hand allow one to create 
arbitrary types. A refinement types is constrained by a decidable predicte, 
bringing a better ease of programming. While dependent types are significantly 
more powerful than refinement types, the latter provides a good balance between 
expressiveness and ease of use. We propose to create a simple framework with 
refinement typing that resembles mainstream programming language in order to 
study the subject further. 

\par
This dissertation serves as a document for our findings and is organised as 
follows. This first chapter serves as an introduction to dependent types, 
refinement types and the motivation behind our work.

\par
Chapter 2 if a survey on the current state of dependent types and refinement 
types in existing programming languages. Different languages with varying 
paradigm are explored 
and summarised in order to better understand the extend of their support 
for dependent types. Functional lanaguages and theorem provers are studied to 
understand how dependent types behave in their natural environment. As 
refinement types proves to be more niche and there is no production language 
with refinement support, we studied past research that attempts to bring the 
language mainstream. Finally, we extensively studied C++ as its templating 
engine bears strong resemblence to refinement types and we observe its limitation. 
We conclude the chapter by proposing how our project will address these limitations. 

\par
In chapter 3 we will be introducing an imperative language with refinement type support. 
Our language, named Simple-$R$ is a First-Order Programming Language which 
highly resembles the C programming language. Our aim with the language is to 
capture the core behaviour of refinement types and thus for the pursuit 
of simplicity is kept at a minimal with 
only the fundamental features. In this chapter, we will be 
defining the syntax, typing rules and semantics 
of a basic language with refinement types support which serves as a basis 
which will be studied throughout the chapter. 
We then present the semantics of Simple-$\Pi$, in addition 
to the basic operational semantics, we will raise
multiple scenarios that refinement types cause ambiguity in imperative programming. 
We start by discussing the impact of mutability has on dependent types and 
answer the problem by proposing different solutions to resolve the 
ambiguity and observes how these approaches differs. 
We follow up our findings by introducing pointers and how the approach used to 
address mutability can be adapted to handle alias variables. Finally we conclude 
the chapter by showing an example of building arrays with dependent types. 

\par
In chapter 4 we will discuss our work with regards to the 
existing work done in the area and how it completments the literature.
Finally we will conclude by discussing advanced features that can be integrated 
into our languages and how it can further complicate the language. We will also 
discuss some of the other considerations that need to be taken account when 
thinking about incorporating dependent types into a real language. 

\section{What Are Dependent Types}
In this section we will be providing the definitions of dependent types.

\subsection{Basic Definition}
At a very high level dependent types are types that depends on the value of 
another type. For example, we can define a type that captures only the even 
integers using the definition 
\verb+type EvenInt := { i : Int | i % 2 = 0}+. In this case we 
can say that the type EvenInt \textit{EvenInt} depends on the type \textit{int}.
Another commonly used example to describe dependent types would be a type like 
\verb+type FixVec<T, N> := { v : Vec<T> | len(v) = N}+, this type definition defines 
a vector or array of elements with type $T$ that always contains $N$ elements.

\subsection{Dependent $\Pi$ Types}
We can capture the definition mathematically using the notion of \textit{dependent 
product types}, i.e. $\Pi$ type. This is also sometimes referred to as 
\textit{dependent function type} as in this definition we construct a function 
$F: A \rightarrow B$. The function $F$ takes an element of type $A$ and 
gives us an element of type $B$ which depends on $A$. We express it 
mathematically using the $\Pi$ notation as
\begin{center}
 \begin{tabular}{l}
   $\prod x: A.  F(x)$
 \end{tabular} 
\end{center}

In this definition, $F(x)$ is the type family for the type $B$ that depends on $A$.
However $F$ could be a constant function, so we can also express the definition 
as $\Pi x:A.B$, in this case $B$ does not depend 
on the value $x$. Using the \textit{EvenInt} example from earlier, 
it can be defined as 
$\Pi x:Int.\text{ }\{ i:Int\text{ }|\text{ }i\text{ }\%\text{ }2\text{ }= 0\}$.

\par
Interestingly, the dependent product type correspond to the 
\textit{forall quantifier} as per 
the \textit{Curry–Howard correspondence}. The idea is that the dependent 
function $F(x)$ correspond to predicate $P(x)$ and thus the dependent product 
type has a one-to-one correspondence to $\forall x: A. P(x)$.

\subsection{Dependent $\Sigma$ Types}
In addition to the dependent product type, we have the notion of \textit{dependent sum 
types}, written as $\Sigma$ type. This is often referred to as the 
\textit{dependent pair type} as the resulting type here is an ordered pair. 
Specifically the resulting pair $\langle a,b \rangle$ is ordered such that the 
second element depends on the first element. The 
mathematical definition is similar to that of the product type
\begin{center}
 \begin{tabular}{l}
   $\langle a,b \rangle :\sum x: A.  F(x)$
 \end{tabular} 
\end{center}
In the case $a:A, b: F(x)$, similarly, $F$ could be a constant function and thus 
the expression is $\Sigma x:A.B$. Consider the following example, 

$\Sigma x: Int.\{y:Int\text{ }|\text{ } y = x * 2\}$, then the type would 
contain values like $\langle 1,2 \rangle$ and $\langle 4,8 \rangle$ where the 
second pair is doubled the first.

\par
Like the dependent product type, the dependent sum type correspond to a 
universal quantifier, in this case, the \textit{existential quantifier}. As 
per the Curry–Howard correspondence, $F(x)$ corresponds to predicate $P(x)$ 
thus $\Sigma x:A.F(x)$ correponds to $\exists x: A. P(x)$.

\par
While both dependent product types and dependent sum types are important to the 
literature, the project itself will mainly focus on the former. we believe that 
the the notion of pair in dependent sum types prove to be redundant in 
the construction a programming language and does not provide any additional 
value. The dependent product type is largely adequate for our goal.

\section{Refinement Types vs Dependent Types}
Refinement Types is a type system where a certain base type is refined by a 
predicate. A refinement type $A$ is written in the form 
$\{\upsilon : B\text{ }|\text{ }P(\upsilon)\}$. $\upsilon$ is a special variable 
not in the program, $B$ is a base type and $P(\upsilon)$ is the 
\textit{refinement predicate}, a boolean expression 
involving $\upsilon$ and any free variables in the program. Formally, a value 
$i$ is well typed with regards to a refinement type if $P(i)$ evaluates to 
\textit{true}.

\par
The key differentiating factor between refinement types and dependent types is 
that the latter is unrestricted. A refinement type is restricted predicate 
$P(\upsilon)$ whereas a dependent types is able to rely on a function $P(x)$ 
where there is no algorithm to prove its correctness. One has to manually 
provide the proof for a dependent types. Furthermore, a refinement type $A$ 
that is a refinement on a base type $B$ has a the property $A \preceq B$ 
specifying $A$ is a subtype of $B$, this is not true in a dependent type 
language.

\par
The decidability of refinement types allow one high level of automation and 
provide a simpler understanding. While in many cases dependent types prove to be 
more powerful, refinement types for all intent and purposes does the job in 
providing the improved expressivity for general programming. For this reason, we 
will be basing our project on refinement types. 

\section{Overview of a Dependently Typed Language}
In this section we will discuss at a very high level the behaviour one would 
expect from a dependently typed language, its benefits and use cases.

\subsection{Language Behaviour}
The key behaviour we are interested in is regarding compile time type checking. 
For instance, using the example above, if a type is defined as an \textit{EvenInt} 
then if at any point in the code it becomes odd then it should be caught at 
compile time. 

\par
Consider the psedocode below: 
\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  function f(int x) {
    if (x \% 2 == 0) {
      ...
    }
    throw error ``x has to be even''
  }
  
  function dependent_f(EvenInt i) {
    ...
  }
  \end{lstlisting}
  \caption{Dependenty Typed Language Behaviour}
\end{figure}

\par
The function \textit{f} above checks whether the argument $x$ is even, if it 
isn't then it throws a runtime error. If dependent type is available, then if an 
invalid argument is passed in it should signal an error at compile time, saving the 
error handling code as shown in \textit{dependent\_f}. 

\subsection{Benefits of Dependent Types}
As we seen in the previous subsection, dependent types allows programmer to 
define much richer and expressive types that can be checked at compile time. The 
addition of dependent types allow for safer code as it is able to guarentee certain 
properties. 

\par
Furthermore, using dependent types eliminates the need for many trivial error 
handling code. Around 4\% of code in every program is dedicated to error 
handling \cite{errorHandlingCode}, dependent types will be able to reduce the 
numbers and allow the programmer more time to write the logical part of the 
code, indirectly leading to more robust codebases.

\par
Consider a banking system where users are able to transfer and withdraw 
money using a function, 
in order to prevent overdraft one might be able to define a function that takes 
a type \textit{Amount$<$T$>$}, a double type that is always 
greater than 0 and less than \textit{T}, where \textit{T} is the current balance in the account. 
This approach guarantees the amount is always valid without the need of writing 
error handling code. This example demonstrated using an object-oriented style 
language by Vasconcelos \cite{objOritentedDependentType}.


\section{Motivation}
Dependent types appears to be one of the niche fields in programming language 
theory and type theory research. I argue that this is the result of the 
difficult barrier of entry. Research in dependent types presented are usually 
highly complex and requires substantial prerequisite. Type systems presented in 
these paper often assumes full knowledge of \textit{The Lambda Calculus} 
\cite{lambdaCalculus} or uses the concept of \textit{Monads} \cite{monads}. 
While these are established framework commonly used to express and reason about 
computation, with the addition of normal types and dependent types, the 
underlying logic becomes hard to follow. 

\par
Similarly, research in the area that branch away from the convention of building 
a dependent type system on the lambda calculus often showed highly complex 
language features such as object orientation and dynamic memory allocation. The 
purpose of these research often are to demonstrate the feasibility of 
incorporating dependenet types in complex languages rather than providing an 
overview of the concept. 

\par
Our project is motivated by the apparent lack of accesible literature on the 
theory of dependent types. We aim to present a simple, restricted framework that 
captures the essence of dependent types. The said framework will be presented as 
an extension to \textit{WHILE language} \cite{whileLanguage}. Created as a tool 
to aid the study of programming language theory, we believe it strongly satisfy our 
requirement of accessibility with its simple syntax and semantics. 

\par
At the end of the project we aim to achieve the following, i) Survey the state 
of dependently typed languages and their differences, ii) Describe a dependently 
typed language based on the WHILE language, iii) Explore the ambiguity of 
dependent types in an imperative environments, iv) Demonstrate the use of 
dependent types to build further language features, v) Discuss how our work 
compliments the literature. 


\chapter{Background Research} 
In this chapter we will be reviewing the current knowledge of dependent types 
in different programming languages. It will cover languages with full dependent 
types support as well as some languages with similar concepts and point out how 
it differs from dependent types. Lastly we will summarise all these languages 
and point out some limitations and unknowns. 

\section{Functional Languages}

In this section we will be examining three functional languages with 
dependent typing. Functional languages 
uses the \textit{functional programming} \cite{overviewFP} paradigm which is a programming 
paradigm that constructs program using a series of function applications. In 
this paradigm, functions return values as oppose to altering the state of the 
program. In this programming paradigm, the language focuses on describing 
\textit{what} the program will accomplish.

\par

Many functional languages has the notion of purity, i) A function will always 
return the same value when given the same arguments. ii) The evaluation of a 
function has no side effects (changes to the state of the program).

\subsection{Agda}

\textit{Agda} \cite{agda} is a purely functional language originally developed by Ulf Norell in 
1999 however the first appearance the current version known as Agda 2 is in 
2007. Agda has all the necessary constructs one would expect in a functional 
language such as first-class functions, inductive definitions, pattern matching, 
etc. In addition to being a functional language, Agda also serves an automated theorem prover. 
Agda is one of the few programming language with native dependent type support. 

\par
The code listing below is an example of defining a fixed length vector in 
dependent type. 

\begin{figure}[H]
  \begin{lstlisting}[mathescape=true] 
  data Nat : Set where 
  zero : Nat
  suc  : Nat -> Nat  
  
  data EvenNat : Nat -> Set where
  even-zero  : EvenNat zero
  even-plus2 : {n : Nat} -> EvenNat n -> EvenNat (suc (suc n))
  
  data Vec (A : Set) : Nat -> Set where
  [] : Vec A zero
  _::_ : {n : Nat} -> A -> Vec A n -> Vec A (suc n)
  \end{lstlisting}
  \caption{Dependent Types in Agda}
\end{figure}

\par
While Agda provides dependent type support, it remains a niche language. One of 
the reason being its paradigm, Agda is \textit{purely functional} \cite{purelyFP}, meaning that 
all functions are pure (i.e. not relying on the program state or other mutable 
data). Functional languages are generally considered harder to learn and grasp 
compared to other paradigms \cite{fpHarder}. Furthermore, the general lack of 
awareness and competent users who can program dependent types contribute to Agda 
being a niche language in the programming world and is 
predominantly used for theorem proving.

\subsection{Haskell}
\textit{Haskell} \cite{haskell} is a purely functional programming language first appeared in 1990. In 
contrast to Agda, Haskell is often considered a more general purpose programming 
language. Haskell is among the most popular programming languages and argubly 
the most popular ``pure'' language in the world \cite{pypl}. 
Haskell has even been adopted by software companies such as Facebook \cite{haskellFB}.

\par
Haskell is not a language that supports dependent types natively however many 
extensions has been developed to simulate the experience. 
Generalised Algebraic Data Types (GADTs) are a generalization of the 
algebraic data types, it allows the programmer to 
explicitly write down the types of the constructors \cite{haskellGADT}. 
\begin{figure}[H]
  \begin{lstlisting}
    data Expr = I Int        
          | Add Expr Expr 
          | Mul Expr Expr 
  \end{lstlisting}
  \caption{A GADT defintion for arithmetic operations in Haskell}
\end{figure}

Using the power of GADT one could define dependent types as so

\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat (n :: Nat) where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vec a (n :: Nat) where
      Nil  :: Vec a 0
      (:>) :: a -> Vec a n -> Vec a (n + 1)
  \end{lstlisting}
  \caption{Dependent Types in Haskell}
\end{figure}

\par
Although GADTs provide a way of simulating dependent types in Haskell and 
argubly enough for simple dependent typing enough for many cases. 
Haskell does not qualify as a fully dependent 
language due to the lack of certain features such as dependent functions. There 
have been proposals to add full dependent type support to Haskell however a lot 
of work remains to be done \cite{dependentHaskell, aRoleForDependentHaskell}. 
Furthermore, while Haskell is significantly more well known compared to Agda, it 
still lack the popularity of languages like Java and Python.

\subsection{Idris}
\textit{Idris} \cite{idris} is a dependently typed functional language first 
appeared in 2007. Idris bears similarity with Agda, both in terms of paradigm 
and type system. However the differ in one crucial way, Idris is designed to 
emphasise general purpose programming rather than theorem proving. Earlier one 
we stated that one of the less desirable property of Agda was its niche because 
of its emphasis in theorem proving. Idris provides 
interoperability with systems libraries and C programs, 
as well as language constructs for domain specific language 
implementation \cite{gpIdris}. 

\par
Syntactically Idris is very similar to Agda, dependent types are defined as so: 
\begin{figure}[H]
  \begin{lstlisting}      
    data EvenNat :  Nat -> Type where
      EvenZero  :: EvenNat 0
      EvenPlusTwo :: EvenNat n -> EvenNat (n + 2)
      
    data Vect : Nat -> Type -> Type where
      Nil  : Vect 0 a
      (::) : (x : a) -> (xs : Vect n a) -> Vect (n + 1) a
  \end{lstlisting}
  \caption{Dependent Types in Idris}
\end{figure}

\par
While Idris offers interoperability with multiple mainstream programming 
languages such as C and JavaScript, Idris remain predominantly a research tool. 
Idris is not production ready \cite{gpIdris} as it is missing certain libraries 
and more importantly nobody is working on Idris full time. Furthermore Idris is 
still a functional language, hence suffering from the limitation stated earlier. 

\section{Imperative Languages}

In this section we will be discussing dependent typing with regards to imperative 
languages. Imprative languages uses the \textit{imperative programming} 
\cite{imperativeOverview} paradigm, in constrat to the functional 
programming, this pradigm emphasises \textit{how} a program will operate 
by using a series of statements to change the program state.

\par

Imperative languages can be further broken down into different categories, 
mainly Procedural and Object-Orinted. Many of the world's most popular languages 
fall into this two categories, C, FORTRAN, COBOL are examples of procedural 
languages while Java, C#, Kotlin are Object-Oriented Languages. Some languages such 
as C++, Python are multi-paradigm and allows the programmer to write code both 
in a procedural manner or object-oriented manner. 

\par

Currently there is no production ready imperative programming language with 
proper dependent type support. Previous research has look at creating an 
impertaive language with dependent types but these are not available to the 
general programmers. Certain mainstream languages also have aspect that 
resembles dependent types but do not provide the complete feature.

\subsection{Xanadu}
\textit{Xanadu} \cite{xanadu} is a dependently typed imperative language created by a team at 
the University of Cincinnati. The language was implemented in OCaml and was 
said to be available online in the original paper, however the original cited 
location looks to have been taken offline. It is safe to conclude that 
the language itself is also no longer in active development 

\par
There are no examples of the actual language available online except some code 
snippets shown by the author in the original paper. As such we are unable to 
provide any analysis on the language itself.

\par
However, the language is worth a mention here as it shows the feasibility of 
imperative languages having full dependent typing. The research by the authors 
are impressive and it serves as inspiration for our project. 

\par
Our project complements the work by Xi by providing analysis on the problem at 
hand. The original paper merely demonstrated the development and semantics of 
Xanadu, our project aims to discuss more on the topic. 

\subsection{C++ Templates}
\textit{C++ Templates} \cite{cppTemplate} are a way of passing the type of a 
data as a parameter so certain code can be reused. For instance, the same 
sorting algorithm can be used on multiple data types such as \textit{int} and 
\textit{double}, using templates the programmer will not need to write the same 
sorting function multiple times for different data types. 

\par
Templates are often compared to Java's \textit{Generics} \cite{javaGenerics} 
as the C++ equivalent. While this statement is mostly true, C++ templates 
differ in a big way. 
Generics only allow the template parameter to be a class, templates on the other 
hand allow the parameter to be a class, values or pointers. The ability to 
pass values into a template to create types certainly resembles dependent types.

\par
The code listing below is an example of templates with values. It defines the 
struct that represents an integer less than N. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N>
    struct LessThanN {
      int value;
      LessThanN(int x) {
        if (x < N)
            value = x;
        else
           throw ``invalid type'';
      }
    };
  \end{lstlisting}
  \caption{Struct dependent on values using C++ Templates}
\end{figure}

\par
Using the above definition it is possible to define types such as \\
\verb+LessThanN<5> ltf = LessThanN<5>(3)+, this will define a type that will has 
to be less than 5. However, certain questions arise from this definition, 

i) What will happen if the constructor is given an invalid argument? 

ii) What if the template parameter is a variable and its 
value change? 

iii) What if the value of \textit{value} change during execution?

In the subsequent text, the term ``Dependent Value'' will be used to refer to the 
value $N$ and ``Value'' will refer to the actual value held by a LessThanN type, 
i.e. the \textit{value} state in the struct. 

\subsubsection{The Intended Behaviour}
First, we observe the intended behaviour of LessThanN using the following test 
code:
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(3);
      cout << ltf.value; // Prints out 3
      return 0;
    }
  \end{lstlisting}
  \caption{Intended Behaviour of LessThanN in C++}
\end{figure}

\par
As expected, the code compiles perfectly and outputs 3 when executed.

\subsubsection{Invalid Definition of LessThanN}
In order to observe the behaviour of i), we simply have to pass in an 
invalid value into the constructor, i.e. a value greater than N, 
the test is conducted using the code below. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int main() {
      LessThanN<5> ltf = LessThanN<5>(10); // Error here
      cout << ltf.value; 
      return 0;
    }
  \end{lstlisting}
  \caption{Invalid Definition of LessThanN in C++}
\end{figure}

\par
Interestingly, the code compiles perfectely despite the invalid definition. 
However it fails to execute as the exeception thrown in the \textbf{else} clause 
is left uncaught. This behaviour makes it no better than an simple if statement 
in the constructor. An addition in C++ 11 was the introduction of 
\textit{constexpr} and \textit{static\_assertation}. These allow for certain 
compile time checking, however the values checked must fulfil 
the \textit{constant expression} requiremets \cite{cppConstExpr}. 

\par
Modifying the \textbf{struct} to use the code below we get compile time type 
checking. 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    template <int N, int M>
    struct LessThanN {
      int value;
      LessThanN() {
        static_assert(M < N, ``type is invalid'');
        value = M;
      }
    };
  \end{lstlisting}
  \caption{LessThanN with Compile Time Type Checking in C++}
  \label{code:compileLTN}
\end{figure}

\par
Now, providing an invalid definition yields a compile time error, with the 
following: 
\verb+LessThanN<10, 12> ltf = LessThanN<10, 12>;+ 

\textbf{static\_assert failed due to requirement `12 $<$ 10' ``type is invalid''}

\subsubsection{Mutation of Template Variable}
In our previous example we have been passing integer literal as the template 
parameter for the dependent value. Often programmers are required to 
work with varied values through variables, how will this effect the behaviour? 

\par
Consider the following hypothetical situation using the struct defined in 
figure \ref{code:compileLTN}: 

\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>();
    n = 2; // Is ltf still well typed??
  \end{lstlisting}
  \caption{Mutating the Dependent Variable for LessThanN in C++}
\end{figure}

\par
Compiling the above code leads to a compile time error, C++ requires template 
arguments to be constant expressions. In order to use variables as template 
arguments, they have to be defined \textbf{const}. In which case the above 
situation is impossible as the variable $n$ now cannot be changed. 

\subsubsection{Changing The Value of Struct During Execution}
We've showed that it is not possible to change the dependent value in 
the program, however what if the value changes? Will a 
variable be well-typed on one line and ill-typed on the next line? 

\par
Consider the following code: 
\begin{figure}[H]
  \begin{lstlisting}[language=c++]     
    const int n = 5;
    LessThanN<n, 3> ltf = LessThanN<n, 3>(); // Well typed
    ltf.value = 10; // Now ill-typed but not caught
  \end{lstlisting}
  \caption{Mutating the value of LessThanN in C++}
\end{figure}

\par
In order to achieve our intended behaviour there has to be some form of check 
that runs throughout the lifetime of the program, currently there is no native 
support for this form of invariant. However one potential workaround as a 
programmer would be to make the LessThanN type immutable, by setting \textit{value} 
to be a \textbf{const} however that significantly limits the usability of the 
language. 

\par
We see glimpses of dependent typing in certain imperative languages, the 
examples using C++ presented above is one of them. One could argue arrays in 
Java and C++ resembles the fixed size vector however they are quite similar. In 
the subsequent chapters of this dissertation we will define a language to 
address these uncertainties. 


\section{Summary of Dependently Typed Langauge}
\begin{table} [H]
  \begin{tabular}{|p{2cm}|p{2cm}|p{10cm}|}
    \hline
    \textbf{Name} & \textbf{Paradigm} & \textbf{Notes} \\ 
    \hline
    Agda & Purely Functional & Actively developed but 
      Predominantly used for theorem proving rather than general programming. \\ 
    \hline
    Haskell & Functional & Widely used as a general purpose programming language, however not natively dependently typed. \\ 
    \hline
    Idris & Purely Functional & More general purpose compared to Agda however 
      still lacks mainstream recognition. \\
    \hline
    \textit{ATS} \cite{ATS} & Functional & Developed by Xi who created Xanadu, 
      support dependent typing however only for static terms. \\
    \hline
    \textit{F*} \cite{FStar} & Functional & Jointly developed by Microsoft 
    Research and Inria aimed at program verification. Lacks mainstream 
    programming recognition.\\
    \hline
  \end{tabular}
  \caption{Summary of Dependently Typed Language}
\end{table}

\par
The table above shows a number of languages that supports dependent typing, we 
observed that majority of the languages in this category are using the 
functional paradigm. As functional languages pale in comparison to imperative 
languages in terms of populatiry, the general awareness for dependent types 
remains low. 

\par
Our aim for this project is to i) Explore how dependent types should behave in 
an imperative language and how a language can use different mechanism to enable 
this behaviour. ii) Encourage the research into dependent types by extending the 
WHILE language \cite{whileLanguage} to support dependent typing. We chose this 
language because of its simple and familair syntax which at its core resembles 
popular languages such as C. 

\chapter{The Simple-$R$ Language}
We propose Simple-$R$, a basic procedural language with support for refinement 
types. In this chapter we will describe the mechanics of the language in details.

\section{Language Syntax}
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{l l l}
      \textit{Types} & $T$ & $:\text{ }int\text{ }|\text{ }bool\text{ }|
      \text{ }\{x: T\text{ }|\text{ }e\}\text{ }|\text{ }void$\\
      \textit{Functions Type} &  & $:\text{ }T_1, T_2,T_3...T_n\longrightarrow T_0$\\
      \textit{Functions Definition} & $f$ & $:$ $(x_0,x_1,...x_n) \longrightarrow C;e$\\
      \textit{Operators} & $ops$ & $:$ $+$ $|$ $-$ $|$ $\wedge$ $|$ $\vee$ $|$ $<$ $|$ $>$ \\
      \textit{Expressions} & $e$ & $:$ $vals$ $|$ $\textbf{void}$ $|$ $x$ $|$ $e_1$ $ops$ $e_2$ 
      $|$ $f(e_1...e_n)$ \\
      \textit{Commands} & $C$ & $:$ $C_1;C_2$ $|$ \textbf{skip} $|$ $x\text{ }:= e_1$ 
      $|$ \textbf{while} $e_1$ \textbf{do} $C_1$ $|$ \\ 
        & & \; \textbf{if} $e_1$ \textbf{then} $C_1$ \textbf{else} $C_2$ $|$ 
        $\textbf{begin } D;C_1\textbf{ end}$ \\
      \textit{Declarations} & $D$ & $:$ $\textbf{var } x : T = e$ \\
      \textit{Variables} & $vars$& $:$ $x \in {a,b,c...z}$\\
      \textit{Values} & $vals$& $:$ $\forall v \in \mathbb{Z}$ $|$ $\forall v \in \mathbb{B}$\\
      \textit{Variable Types Context} & $\Gamma$& $:$ $vars \mapsto T$\\
      \textit{Variable Values Context} & $\sigma$& $:$ $vars \mapsto vals$
    \end{tabular}
  \end{center}
  \caption{Language Syntax for Simple-$R$}
\end{figure}

\par
Figure 3.1 shown above is the syntax of Simple-$R$, the paragraphs below 
explains the language in details. In constrast to other literatures in this area, 
Simple-$R$ is a \textit{First Order Programming Language} \cite{FOL} modelled 
after the WHILE \cite{whileLanguage} programming language but with functions.
Rather than building it on the $\lambda$-calculus as one would in 
a Higher Order Language, we opted for a ``C-like'' syntax, with concepts such as 
expressions, commands and top-level functions.

\par
In order to achieve simplicity and observe the core behaviour of dependent 
types, the language is kept at a minimum with only the necessary construct. 

\paragraph{Types} The Simple-$R$ language has support the following four data types. 
\begin{itemize}
  \item The basic integer type \textit{int}
  \item The basic boolean type \textit{bool}
  \item The refinement type, written as $\{x: A\text{ }|\text{ }P(x)\}$. This defines 
  a type that is a refinement of type $A$ that satisfies a boolean expression $P(x)$.
  \item The \textit{void} type to represent empty or null. Commands are modelled 
  as having the $void$ type.
\end{itemize}

\paragraph{Functions}
Functions Type are defined in Simple-$R$ as $(T_1, T_2,T_3...T_n \longrightarrow T_0)$, 
it takes a up to $n$ types and returning a type. Note that functions are 
not first-class in this language, unlike a higher order 
language, functions types are its own entity and are distinct from the regular 
types. This distinction ensures that functions cannot be passed to 
other functions, nor can it return a function as a result. One can compare 
functions in Simple-$R$ to functions in C or Java. The function body is a 
command however it must end in an expression as the return value. Note that the 
return keyword is ommited. Functions return can be difficult to represent, to achieve 
a simply model for functions, we came to the decision to disallow return in the 
middle of the function, values can only be returned at the very end of the 
function.

\paragraph{Operators}
The language supports the following built in operators.
\begin{itemize}
  \item Integer addition using the $+$ operator writte in an infix notation.
  \item Integer subtraction using the $-$ operator written in an infix notation.
  \item Integer inequality $<$ as the less than operator.
  \item Integer inequality $>$ as the greater than operator.
  \item Logical conjunction using the $\wedge$ operator written in an infix 
  notation.
  \item Logical disjunction using the $\vee$ operator written in an infix 
  notation.
\end{itemize}

\paragraph{Expressions} The following expressions make up the language.
\begin{itemize}
  \item Variables and values represents the most basic form of an expression.
  \item The four operators which operates on two other expressions $e_1$ 
  and $e_2$ and return an expression.
  \item The function call $f(e_1..e_n)$ invokes function $f$ with arguments 
  $e_1..e_n$ and return the result. Functions are classified as expression as 
  one can utilise the computed result in other expressions. 
  \item $\textbf{void}$ is used as the return value for a function that returns 
  a $void$ type.
\end{itemize}

\paragraph{Commands} Commands are statements that can be executed to perform an 
actions. Simple-$R$ supports the following commands,
\begin{itemize}
  \item The assignment statement $(:=)$ assigns an expression $e_1$ to variable 
  $x$, note $x$ must have already been declared. 
  \item The \textbf{if then} and \textbf{while do} statements are the standard 
  control flow operations one would expect.
  \item The \textbf{skip} statement is use to indicate an empty expression and 
  does not perform any meaningful action. 
  \item The \textbf{begin ... end} command allows one to open a new scope. A 
  begin statement is followed by a variable declaration $D$, the declared 
  variable would then me accessible in the scope of command $C_1$. Upon reaching 
  \textbf{end}, the variable is out of scope and deallocated. 
\end{itemize}

\paragraph{Declaration} Declarations are the method one use declare new construct 
in the program. We start the language off having the most basic variable declaration 
$\textbf{var }x : T = e$ which declare a new variable $x$ of type $T$ and 
initialise it the resulting value of expression $e$.

\paragraph{Variables and Values} In Simple-$R$, all variables are allocated 
locally, we use $x$ to denote a variable. Variables can take values as suggested by the types, all the integer 
literals $\mathbb{Z}$, booleans $\mathbb{B}$ and $nil$ which is $void$ type. 

\paragraph{Variable Values Context} Variables are mapped to values in the program 
context $\sigma$. Each variable is allowed to only appear once in 
the context. We use \textbf{dom}($\sigma$) to retrive the domain which represent 
the set of declared variables. We use the notation $\sigma(x)$ 
to retrieve the value bound to variable $x$.

\paragraph{Variable Types Context} Variables are also mapped to their types 
in the type context $\Gamma$. Each variable is allowed to only appear once in 
the context. This context will be used to type check the program using the 
typing judgement in the next section.

\section{Typing Rules}
This section defines the typing rules for the Simple-$R$ language.

\par
We begin by defining the typing judgements. The typing judgements used in 
Simple-$R$ takes the form of the standard notation. 
\begin{center}
  $\Gamma \vdash e : T$\\
  $\Gamma \vdash_{C} C : void$\\
  $\Gamma \vdash_{D} D \dashv \Gamma'$\\
\end{center}
This first and second judgement represents that expression $e$ 
under the context $\Gamma$ has the type $T$. The third states that a declaration 
produces the output context $\Gamma'$.

\par
Using the judgement rule we can easily define the fist few typing rules for base 
values \textit{int}, \textit{bool}, $nil$ and variables.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\forall n \in \mathbb{Z}$, $\Gamma \vdash n : int$ & 
      $\forall b \in \mathbb{B}$, $\Gamma \vdash b : bool$ & 
      $\Gamma \vdash_{C} \textbf{skip} : void$ & 
      $x : T, \Gamma \vdash x : T$  & 
      $\Gamma \vdash \textbf{void} : void$
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Base Values}
\end{figure}

\par
The remaining typing rules for the operators, statements and function  
calls are presented below. First we define the 
basic rules in figure 3.3, 
most of the typing rule are straightforward and what one would expect from the 
type checker. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int}
        {\Gamma \vdash e_1 + e_2 : int}[(\textbf{op} $+$)] \text{ }
      \inference {\Gamma \vdash e_1: int & \Gamma \vdash e_2: int} 
        {\Gamma \vdash e_1 - e_2 : int}[(\textbf{op} $-$)] & \\
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool}
        {\Gamma \vdash e_1 \wedge e_2 : bool}[(\textbf{op} $\wedge$)] \text{ }
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash e_2: bool} 
        {\Gamma \vdash e_1 \vee e_2 : bool}[(\textbf{op} $\vee$)] & \\
      \inference {\Gamma \vdash e_1: bool \\ \Gamma \vdash C_1: void & \Gamma \vdash C_2: void}
        {\Gamma \vdash_{C} \text{\textbf{if }} e_1 \text{\textbf{ then }} 
        C_1 \text{\textbf{ else }} C_2: void}[(\textbf{if else})]
      \inference {\Gamma \vdash e_1: bool & \Gamma \vdash C_1: void}
        {\Gamma \vdash_{C} \text{\textbf{while }} e_1 \text{\textbf{ do }} C_1 : void} [(\textbf{while do})] & \\
      \inference {\Gamma \vdash x: T & \Gamma \vdash e_1: T} 
        {\Gamma \vdash_{C} x := e_1 : void} [($:=$)] \text{ }
      \inference {\Gamma \vdash C_1: void & \Gamma \vdash C_2: void} 
        {\Gamma \vdash_{C} C_1;C_2 : T_2} [(concatenation $;$ $C$)] \text{ }
      & \\
      \inference {\Gamma \vdash e_1: T_1} 
        {\Gamma \vdash_{D} \textbf{var } x : T_1 = e_1 \dashv \Gamma'} [($vars$ Declaration)]
      & \\
      \inference {\Gamma \vdash D_1 \dashv \Gamma' & \Gamma' \vdash_{C} C_1 : void} 
        {\Gamma \vdash_{C} \textbf{begin }D_1;C_1\textbf{ end}} [(Begin scope)]     
    \end{tabular}
  \end{center}
\caption{Basic Typing Rules for Simple-$\Pi$}
\end{figure}

\subsubsection{Functions}
For a function call, we use the type judgement above. We use  
first order logic to write $f(e_1...e_n)$ as an n-nary function of 
type $T_1$ to $T_n$, then the arguments $e_1$ to $e_n$ must be of same type. 
Evaluation of the function will then satisfy the return type $T_0$.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {f : T_1,T_2...T_n \longrightarrow T_0 \\ 
      \Gamma \vdash e_1 : T_1 & \Gamma \vdash e_2 : T_2 &...& \Gamma \vdash e_n : T_n}
        {\Gamma \vdash f(e_1...e_n): T_0}[(\textit{functions})]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Functions in Simple-$R$}
\end{figure}

\subsubsection{Refinement Types}
Finally we define typing rules for a refinement types. A refinement type 
is represented in our system as $\{\upsilon : T\text{ }|\text{ }e\}$ and is 
constructed by a base type $T$ and a refinement predicate $e$ which may contain 
the free variable $\upsilon$ and any free variables in the program. A refinement 
type represent all values of $T$ where the expression $e[u/\upsilon]$ holds. 

\par
We define the typing rule for refinement types using the idea of 
\textit{universes} \cite{martinLof} in type theory, using the 4th judgement form 
$\Gamma \vdash A : Type$ to represent that $A$ is a type. 

\par
We begin by defining the formation rule for a refinement type. 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash \upsilon : T & \Gamma \vdash e : bool}
        {\Gamma \vdash \{\upsilon : T\text{ }|\text{ }e\}: Type}[(Refinment Type formation)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Refinement Types in Simple-$R$}
\end{figure}


Additionally, we defining the typing rule for a subtypes. A refinement type 
$A$ is a subtype of another refinement type $B$ if 
the set of values in $A$ is a subset of or equal the values in $B$, 
we express $A$ is a subtype of $B$ as $A \preceq B$. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash \forall \upsilon_1 : T\text{ }s.t.\text{ }e_1 \Rightarrow e_2[\upsilon_1/\upsilon_2]}
      {\Gamma \vdash \{\upsilon_1 : T_1\text{ }|\text{ }e_1\} \preceq \{\upsilon_2 : T_1\text{ }|\text{ }e_2\}} [(Subtype Base)]
      & \\ 
      \inference {\Gamma \vdash T_1 \preceq T_2 & \Gamma \vdash T_1 \preceq T_3} 
      {\Gamma \vdash T_1 \preceq T_2} [(Subtype Trans)]
      & \\
      $\Gamma \vdash T_1 \preceq T_1$ (Subtype Reflex)
    \end{tabular}
  \end{center}
\end{figure}

\par
The three subtype judgement defined above allows us to perform perform basic 
polymorphism. One should be able to use a value of type $T_1$ in a context 
expecting type $T_2$ provided $T_1$ is a subtype of $T_2$. We enable this 
behaviour using the judgement below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
       \inference {\Gamma \vdash T_1 \preceq T_2 & \Gamma \vdash e : T_1} 
      {\Gamma \vdash e : T_2} [(Subtype)]
    \end{tabular}
  \end{center}
\end{figure}

\par
In this section we covered the typing rules for Simple-$R$, typing rules are a 
way of allowing us to statically check the correctness of our program with 
regards to typing rules. Refinement types are hard to verify statically because 
of the dynamic behaviour when evaluating the refinement predicate. In the next 
section we will analyse the dynamic behaviour of the language. 

\section{Operational Semantics}
In this section we will define the \textit{Operational Semantics} 
\cite{operationalSemantics} for the Simple-$R$ language 
using the \textit{Structural Operational Semantics} \cite{plotkinSOS} (SOS) rules.

\par
Throughout the text we will be extending the syntax defined in the 
previous chapter in order to accomodate more features. 
We will use the following metavariables and notations throughout our 
definitions.

\renewcommand\labelitemii{$\blacksquare$}
\begin{itemize}
  \item The metavarible $op$ as one of a range of operators. 
  \item The metavariable $v$ to range over all values.
  \item The uppercase letters $A,B,C,T$ to range over all types.
  \item Greek letters ($\alpha$, $\pi$, $\upsilon$) to define local variables in 
  the formuli. 
  \item The following notations to operate on states. 
    \begin{itemize}
      \item $\sigma + \{x \mapsto v\}$ adds $\{x \mapsto v\}$ to $\sigma$ provided initially $x \notin\textbf{dom}(\sigma)$. 
      \item $\sigma[x \mapsto v]$ or $\sigma \uplus \{x \mapsto v\}$ updates $\sigma$ such that now $\sigma(x) = v$.
      \item $\sigma \setminus \{x\}$ to remove $x$ from $sigma$, provided that $x \in \textbf{dom}(\sigma)$.
    \end{itemize}
  \item $\langle e, \sigma \rangle \Longrightarrow \langle e', \sigma \rangle$ as the transition relation for expression.
  \item $\langle C, \sigma \rangle \longrightarrow \langle C', \sigma' \rangle$ and $\langle C, \sigma \rangle \longrightarrow \sigma'$ as the transition relation for commands.
\end{itemize}

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {v = v_1 + v_2}{\langle v_1 + v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $+$)] \text{ }
      \inference {v = v_1 - v_2}{\langle v_1 - v_2, \sigma \rangle \Longrightarrow  \langle v, \sigma \rangle}[(op $-$)]
      & \\
      \inference {v = v_1 \wedge v_2}{\langle v_1 \wedge v_2, \sigma \rangle \Longrightarrow \langle v, \sigma \rangle}[(op $\wedge$)] \text{ }
      \inference {v = v_1 \vee v_2}{\langle v_1 \vee v_2, \sigma \rangle \Longrightarrow \langle v, \sigma \rangle}[(op $\vee$)]
      & \\
      \inference {\langle e_1, \sigma\rangle \Longrightarrow \langle e_1', \sigma \rangle}
        {\langle e_1\text{ }op\text{ }e_2, \sigma  
        \rangle \Longrightarrow \langle e_1'\text{ }op\text{ }e_2, \sigma \rangle}[($op$ $expr$)]
      \text{ }
      \inference {\langle e_2, \sigma\rangle \Longrightarrow \langle e_2', \sigma \rangle}
        {\langle v\text{ }op\text{ }e_2, \sigma  
        \rangle \Longrightarrow \langle v\text{ }op\text{ }e_2', \sigma \rangle}[($op$ $expr$ 2)]
      & \\
      $\langle v, \sigma \rangle \Longrightarrow \sigma$ ($vals$) evaluation
      \text{ }
      \inference {x \in \textbf{dom}(\sigma)}{\langle x, \sigma \rangle \Longrightarrow \langle \sigma(x), \sigma \rangle}[($vars$) evaluation] 
    \end{tabular}
  \end{center}
  \caption{Basic Evaluation Rules for Simple-$R$ Expression}
  \label{fig:sos_expr}
\end{figure}

\par
Figure \ref{fig:sos_expr} defines the reduction rules for expression, importantly, expressions 
are not able to modify the state of the program. If one defines a singular value 
it performs no meaningful action. We next define the evaluation rules for 
commands. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\langle \text{\textbf{skip}}, \sigma \rangle \longrightarrow \sigma$ (\textbf{skip})
      \text{ }
      \inference {\langle C_1, \sigma \rangle \longrightarrow\sigma'}
        {\langle C_1;C_2, \sigma \rangle \longrightarrow \langle C_2, \sigma' \rangle}[($C_1;C_2$)]
      & \\
      $\langle \text{\textbf{if }\textit{true}} \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle C_1, \sigma\rangle$ (\textbf{if} true)
      & \\
      $\langle \text{\textbf{if }\textit{false}} \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle C_2, \sigma\rangle$ (\textbf{if} false)
      & \\
      \inference {\langle e_1, \sigma \rangle\Longrightarrow\langle e_1', \sigma \rangle}
        {\langle \text{\textbf{if }} e_1 \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle \longrightarrow \langle \textbf{if } e_1' \text{\textbf{ then }} C_1 \text{\textbf{ else }} 
        C_2, \sigma \rangle}[(\textbf{if} $expr$)] 
      & \\
      $\langle \text{\textbf{while }} e_1 \text{\textbf{ do }} C_1, \sigma \rangle \longrightarrow \langle 
        \text{\textbf{if }} e_1 \text{\textbf{ then }} C_1;
        (\text{\textbf{while }} e_1 \text{\textbf{ do }} C_1) \text{\textbf{ else }} \textbf{skip}, \sigma \rangle$ (\textbf{while do})      
      & \\
      \inference {x \in \textbf{dom}(\sigma)} 
      {\langle x := v, \sigma \rangle \longrightarrow \sigma[x \mapsto v]} [(assign 1)] \text{ }
      \inference {\langle e, \sigma \rangle \Longrightarrow \langle e', \sigma \rangle} 
      {\langle x := e, \sigma \rangle \longrightarrow \langle x := e', \sigma \rangle} [(assign 2)]
     \end{tabular}
  \end{center}
  \caption{Operational Semantics for Simple-$R$ Commands}
  \label{fig:sos_commands}
\end{figure}

\par
Figure \ref{fig:sos_commands} defines the operational semantics for the basic commands 
in the language. The semantics for $\textbf{begin }D;C \textbf{end}$ will be 
covered in the next section.

\subsection{Scoping}
Scoping has an important role in programming languages, variables can be defined 
in scopes and are unavailable once outside. While there are many different 
variables that does not follow this rule, such as static variables and global 
variables. For simplicity, we will focus initially on local variables. 

\par
In order to help us formalise the notion of scopes we define a new notation, 
$\Longrightarrow^{*}$ and $\longrightarrow^{*}$ as a multi-step evaluation. 
The evaluation rule $\langle e, \sigma \rangle \Longrightarrow^{*} 
\langle v, \sigma' \rangle$ simply 
evaluate the expression $e$ one or more times until it evaluates to a value $v$. 
The same applies for a multistep evaluation for commands, 
$\langle C, \sigma \rangle \longrightarrow^{*} \sigma'$ execute the command $C$ 
until there is no evaluation rules to apply. 

\par
Using a multi step evaluation, We can easily define the scoping rules as shown 
in \ref{fig:scoping_rules}.
  
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \textbf{dom}(\sigma) 
      & \langle C_1, \sigma' \rangle \longrightarrow^{*} \sigma''} 
      {\langle\textbf{begin var }x : T = v_0; C_1 \textbf{ end}, \sigma \rangle 
      \longrightarrow \sigma'' \setminus \{x\}} [(\textbf{begin end} values)] 
      & \\
      \footnotesize
      \inference {\langle e_1, \sigma \rangle \Longrightarrow \langle e_1', \sigma \rangle} 
      {\langle \textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma \rangle 
      \Longrightarrow \langle\textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma \rangle} 
      [(\textbf{begin end} $expr$)]
      \normalsize
    \end{tabular}
  \end{center}
  \caption{Scoping Rules for Simple-$R$}
  \label{fig:scoping_rules}
\end{figure}

\par
The \textbf{begin in} statement opens a new scope $\sigma'$ which 
assigns $x$ the value $v$, this scope allows the command $C_1$ to be evaluated 
using a multi step evaluation. Notice that the resulting state 
uses the $\setminus$ operator which removes all the variables 
in the set $\{x\}$ from the domain of $\sigma$. 

\par
This is necessary as it is possible to modify the range of $\sigma$ through 
assignments but not the domain. Upon exiting a scope the alteration to the program 
should still be visible, the only difference is that the variable $x$ is no longer in 
the state, i.e. has ran out of scope.

\par
The multi-step evaluation provides us to easily express scoping rules, 
the alternative would be to model an explicit call stack, which complicates the 
formulas and syntax.

\subsection{Functions}
Functions in almost all imperative language operates in their own scope. In many 
cases they do not have the access to the local variables out of their scope however 
one can pass data using arguments. Functions in Simple-$R$ are call by values, 
changing the value of an argument in the function does not change the value in 
the outside scope. Our multi-step evaluation rule defined previously helps us 
evaluate functions in their own scope. 

\par
In order to define the operational semantics of a function we will need to 
specify the function body. We define a mapping 
\textit{fns} $: f \mapsto ((x_1, x_2...x_n), C_1;e)$, 
using this mapping allows us to retrieve the body of a function. Since functions 
definition cannot be changed at runtime, this does not need to be part of the 
configuration and can be consider as a static context.

\par
We can then evalute the function body which using the multi-step evaluation.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\textit{fns}(f) = ((x_1..x_n), C_1;e_1) & \langle C_1, \sigma' 
      \rangle \longrightarrow^{*} \sigma''
        \\ \sigma' = \{x_1 \mapsto v_1 ... x_n \mapsto v_n\} & \langle e_1, \sigma'' \rangle \Longrightarrow^{*} \langle v, \sigma'' \rangle}
      {\langle f(v_1...v_n), \sigma \rangle \Longrightarrow \langle v, \sigma \rangle} [(function call vals)]
      & \\
      \inference {\langle e_k, \sigma \rangle \Longrightarrow \langle e_k', \sigma' \rangle}
      {\langle f(v_0...v_{k - 1},e_k...e_n), \sigma \rangle \Longrightarrow \langle f(v_0...v_{k - 1}, e_{k}'...e_n), \sigma \rangle} [(function call expr)]
    \end{tabular}
  \end{center}
  \caption{Functions Semantics for Simple-$R$}
\end{figure}

\par
The first rule (function call vals) resembles the evaluation rule for 
variable declaration but it differs in a crucial way, in the new context for a 
function call, none of the variables from the previous scope transfer over, only 
the argument values are copied. We then evaluates the function body until it 
evaluates to a value which is then returned to the caller's context. Unlike 
scopes, functions only update its local state which is dellalocated upon return. 
It cannot change the caller's state. 

\par
The second rule (function call $expr$) evaluates the expression passed into the 
function as arguments. Our language defines a strict behaviour that all 
arguments are evaluated in the order they are passed in, i.e. from left to right 
and arguments are call-by-value.

\subsection{Refinement Type Checking}
Refinement Type declaration requires specific evaluation rule. When one declare 
a variable of a refinement type, the language has to ensure the evaluation 
holds. While we have defined a statically typed language, even in a statically 
typed language, there are cases when the type of some data cannot be determined 
statically. Gordon Plotkin discussed the idea of dynamically checking a static 
language in this work \cite{dynamicCheckStaticLanguage} which inspired our idea.

\par
The refinement predicate proves to be hard to decide at compile time, one might 
require access to program state for values of variables in order 
to evaluate the refinement predicate. In many cases, 
only constants and constant expressions are available at compile time. 
Alternatively, one can type check refinement type dynamically at runtime. We 
define a special form of typing judgement to do that. Interestingly, 
Cormac Flanagan proposed a similar idea dubbed Hybrid Type Checking to verify 
the correctness of Dependent Types and Refinement Types in a $\lambda$-calculus 
\cite{hybridTypeChecking}.


\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      $\sigma, \Gamma \vdash_{R} e_1 : \{\upsilon : T \text{ }|\text{ }e\}$
    \end{tabular}
  \end{center}
  \caption{Typing Judgement for Refinement Types}
  \label{fig:refine_judgement}
\end{figure}

\par
Figure \ref{fig:refine_judgement} shows a typing judgement for refinement 
types which has the ability to access the runtime state $\sigma$. We can then 
perform a type check on refinement type using the rule defined below. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference{\Gamma \vdash e_1 : T_1 & \langle e[e_1/\upsilon], \sigma \rangle \Longrightarrow^{*} \langle \textit{true}, \sigma \rangle}
      {\sigma, \Gamma \vdash_{R} e_1 : \{\upsilon : T_1\text{ }|\text{ }e\}} 
    \end{tabular}
  \end{center}
  \caption{Type Checking Refinement Types}
  \label{fig:refine_typecheck}
\end{figure}

\par
The typing judgement in figure \ref{fig:refine_typecheck} asserts that an expression 
$e_1$ is a valid refinement type if it evaluates to the base type $T_1$ and 
the refinement predicate $e[e_1/\upsilon]$ evaluates to true under state 
$\sigma$.

\par
Our type check rule looks to capture the behaviour of refinement type however it 
turns out the current definition is underspecified. In the next section we 
will put forward certain ambiguities with the design and discuss different choices 
one can make to address them.

\section{Refinement Types and Variables}
Programming languages often have a wide range of features, often the team behind 
the language have to put extensive thought into the design decisions. As there 
are often multiple way to handle a certain feature, rarely is there a definite 
answer to which is the most optimal.

\par
This seemingly undecideable problem is known as \textit{feature interactions} 
\cite{featInteract}, it describes the problem in some situations multiple 
features would modify the behaviours of each others. The same applies to 
refinement types, which can be seen as a feature. For instance, the inclusion 
of refinement types would modify the behaviour of assignments and vice versa. 
This section will cover the different ways of handling refinement types and how 
they interact with other features.

\subsection{The Ambiguity of Refinement Types with Mutation}
Consider these few ambiguity of using variables to define dependent types. For 
instance: 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{begin var }$y\text{ }:\text{ } int = 10;$ \\
    \tab\textbf{begin typedef }$BoundedIntY$ = $\{i : Int\text{ }|\text{ } i < y\}$; \\ 
    \tab\tab\textbf{begin var }$x\text{ }:\text{ }BoundedIntY = 4;y := 5$\textbf { end} \\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Mutation to Free Variables in Refinement Predicate}
  \label{fig:amb_refinement_vars}
\end{figure}

\par
The simple program demonstrated in \ref{fig:amb_refinement_vars} declares a 
bounded integer type $BoundedIntY$ whose value cannot be greater than another integer $y$, 
a free variable in the program. A variable $x$ is declared to be of type 
$BoundedIntY$ with the appropriate value. Later in the program, the value of $y$ 
changes. resulting to $x$ now being ill-typed. The behaviour is now undefined, 
should $x$ still be well-typed, or is the behaviour invalid? This section will 
discuss this problem in detail. 

\par
First we need to introduce a new declaration statement for type declaration, 
in the example above we used the statement (\textbf{typedef} $x = T$) to denote a 
new type $T$ with the name $x$, this declaration statement resembles variable 
declaration and has the following typing judgement. 

\begin{center}
  \begin{tabular} {c}
    \inference{\Gamma \vdash T : Type} {\Gamma \vdash_{D} \textbf{typedef } x = T \dashv \Gamma'}  
  \end{tabular}
\end{center}
  
\par
We need to add this construct into our syntax. In our current syntax, 
we have a context mapping $vars$ to $vals$, We now need to add a similar mapping \
for types, We use $\tau$ to represent the type name map. 

\par
The syntax is extended by adding the following: 
\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Declaration} & $D$ & $:$ ... $|$ \textbf{typedef }$x = T$\\
      \textit{Type Name Context} & $\tau$& $:$ $vars \mapsto T$ \\
    \end{tabular}
  \end{center}
  \caption{Type Name Context Extension for Simple-$R$}
\end{figure}

\par
In our operational semantics, our signature is updated from $\langle C, \sigma \rangle$ 
to $\langle C, \sigma, \tau \rangle$ in order to incorporate this new feature. 
All previous operational semantics should be updated consistently.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference { 
      \langle C_1, \sigma, \tau' \rangle \longrightarrow \langle \sigma', \tau' \rangle\\
      x \notin \text{\textbf{dom}}(\sigma) & x \notin \textbf{dom}(\tau) & \tau' = \tau + \{x \mapsto T\}}
      {\langle \textbf{begin typedef }x = T;C_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau \rangle}[(\textbf{typedef})] \text{ }    
    \end{tabular}
  \end{center}
\end{figure}

\par
Note that unlike the rule for variable declaration, we did not have to remove 
the type name $x$ from the context after evaluation. This is because unlike 
variables, types cannot change after declaration. The new type simply goes 
out of scope, hence the new type context will simply be our initial one. 

\par
The operational semantic above simply adds a new type definition with name $x$ 
into the Type Name context $\tau$. Importantly, the variable $x$ cannot have 
already been defined as a value variable in $\sigma$ and a type of the same name 
can not already be defined. Logically it is equivalent to the semantics for 
variable declaration.

\par
We complete our evaluation to specify how a variable is declared using a type 
name. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {y \in \textbf{dom}(\tau) & T = \tau(y)} 
      {\langle\textbf{begin var }x : y = e_1;C_1\textbf{ end}, \sigma, \tau \rangle 
      \longrightarrow \langle\textbf{begin var }x : T = e_1;C_1\textbf{ end}, \sigma, \tau \rangle }
    \end{tabular}
  \end{center}
\end{figure}

\subsection{Immutability}
The main issue one encounters when associating refinement types with imperative 
languages is the presence of mutability and assignments. The obvious way to 
work around this problem is to remove the ability to make changes to the state 
of the program, all variables declared are final.

\par
Using this approach does definitely resolves the uncertainty the usability of 
the language is poor. Imperative programming relies on state changes, forbidding 
that go against the paradigm. However, if we strategically enforce immutability 
we can resolve the ambiguity while preserving a flexible imperative style 
language. In the next few sections we will discuss two approaches that 
improve the specification of our type checker through restricting changes to 
variables. 

\subsection{Immutability For Refinement Variables}
In order to avoid feature interaction between refinement types and assignments, we 
observe that it is suffice to require free varibles appearing in a refinement 
predicate to be immutable. This approach improves flexibility of our language as 
one will still be able to have mutability in context irrelevant to refinement 
types. 

\par
In order to capture the notation of immutable types, the set of variables $vars$ 
is partitioned into two different distinct catogories. Mutable and immutable, we 
define a predicate $is\_immutable$ that specify if a given variable is immutable. 
$is\_immutable(x)$ holds if and only if $x$ is immutable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Declaration} & $D$ & $:$ $...\text{ }|\text{ }\textbf{const }x : T = e_1$
    \end{tabular}
  \end{center}
  \caption{Immutable Variable Context for Simple-$R$}
\end{figure}
 
One can declare an immutable variable similar to defining a mutable 
variable, using the \textbf{const} $x : T = e$ statement. We establish the following 
rules for immutable variables. 

\par
The typing judgement which appears identical to that of variable declaration. 

\begin{center}
  \begin{tabular} {c}
    \inference {\Gamma \vdash e_1: T_1} 
        {\Gamma \vdash_{D} \textbf{const } x : T_1 = e_1 \dashv \Gamma'} [($vars$ Declaration)]
  \end{tabular}
\end{center}

\par
The operational semantics describing the process of creating a immutable 
variable is similar to the one for regular mutable variables. The only oddity 
here is extending the assignment statement to only accept the latter. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      \langle C_1, \sigma', \tau \rangle \longrightarrow^{*} \langle \sigma'', \tau' \rangle 
      \\ \sigma' = \sigma + \{x \mapsto v\} & x \notin \textbf{dom}(\sigma)} 
      {\langle \textbf{begin const }x : T = v;C_1\textbf{ end}, \sigma, \tau \rangle 
      \longrightarrow \langle \sigma'' \setminus \{x\}, \tau' \rangle} [(\textbf{let in} values)] 
      & \\
      \footnotesize
      \inference {\langle e_1, \sigma, \tau \rangle \Longrightarrow \langle e_1', \sigma, \tau \rangle} 
      {\langle \textbf{begin const }x : T = e_1;C_1\textbf{ end}, \sigma,\tau \rangle 
      \longrightarrow \langle \textbf{begin const }x : T = e_1';C_1\textbf{ end}, \sigma, \tau \rangle}
      [(\textbf{const in} $expr$)]
      \normalsize
      & \\
      \inference {x \in \textbf{dom}(\sigma) & \neg is\_immutable(x)} 
      {\langle x := v, \sigma, \tau \rangle \longrightarrow \langle \sigma[x \mapsto v], \tau \rangle} [(assignment $vals$)]
    \end{tabular}
  \end{center}
  \caption{Immutable Variables Rules for Simple-$R$}
\end{figure}

\par
Once we define the ability to define immutable variables, we can utilise it in 
our type definition. First we refine our specification for \textbf{typedef} 
with regards to refinement types using the evaluation rules.

\par
We require a new notation to capture all the variables that appear in an 
expression $e$, we use the notation \textit{free\_vars}$(e)$ to give the set of all 
variables that appear in an expression $e$.

\par
Notice that in our syntax the refinement predicate is simply a boolean 
expression, this means that it is not possible for the refinement predicate to 
declare any new variables within it. So it is easy to see that for a refinement 
predicate $e$, $\textit{free\_vars}(e) \subseteq \textbf{dom}(\sigma)$, note that 
$\upsilon$ is not a free variable. 

\par
Using the new notation we can easily verify that all free variables in a 
refinement predicate is immutable using the evaluation defined below.
\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      a \notin \text{\textbf{dom}}(\sigma) & a \notin \textbf{dom}(\tau) \\
      \forall \alpha \in \textit{free\_vars}(e)\text{ }s.t.\text{ }is\_immutable(\alpha)
      \\ \langle C_1, \sigma, \tau + \{a \mapsto \{\upsilon :A\text{ }|\text{ }e\} 
      \rangle \longrightarrow \langle \sigma', \tau \rangle}
      {\langle \textbf{begin typedef } a = \{\upsilon :A\text{ }|\text{ }e\};C_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle \sigma', \tau \rangle}[(Refine def)]
    \end{tabular}
  \end{center}
\end{figure}

\par
We address the ambiguity brought up using this semantic. The program in figure 
\ref{fig:amb_refinement_vars} is no longer a valid program as 
$y$ is a mutable variable and is forbidden from appearing in a refinement type. 
One would have to rewrite the declaratio of $y$ using \textbf{const} which 
forbids it from being assigned to after initialisation. 
It is easy to see by restricting free variables in the refinement predicate we ensure 
that the expression stays the same throughout its existence, avoiding any 
complications regarding mutation.

\par
The approach laid out here is a simple approach to dealing with the ambiguity of 
having mutability and refinement types. Interestingly, C++ utilises the same 
strategy for templates values, where a value passed into a template must be a 
constant expression. 

\par
We could potentially adapt a clever approach used by the Java programming 
language to overcome variable mutation in Anonymous classes. Java requires that 
any variables accessed by an anonymous class that is part of 
its enclosing scope to be final or \textit{effectively final} 
\cite{effectFinal}. An effectively final variable is a variable that is not 
declared immutable but its value is not changed after declaration. While this 
does improves some flexibity as one do not need to use the \textbf{const} 
statement for declaration, it behave the same for all intents and purposes. 
For this reason we consider this additional feature as future consideration and 
out of scope for this current project. 

\par
One significant strong point in requiring constants in the refinement predicate 
is that one can easily have compile time checking. In programming languages 
the value of immutable variables are often available at compile time, this 
allows one to have a compiler with capabilities of evaluating the refinement 
predicate and type check a refinement type at compile time rather than at run 
time. 

\par
The limitation of this approach is of course the fact that one has to strategically 
declare the variables needed, in some cases one might not be able to declare 
immutable variable but still want the ability to define a refinement type.

\subsection{Refinement Predicate Closure}
If we further analyse our design, we notice that our main concern is for the 
refinement predicate to stay static, any changes in the program context should 
not change its definition. In this section, we propose a design which allows us 
to keep variables in a refinement predicate constant without the need of 
defining the variables immutable.

\par
First we recap two ideas commonly found in programming language, \textit{Closures} 
\cite{closures} and \textit{Pass By Value} \cite{pbv}.
In languages such as JavaScript, Python and Ruby, a closure is simply a  
function enclosed with an environment. Closures have access to 
variables from the calling context, even if the original variable goes out of 
scope. Semantically, a closures can be modelled as a data structure mapping 
functions to environment as demonstrated in the extended lambda calulus proposed by 
Gerald J. Sussman and Guy L. Steele Jr in this paper \cite{closureLambdaOp}. 

\par
In C/C++, \textit{pass by value} \cite{pbv} is a way of passing a 
parameter into a function in a way that any modification to the 
parameter in the function does not reflect changes outside and vice versa. In 
order to make free variables in a predicate independent, we designed a similar 
approach where we bind free variables with a value. 

\par
Taking the example program in figure \ref{fig:amb_refinement_vars} if the 
variable $y$ in the refinement predicate is different from the variable 
$y$ in the program state, then any changes to the variable $y$ will not 
affect the type definition and the program 
will stay well typed.

\par
Our appraoch is to have the predicate to evaluate in a different environment, we 
denote that every refinement predicate has their own evaluation context, this 
will be the program context at the time of the type definition. We define a new 
mapping $\mathcal{R}$.

\begin{center}
  $\mathcal{R}: T \mapsto (\sigma, \tau)$   
\end{center}

The mapping $\mathcal{R}$ is used to associate a refinement type with its 
evaluation context. The said context is simply the $\sigma, \tau$ at the time of 
the refinement type creation.

\par
We formalise this behaviour in the evaluation rules below. Our signature is now 
$\langle C, \sigma, \tau, \mathcal{R} \rangle$, previously defined operational 
semantics should be updated as such. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {
      \langle C_1, \sigma, \tau + \{y \mapsto \{\upsilon : A\text{ }|\text{ }e\}\}, \mathcal{R}'
      \rangle \longrightarrow^{*} \langle \sigma', \tau, \mathcal{R} \rangle      
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}}
      {\langle\textbf{begin typedef } y = \{\upsilon : T\text{ }|\text{ }e\};C_1;e_1\textbf{ end}, 
      \sigma, \tau, \mathcal{R} \rangle \longrightarrow \langle \sigma', \tau, \mathcal{R} \rangle} 
      & \\
      \inference {\sigma' = \sigma + \{x \mapsto v_0\} & x \notin \textbf{dom}(\sigma) 
      & \langle C_1, \sigma', \tau, \mathcal{R} \rangle \longrightarrow^{*} \langle 
      \sigma'', \tau, \mathcal{R} \rangle
      \\ \sigma_1 = \sigma & \tau_1 = \tau & \mathcal{R}' = \mathcal{R} + \{\{\upsilon : T\text{ }|\text{ }e\} \mapsto (\sigma_1, \tau_1)\}} 
      {\langle\textbf{begin var }x : \{\upsilon : T\text{ }|\text{ }e\} = v_0; C_1 \textbf{ end}, \sigma \rangle 
      \longrightarrow \sigma'' \setminus \{x\}}
    \end{tabular}
  \end{center}
  \caption{Evaluation of Refinement Type with Closures}
\end{figure}

\par
We define $\sigma_1$ and $\tau_1$ as a copy of the program state $\sigma$ and 
$\tau$ and attach this to the type using the context $\mathcal{R}$. The same 
applies when one declare a variable of type $\{\upsilon\text{ }|\text{ }e\}$ 
without using the \textbf{typedef} command.

\par
In order to type check refinement types with closures, we update our refinement 
typing judgement with the addition of $\mathcal{R}$

\begin{center}
  \begin{tabular} {c}
    $\mathcal{R},\Gamma \vdash_{R} x : \{\upsilon : T\text{ }|\text{ }e\}$
  \end{tabular}
\end{center}

\par
Our new typing judgement now retrieves the associated context from $\mathcal{R}$ 
and evaluates appropriate, the new rule is defined in figure. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference{\Gamma \vdash e_1 : T_1 
      & (\sigma, \tau) = \mathcal{R}(\{\upsilon : T_1\text{ }|\text{ }e\}) 
      & \langle e[e_1/\upsilon], \sigma, \tau \rangle \Longrightarrow^{*} \langle \textit{true}, \sigma, \tau \rangle}
      {\mathcal{R}, \Gamma \vdash_{R} e_1 : \{\upsilon : T_1\text{ }|\text{ }e\}} 
    \end{tabular}
  \end{center}
  \caption{Type Checking a Refinement Type with $\mathcal{R}$}
\end{figure}


\par
The typing judgement behaves similar to our initial judgement, the only 
exception here is the context being evaluated in. When type checking against a 
refinment type, the evaluation context is retrieved from $\mathcal{R}$, the 
predicate $e[e_1/\upsilon]$ is then evaluated under the context.

\par
It address the ambiguity in figure \ref{fig:amb_refinement_vars} by specifying 
a concrete behaviour. $BoundedIntY$ being bounded to $10$ throughout, even when 
the free variable $y$ is reassigned to another value.
 
\par
Unlike C++, this form of sematics allows one to utilise non-constant expression 
in type definition. This is achieved by fixing a refinement type with an 
environement as one does in closures. 
 
\subsection{Summary}
In this section, we proposed a scenario where our refinement type checker is 
underspecified in the presence of mutation. We proposed two different approaches 
to complete our specification, approach one utilise constants and immutable 
variables to disallow modification of free variables used in a refinement 
predicate. The second utilises closures and value bindings to ensure 
consistency. 

\par
While the proposed solutions are effective in dealing with mutation on local 
variables. As the language starts incorporating more features, our current 
design becomes underspecified yet again. In the next section, we will analyse 
the behaviour of our system in the presence of dynamic memory allocation.

\section{Pointers and Reference Variables}
Previously we proposed a set of rules that specifies behaviour of refinement 
types with regards to local variables and we learn that we can keep behaviour 
consistent if we restrict changes to the variable. However, our solution does 
not accomodate for reference variables and pointers. If a refinement type 
relies on pointers in the refinement predicate then the simple act of declaring 
them immutable is not enought. Pointers value can be altered through aliasing. 

\par
In this section we will first extend our syntax with the notion of dynamically 
allocated memory. Later we will study the feature interaction between 
pointers and refinement types in order to specify a consistent behaviour. 

\subsection{Heap Memory}
In programming languages, there are three different types of memory allocation, 
static, stack and heaps \cite{heapVsStack}. While we have not explicitly 
discussed our memory management model, it is rather obvious that Simple-$R$ 
operates on a stack based model. It is apparent in the behaviour of locals 
variable which are inaccesible once out of scope as discussed in our scoping rules. 

\subsubsection{Syntax Extension}
First we will have to extend our syntax to accomodate these new features, we define 
the new syntax in figure \ref{fig:ptr_syntax}. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}
      \textit{Types} & $T$ & $:$ $...\text{ }|\text{ }T\text{ \textit{ref }}$ \\
      \textit{Expressions} & $e$ & $:$ $...\text{ }|\text{ }!e_1\text{ }|\textbf{ new}(T)|\textbf{ new}(T, v)$\\
     \textit{Values} & $vals$& $:$ $...\text{ }|\text{ }h$ $|$ $nil$ \\
     \textit{Heap} & $\Delta$& $:$ $h \in \{h_1,h_2, h_3...\} \mapsto vals$\\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$R$}
  \label{fig:ptr_syntax}
\end{figure}

\paragraph{Types}
We introduced a new type, $T$ \textit{ref} is a reference type that behaves like 
a pointer in C/C++, like pointers, references are typed and its value is a heap address. 

\paragraph{Expressions}
The following expressions are introduced into the language. Unlike C/C++ 
where one is allowed to retrieve the address of a local variable, in our 
system one may only create a pointer through the use of \textbf{new}.
\begin{itemize}
  \item $!e_1$ to dereference the heap address held by expression $e_1$.
  \item \textbf{new}($T$) to allocate and return a $T$ \textit{ref} 
  without specifying the value which will be assigned $nil$.
  \item \textbf{new}($T, v$) to allocate and return a $T$ \textit{ref} with the 
  value $v$.
\end{itemize}
\par
For simplicity, we have ommited the need for manual memory management, we 
assumme that automatic garbage collection is present in the language. 

\paragraph{Values}
We added two new values to the language, $h$ is simply a heap address and $nil$ 
as an empty reference. $nil$ is treated as a standalone 
value and not a dedicated heap address as it is the case in C/C++.

\paragraph{Heap}
Finally, we define a heap context $\Delta$ as a set of 
heap addresses $\{h_0, h_1, h_2...\}$, it represents the set of address currently in use, 
realisticly $\Delta$ will be a finite mapping however, in our case we are assuming 
$\Delta$ be an infinite set of heap addresses as we consider cases of 
insufficient memory out of scope for our project. We use the notation, $\Delta(h)$ 
to get the value held at a particular heap address. 

\subsubsection{Typing Rules}
We first define the base types for heap address and array values. As it is the 
case with many languages, the $nil$ value is a reference type.
\begin{center}
   $\Gamma \vdash nil : T\textit{ ref}$ ($nil$ reference type) \\
   $\Gamma \vdash h : T\textit{ ref}$ (Heap address type)
\end{center}

\par
We define the rest of the typing judgement as shown below. 
The typing judgements are straightforward, 
dereferencing a heap address of type $T \textit{ref}$ yields type $T$ and 
allocating a new heap address with type $T$ gets a reference of the same type.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash e_1 : T\textit{ ref}}{\Gamma \vdash !e_1 : T}[(dereferencing)]
      & \\
      $\Gamma \vdash \textbf{new}(T) : T\textit{ ref}$ (\textbf{new} ref 1)
      \text{ }
      \inference {\Gamma \vdash v : T}{\Gamma \vdash \textbf{new}(T, v) : T\textit{ ref}}[(\textbf{new} ref 2)]
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Ref Type}
\end{figure}


\subsubsection{Basic Operational Semantics}
Lastly, we need to define the operational semantics for the new addition. We 
begin by defining the SOS rules for pointers. As the reduction rules for 
expressions are largely similar to before we will be ommiting them and only 
focus on the value itself. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h_1 \in \textbf{dom}(\Delta) & v = \Delta(h_1) & h_1 \neq nil}
      {\langle !h_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v, 
      \sigma, \tau, \Delta \rangle} [(Pointer dereferencing)]
      & \\
      \inference {h_1 \in \textbf{dom}(\Delta) & h_1 \neq nil & \Delta' = \Delta[h_1 \mapsto v_1]}
        {\langle !h_1 := v_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v_1, 
        \sigma, \tau, \Delta' \rangle} [(Pointer assignment)]
      & \\
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta + \{h \mapsto v\}}
        {\langle \textbf{new}(T, v), \sigma, \tau, \Delta \rangle \longrightarrow \langle h, 
        \sigma, \tau, \Delta' \rangle} [(Pointer allocation)]
      & \\
        $\langle \textbf{new}(T), \sigma, \tau, \Delta \rangle \longrightarrow \langle nil, 
        \sigma, \tau, \Delta' \rangle$ ($nil$ pointer allocation)
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers}
\end{figure}

\par
Pointers are allocated in two ways, with and without a value. The first rule for 
pointer allocation allocates a new heap address and assigns it the value passed 
in. Calling \textbf{new} without specifying a value, follows the second 
pointer allocation rule ($nil$ pointer allocation) 
which evaluates to a $nil$ reference. A $nil$ reference is not allocated 
in the state $\Delta$ and cannot be deference. 

\subsection{Aliases in Dependent Types}
Previously we explored the behaviour of variables in dependent types and 
proposed three different solutions to address the ambiguity when depending on 
variables. It is important to note that we only considered 
local variables, the notions of pointers and references will complicate matters. 
In this subsection we will discuss the potential pitfalls when dependent types 
involves pointers. 
 
\par
First let us consider the following code snippet, assuming we are utilise 
approach 1 defined previously to address variables in dependent types.

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let const }$y\text{ }:\text{ } int \textit{ ref} = \textbf{new}(int, 10)$\textbf{ in } \\
    \textbf{let const }$x\text{ }:\text{ }int\textit{ ref} = y$\textbf{ in } \\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y : int\text{ ref}. \{i : Int\text{ }|\text{ }i < !y\}$ \textbf{ in } \\ 
    \tab\tab\textbf{let var }$z\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in }$!x := 5$\textbf { end }\\
    \tab\textbf {end} \textbf{end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Changing Values of Aliases within Dependent Types}
\end{figure}

\par
In the above scenario, a pointer to an $int$ $y$ is declared, another variable $x$ 
acts as its alias, i.e. both $x$ and $y$ points to the same memory address. The 
expression $!x := 5$ indirectly modified the definition of the type 
$BoundedIntY$, making $z$ ill-typed. Our defined semantics does not have a way 
to prevent this,

\par
In order to address this case, some of our previous proposed solutions 
to the problem will need to be extended. While it is perfectly reasonable to 
restrict mutation simply by marking a local variable \textit{const}, 
the same can't be done with pointers. A constant 
pointer variable simply restrict the address held by the pointer to be change, 
manipulating the underlying value is still very much possible.

\par
A possible approach would be to extend the previously defined semantics to 
operate on memory location as well as local variables. In C/C++, one is able to 
declare a pointer to a constant, we would require the same in Simple-$R$. It 
is important to note the difference between an immutable pointer and a pointer 
to an immutable. The latter allows the pointer variable to change. In order to 
concrete differentiate the two in a definite manner, we introduce 
a new predicate $is\_nonrewriteable(h)$ to specify if a 
certain heap address can be modified. 

\par
$is\_nonrewriteable(h)$ holds if and only if the heap address $h$ is a const and cannot 
be rewritten. The predicate operates directly on heap address rather than 
pointers itself as 
it is possible to have a pointer to a pointer which will invalidate the 
predicate. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {l l l}      
      \textit{Expressions} & $e$& $:$ $...\text{ }|\text{ \textbf{newconst}}(T, v)$ \\
    \end{tabular}
  \end{center}
  \caption{Heap Memory Allocation in Simple-$R$}
\end{figure}


\par
We first need to extend our syntax to have a way of declaring pointers to 
constant. In the pursuit of simplicity, we include a new expression 
\textbf{newconst}$(T, v)$ to our language, this creates a new pointer to $T$ and 
assigns the value $v$. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {\Gamma \vdash v : T} 
        {\Gamma \vdash \textbf{newconst}(T, v): T \textit{ ref}}[(\textbf{newconst} type)] 
    \end{tabular}
  \end{center}
  \caption{Typing Rules for Pointer to Constants}
\end{figure}

\par
Notice that unlike C/C++, it is not possible to define a constant $nil$ pointer. 
The reason for this is because we believe that a constant $nil$ pointer 
serves no purpose and using the $nil$ value is adequate in all operations. 

\par
The figure above formalises the typing judgement for this new expression and 
its behaviour is captured using the evaluation rules defined in figure 4.27 
below.

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h \notin \textbf{dom}(\Delta) & \Delta' = \Delta 
      \uplus \{h \mapsto v\}}
      {\langle \textbf{newconst}(T, v), \sigma, \tau, \Delta \rangle \longrightarrow \langle h, 
      \sigma, \tau, \Delta' \rangle} [(\textbf{newconst} 1)]
      & \\
      \inference {\langle e_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle e_1', \sigma', \tau', \Delta' \rangle}
      {\langle \textbf{newconst}(T, e_1), \sigma, \tau, \Delta \rangle \longrightarrow \langle \textbf{newconst}(T, e_1'), 
      \sigma', \tau', \Delta' \rangle} [(\textbf{newconst} 2)]
    \end{tabular}
  \end{center}
  \caption{Operational Semantics for Pointers to Constants}
\end{figure}

\par
Additionally, we need to restrict the ability to rewrite memory location that 
are deemed non-rewriteable. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular} {c}
      \inference {h_1 \in \textbf{dom}(\Delta) & \neg is\_nonrewritable(h_1) & \Delta' = \Delta \uplus \{h_1 \mapsto v_1\}}
      {\langle !h_1 := v_1, \sigma, \tau, \Delta \rangle \longrightarrow \langle v_1, 
      \sigma, \tau, \Delta' \rangle} [(Pointer assignment)]
    \end{tabular}
  \end{center}
  \caption{Restricting Write to Immutable Memory Locations}
\end{figure}


\par
The introduction of immutable memory locations will allow us to specify the 
behaviour of pointers in dependent types. We formalise the behaviour by 
decomposing the operational semantics defined in figure 4.10, 
stipulating different behaviours for values and references. 

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c}
      \inference {
      \sigma(x) \notin \Delta &
      a \notin \text{\textbf{dom}}(\sigma) & is\_immutable(x) & a \notin \textbf{dom}(\tau) 
      \\ \langle e_1, \sigma, \tau + \{a \mapsto \Pi x : A.P(x)\} \rangle 
      \longrightarrow^{*} \langle v, \sigma', \tau' \rangle}
      {\langle \textbf{typedef } a = \Pi x :A .P(x) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau' - \{a\}\rangle}[(\textbf{typedef}) $\Pi$ vals]  
      & \\
      \inference {
      \sigma(x) \in \Delta &
      a \notin \text{\textbf{dom}}(\sigma) &  a \notin \textbf{dom}(\tau) \\ is\_immutable(x) & is\_nonrewriteable(\sigma(x)) \\
      & \langle e_1, \sigma, \tau + \{a \mapsto \Pi x : A.P(x)\} \rangle 
      \longrightarrow^{*} \langle v, \sigma', \tau' \rangle}
      {\langle \textbf{typedef } a = \Pi x :A .P(x) \textbf{ in }e_1\textbf{ end}, 
      \sigma, \tau \rangle \longrightarrow 
        \langle v, \sigma', \tau' - \{a\}\rangle}[(\textbf{typedef}) $\Pi$ refs] 
    \end{tabular}
  \end{center}
  \caption{Operational Semantics Dependent Type Definition with Pointers}
\end{figure}


\par
The appropriate rule is applied during evaluation, the top rule 
(\textbf{typedef} $\Pi$ vals) is evaluated if the variable depended on $x$ is 
a local variable and not a reference. In this case, our previous logic would hold, 
$x$ must be a constant. If, however, $x$ is a pointer variable, then we would have 
to apply the second rule which asserts that in addition to $x$ being a constant, 
preventing it to be reassigned to a different heap address, 
the underlying memory location held by $x$ must not be rewriteable. 

\par
With our newly defined rules the program in figure 4.24 becomes invalid, 
we can rewrite our program to be correct as shown in the example below. 

\begin{figure} [H]
  \begin{tabs}{1cm,2cm}
    \textbf{let const }$y\text{ }:\text{ } int \textit{ ref} = \textbf{newconst}(int, 10)$\textbf{ in }\\
    \tab\textbf{typedef }$BoundedIntY$ = $\Pi y : int\text{ ref}. \{i : Int\text{ }|\text{ }i < !y\}$ \textbf{ in } \\ 
    \tab\tab\textbf{let var }$z\text{ }:\text{ }BoundedIntY = 6$ \textbf{ in skip end}\\
    \tab\textbf {end} \\
    \textbf{end}
  \end{tabs}  
  \caption{Valid use of Pointers in Dependent Types}
\end{figure}


\par
In this subsection we have adapted our first approach to accomodate advance 
language features such as heap addresses and aliasing. While minor changes are 
needed to adapt the reamining two approaches to accomodate, we decided to leave 
them out of scope for the current project and as an open future work.

\chapter{Related Work}

\chapter{Further Work}

\chapter{Summary and Conclusions} 


\appendix
\singlespacing

\printbibliography

\end{document}
